Traceback (most recent call last):
  File "run.py", line 5, in <module>
    config=json.load(fp=f)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 7 column 22 (char 174)
Traceback (most recent call last):
  File "run.py", line 5, in <module>
    config=json.load(fp=f)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 7 column 22 (char 174)
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 3257, 2: 9922, 4: 86, 9: 18, 10: 69, 11: 2933, 13: 4228, 14: 3737, 15: 8617, 16: 7, 19: 194, 23: 7570, 24: 3674, 25: 16, 26: 67, 27: 4560, 28: 1736, 32: 766, 33: 191, 34: 4742, 35: 1830, 36: 9243, 37: 8, 38: 2851, 39: 8981, 40: 12519, 41: 2244, 42: 3685, 44: 2358, 45: 161, 46: 2466, 48: 1, 50: 2682, 51: 2020, 52: 55, 53: 14104, 54: 2698, 55: 17138}, 1: {2: 13620, 3: 16802, 6: 56, 7: 5876, 11: 1, 12: 144, 16: 950, 17: 2878, 21: 65, 22: 6578, 25: 8326, 26: 1877, 27: 512, 28: 13638, 30: 46, 31: 74, 32: 3925, 33: 2492, 36: 787, 41: 16, 43: 8737, 44: 348, 46: 1, 47: 15313, 48: 1, 50: 67, 51: 427, 52: 2939, 55: 1124, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 292, 2: 1502, 3: 1022, 4: 4962, 5: 1078, 6: 218, 7: 22942, 8: 396, 9: 11365, 10: 6333, 11: 943, 12: 8875, 14: 656, 15: 72, 16: 1519, 17: 37, 18: 5325, 20: 283, 21: 4944, 22: 1675, 23: 410, 25: 5, 26: 661, 27: 1, 28: 5390, 29: 9819, 30: 12556, 31: 4563, 32: 4, 33: 88, 34: 1, 35: 871, 36: 2, 37: 5151, 38: 2, 39: 1196, 40: 12112, 41: 300, 42: 2, 43: 1, 44: 19, 45: 1734, 46: 24, 47: 5, 48: 2643, 49: 11418}, 3: {0: 20697, 1: 20863, 2: 9158, 4: 28414, 5: 2121, 6: 33955, 7: 232, 8: 1794, 9: 22360}, 4: {0: 10339, 1: 17511, 2: 1, 3: 17319, 4: 73, 5: 28217, 6: 3, 7: 6704, 8: 31756, 9: 104, 10: 5, 11: 1, 12: 1075, 13: 334, 14: 541, 15: 493, 16: 41, 17: 237, 18: 6621, 19: 3568, 20: 2185, 21: 67, 22: 749, 23: 257, 24: 21309, 29: 1, 36: 1, 38: 1, 41: 1, 45: 1, 51: 1, 53: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 141434
INFO:root:client_idx = 0, batch_num_train_local = 2209, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 123969
INFO:root:client_idx = 1, batch_num_train_local = 1937, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 143417
INFO:root:client_idx = 2, batch_num_train_local = 2240, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 139594
INFO:root:client_idx = 3, batch_num_train_local = 2181, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 149518
INFO:root:client_idx = 4, batch_num_train_local = 2336, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 9943, 3: 102, 4: 1202, 8: 13, 9: 521, 10: 533, 11: 2853, 12: 30, 13: 3600, 14: 3243, 16: 67, 17: 2139, 22: 7, 23: 6092, 24: 23790, 25: 4996, 26: 198, 27: 3526, 28: 3563, 29: 3, 31: 21, 32: 1376, 33: 2022, 34: 1827, 35: 880, 36: 8144, 37: 3, 38: 1852, 39: 6776, 40: 12500, 41: 1763, 42: 2294, 43: 2, 44: 731, 45: 238, 46: 1691, 47: 3, 48: 46, 49: 1, 50: 7, 51: 41, 52: 2, 53: 14080, 54: 964, 56: 469, 57: 2907, 58: 1969, 59: 4, 60: 1057, 61: 1135}, 1: {0: 18985, 2: 13039, 3: 19650, 4: 9, 5: 131, 6: 253, 7: 8427, 9: 111, 10: 15, 11: 17, 12: 865, 13: 2, 14: 3, 15: 1058, 16: 2218, 17: 1000, 18: 8563, 20: 11, 21: 325, 22: 4883, 23: 6, 24: 2, 25: 82, 26: 1046, 27: 1120, 28: 9988, 29: 6, 30: 246, 31: 466, 32: 3225, 35: 1805, 36: 114, 37: 1, 38: 919, 40: 4, 41: 151, 42: 13, 43: 8735, 44: 65, 45: 979, 46: 39, 47: 8396, 48: 58, 50: 2466, 51: 19, 52: 22, 53: 24, 54: 57, 55: 28, 56: 2361, 57: 3, 58: 728, 59: 2818, 60: 1308, 61: 1590}, 2: {0: 1520, 2: 1946, 3: 4847, 4: 9106, 5: 12812, 6: 496, 7: 16650, 8: 1232, 9: 13042, 10: 5090, 11: 1007, 12: 6788, 13: 25, 14: 826, 15: 4788, 16: 1, 18: 6, 19: 992, 20: 483, 21: 4425, 22: 2465, 23: 1195, 24: 2, 26: 622, 27: 1, 28: 6278, 29: 1989, 30: 4032, 31: 3641, 32: 93, 33: 112, 34: 3, 35: 15, 36: 1752, 37: 79, 38: 82, 39: 2235, 40: 12125, 41: 644, 42: 40, 44: 1928, 45: 3, 46: 163, 47: 144, 48: 2322, 49: 11416, 51: 2387}, 3: {0: 13959, 1: 20027, 2: 9274, 3: 11, 4: 22114, 5: 17968, 6: 27292, 7: 1676, 8: 2662, 9: 18927, 10: 639, 12: 48, 13: 12, 14: 111, 15: 2784, 16: 230, 19: 2769}, 4: {0: 121, 1: 18347, 2: 1, 3: 10533, 4: 1104, 5: 505, 6: 6191, 7: 9001, 8: 30039, 9: 1246, 10: 130, 11: 1, 12: 2363, 13: 923, 14: 751, 15: 552, 16: 1, 17: 13, 18: 3377, 19: 1, 20: 1974, 21: 326, 22: 1647, 23: 944, 24: 1189, 25: 3269, 26: 739, 27: 426, 28: 935, 29: 7822, 30: 8324, 31: 509, 32: 1, 33: 637, 34: 2913, 35: 1, 36: 23, 37: 5076, 38: 1, 39: 1166, 40: 2, 41: 3, 42: 1340, 43: 1, 44: 1, 45: 676, 46: 598, 47: 6775, 48: 219, 49: 1, 50: 276, 51: 1, 52: 2970, 53: 1, 54: 1678, 55: 18234}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 131226
INFO:root:client_idx = 0, batch_num_train_local = 2050, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 128455
INFO:root:client_idx = 1, batch_num_train_local = 2007, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 141850
INFO:root:client_idx = 2, batch_num_train_local = 2216, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 140503
INFO:root:client_idx = 3, batch_num_train_local = 2195, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 155898
INFO:root:client_idx = 4, batch_num_train_local = 2435, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 5387, 1: 190, 2: 8718, 3: 1921, 4: 10839, 5: 2065, 6: 301, 7: 13132, 8: 1583, 9: 14963, 10: 775, 11: 208, 12: 1523, 13: 611, 14: 307, 15: 3095, 16: 669, 17: 1930, 18: 5, 19: 5, 20: 20, 21: 50, 22: 241, 23: 4978, 24: 5315, 25: 4176, 26: 294, 27: 3118, 28: 2242, 29: 567, 30: 36, 31: 164, 32: 1307, 33: 579, 34: 2969, 35: 713, 36: 5532, 37: 965, 38: 2041, 39: 7087, 40: 23051, 41: 162, 42: 385, 43: 220, 44: 705, 45: 422, 46: 819, 47: 154, 48: 288, 49: 937, 50: 49, 51: 223, 52: 120, 53: 2249}, 1: {0: 113, 1: 208, 2: 29, 3: 9085, 4: 6629, 5: 1875, 6: 9001, 7: 4871, 8: 114, 9: 252, 10: 784, 11: 1998, 12: 3746, 13: 303, 14: 642, 15: 308, 16: 126, 17: 1061, 18: 7597, 20: 78, 21: 550, 22: 3355, 23: 175, 24: 77, 25: 963, 26: 574, 27: 1344, 28: 12778, 29: 657, 30: 2296, 31: 560, 32: 2496, 33: 1703, 34: 4, 35: 1180, 36: 2082, 37: 436, 38: 491, 39: 29, 40: 438, 41: 1167, 42: 607, 43: 7984, 44: 244, 45: 76, 46: 374, 47: 3450, 48: 315, 49: 6, 50: 1610, 51: 165, 52: 267, 53: 7460, 54: 254, 55: 935, 56: 2830, 57: 2910, 58: 2697, 59: 2822, 60: 2365, 61: 2725}, 2: {0: 14625, 1: 88, 2: 13451, 3: 574, 4: 1999, 5: 23179, 6: 4538, 7: 102, 8: 10546, 9: 1099, 10: 578, 11: 13, 12: 480, 13: 1102, 14: 1512, 15: 3879, 16: 1268, 17: 8, 18: 163, 19: 1171, 20: 347, 21: 3374, 22: 2423, 23: 1532, 24: 76, 25: 3075, 26: 465, 27: 34, 28: 1047, 29: 7009, 30: 7029, 31: 1581, 32: 372, 33: 464, 34: 149, 35: 79, 36: 566, 37: 2658, 38: 269, 39: 3060, 40: 275, 41: 1144, 42: 33, 43: 30, 44: 1367, 46: 1251, 47: 662, 48: 1411, 49: 10422, 50: 212, 51: 1772, 52: 2398, 53: 2084, 54: 804}, 3: {0: 2803, 1: 19362, 2: 7097, 3: 1364, 4: 2110, 5: 2091, 6: 19345, 7: 1144, 8: 3993, 9: 2712, 10: 906, 11: 16, 12: 2281, 13: 2529, 14: 2037, 15: 1585, 16: 10, 17: 11, 18: 14, 19: 2581, 20: 1388, 21: 551, 22: 938, 23: 1346, 24: 4741, 25: 133, 26: 1272, 27: 576, 28: 4696, 29: 1587, 30: 3241, 31: 2331, 32: 520, 33: 25, 34: 1621, 35: 729, 36: 1853, 37: 1100, 38: 52, 39: 1, 40: 867, 41: 88, 42: 2662, 43: 504, 44: 409, 45: 1398, 46: 47, 47: 11052, 48: 631, 49: 53, 50: 878, 51: 288, 52: 209, 53: 2312, 54: 1640, 55: 17327}, 4: {0: 11657, 1: 18526, 2: 4908, 3: 22199, 4: 11958, 5: 2206, 6: 1047, 7: 16505, 8: 17710, 9: 14821, 10: 3364, 11: 1643, 12: 2064, 13: 17, 14: 436, 15: 315, 16: 444, 17: 142, 18: 4167, 19: 5, 20: 635, 21: 551, 22: 2045, 23: 206, 24: 14774, 27: 1, 28: 1, 31: 1, 38: 1, 54: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 140405
INFO:root:client_idx = 0, batch_num_train_local = 2193, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 122271
INFO:root:client_idx = 1, batch_num_train_local = 1910, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 139849
INFO:root:client_idx = 2, batch_num_train_local = 2185, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 143057
INFO:root:client_idx = 3, batch_num_train_local = 2235, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 152350
INFO:root:client_idx = 4, batch_num_train_local = 2380, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 59, in train
    loss.backward()
  File "/home/listu/.local/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1745, 1: 21680, 2: 87, 3: 15552, 4: 100, 7: 65, 8: 8037, 9: 5825, 11: 1523, 12: 13, 13: 2169, 14: 1132, 15: 644, 16: 55, 17: 8, 18: 2381, 20: 36, 22: 182, 24: 792, 26: 743, 27: 270, 30: 97, 33: 2, 36: 5284, 37: 2, 40: 1450}, 1: {3: 2066, 5: 424, 6: 258, 7: 3758, 8: 23930, 9: 13, 10: 475, 11: 2, 13: 948, 14: 3, 15: 320, 20: 21, 21: 4678, 24: 24153, 25: 4590, 28: 1154, 30: 1, 31: 1564, 33: 313, 34: 95, 35: 1663}, 2: {0: 156, 2: 15794, 5: 2484, 6: 4449, 8: 1603, 9: 45, 11: 334, 13: 1398, 14: 99, 15: 8191, 16: 314, 17: 116, 18: 2, 22: 2672, 23: 7685, 25: 1, 26: 1344, 27: 261, 29: 1, 30: 226, 31: 2697, 32: 1140, 34: 5, 35: 681, 36: 1509, 39: 9761, 40: 1, 41: 2417, 43: 3, 44: 322, 45: 3, 46: 2459, 47: 200, 48: 70, 49: 10576}, 3: {0: 11087, 3: 271, 5: 23227, 7: 28698, 8: 16, 9: 229, 14: 2762, 17: 2, 20: 4, 21: 1, 23: 197, 25: 522, 27: 198, 28: 1205, 29: 1149, 30: 108, 32: 3, 33: 1128}, 4: {0: 5538, 1: 13182, 2: 93, 3: 1077, 4: 29942, 6: 10149, 7: 614, 9: 15936}, 5: {0: 1, 2: 906, 4: 9, 5: 43, 9: 10635, 10: 27, 11: 1875, 12: 134, 13: 3, 14: 221, 16: 10, 17: 1788, 18: 5843, 20: 3, 22: 3843, 25: 1, 27: 716, 28: 6, 29: 58, 31: 276, 33: 43, 34: 25, 35: 7, 36: 10, 37: 135, 38: 2719, 40: 1, 41: 53, 42: 2556, 43: 2954, 45: 1890, 48: 935, 52: 25, 53: 13783, 55: 14969, 57: 161, 58: 1186, 59: 2821}, 6: {0: 15604, 1: 3318, 2: 7572, 3: 11, 4: 666, 5: 334, 7: 624, 9: 321, 10: 5772, 12: 7279, 13: 22, 14: 12, 16: 14, 18: 3719, 19: 3553, 20: 2402, 22: 1915, 23: 49, 25: 176, 26: 512, 30: 8173, 31: 88, 32: 50, 33: 61, 35: 20, 36: 68, 37: 86, 39: 354, 40: 22900}, 7: {0: 385, 1: 193, 2: 6897, 3: 10, 4: 1320, 6: 19375, 7: 7, 8: 340, 10: 33, 11: 134, 12: 17, 13: 21, 17: 217, 21: 394, 22: 2, 25: 179, 26: 2, 27: 3606, 29: 8611, 30: 30, 31: 9, 32: 3158, 34: 4606, 37: 4935, 40: 211, 41: 32, 42: 1, 44: 2390, 45: 1, 46: 18, 48: 1599, 49: 12, 51: 3, 53: 321, 54: 2656, 56: 2700, 57: 2748, 60: 2364, 61: 11}, 8: {0: 68, 2: 2853, 3: 16100, 5: 1, 7: 1079, 8: 19, 10: 96, 11: 9, 12: 2475, 14: 153, 16: 509, 17: 1020, 23: 214, 25: 2611, 28: 17991, 30: 2197, 32: 118, 33: 1158, 35: 329, 36: 3161, 39: 61, 40: 67, 41: 15, 42: 1129, 43: 1, 46: 13, 47: 15117, 49: 798, 51: 31, 52: 372, 54: 6, 55: 3292}, 9: {0: 1, 1: 1, 2: 1, 3: 56, 4: 1498, 5: 4903, 6: 1, 7: 909, 8: 1, 9: 843, 10: 4, 11: 1, 12: 176, 13: 1, 14: 552, 15: 27, 16: 1615, 17: 1, 18: 1, 19: 209, 20: 2, 21: 3, 22: 388, 23: 92, 24: 38, 25: 267, 26: 4, 27: 22, 28: 408, 29: 1, 30: 1770, 31: 3, 32: 226, 33: 66, 34: 12, 35: 1, 36: 1, 37: 1, 38: 135, 39: 1, 40: 1, 41: 44, 42: 1, 43: 5780, 44: 13, 45: 2, 46: 1, 47: 1, 48: 41, 49: 32, 50: 2749, 51: 2414, 52: 2597, 53: 1, 54: 37, 55: 1, 56: 130, 57: 1, 58: 1511, 59: 1, 60: 1, 61: 2714}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 69874
INFO:root:client_idx = 0, batch_num_train_local = 1091, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 70429
INFO:root:client_idx = 1, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 79019
INFO:root:client_idx = 2, batch_num_train_local = 1234, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70807
INFO:root:client_idx = 3, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 76531
INFO:root:client_idx = 4, batch_num_train_local = 1195, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 70671
INFO:root:client_idx = 5, batch_num_train_local = 1104, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 85675
INFO:root:client_idx = 6, batch_num_train_local = 1338, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 69548
INFO:root:client_idx = 7, batch_num_train_local = 1086, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 73063
INFO:root:client_idx = 8, batch_num_train_local = 1141, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 32315
INFO:root:client_idx = 9, batch_num_train_local = 504, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {1: 715, 2: 104, 3: 4698, 4: 1294, 5: 1549, 6: 12, 7: 127, 8: 9492, 9: 3226, 11: 4, 12: 490, 14: 1369, 15: 1198, 17: 38, 19: 1719, 20: 207, 21: 6, 22: 5, 23: 188, 24: 10022, 25: 7862, 26: 832, 27: 1529, 28: 81, 29: 33, 30: 306, 31: 843, 32: 10, 33: 560, 34: 5, 35: 18, 36: 4370, 37: 59, 40: 2611, 41: 903, 43: 7, 44: 14, 45: 822, 46: 1, 47: 2305, 48: 27, 49: 1991, 50: 377, 51: 29, 52: 211, 53: 2808, 56: 2024, 57: 2903}, 1: {0: 11592, 1: 23, 2: 7451, 3: 1813, 4: 56, 5: 1440, 6: 4, 8: 1, 9: 3228, 10: 32, 11: 1, 12: 1049, 13: 7, 14: 9, 15: 1830, 17: 2, 19: 36, 20: 68, 22: 2290, 23: 23, 25: 45, 27: 49, 28: 2405, 29: 1236, 30: 2633, 31: 196, 32: 272, 33: 35, 34: 567, 35: 1372, 36: 3775, 37: 745, 38: 9, 39: 5636, 41: 253, 43: 25, 44: 1534, 45: 1017, 46: 1367, 47: 1, 48: 97, 49: 8087, 50: 1955, 51: 106, 52: 1689, 53: 10702}, 2: {0: 928, 1: 7, 2: 15318, 3: 33, 4: 5438, 5: 2, 6: 612, 7: 14240, 8: 984, 10: 108, 11: 7, 12: 27, 13: 1346, 15: 187, 16: 1245, 17: 373, 18: 6193, 19: 686, 20: 99, 21: 613, 22: 733, 23: 2407, 24: 8244, 25: 4, 27: 485, 28: 179, 30: 2363, 31: 4, 32: 2971, 33: 396, 34: 132, 35: 168, 36: 706, 37: 27, 38: 9, 39: 3567}, 3: {0: 8523, 1: 112, 2: 1494, 3: 949, 5: 27131, 6: 28435, 7: 1, 8: 25, 10: 1, 11: 47, 12: 1138, 14: 1, 15: 6, 17: 2, 18: 114, 19: 6, 20: 601, 21: 1718}, 4: {0: 74, 1: 29136, 2: 359, 3: 4, 4: 2065, 5: 12, 6: 3065, 8: 15951, 9: 9497, 10: 24, 11: 107, 12: 2517, 13: 2, 14: 20, 15: 37, 16: 10, 17: 444, 18: 328, 19: 435, 21: 665, 23: 1847, 24: 5022}, 5: {0: 11339, 1: 5, 2: 1, 3: 20723, 4: 5, 5: 15, 7: 6123, 8: 2460, 9: 17890, 10: 182, 11: 173, 12: 21, 13: 40, 14: 2064, 15: 790, 17: 437, 18: 1635, 19: 1, 20: 215, 21: 3, 22: 917, 23: 2113, 24: 840, 25: 1, 26: 76, 27: 1348, 28: 10803}, 6: {0: 1458, 1: 687, 7: 11961, 8: 2, 9: 1, 11: 3464, 12: 4070, 13: 86, 14: 35, 15: 9, 16: 132, 17: 427, 18: 3251, 19: 707, 20: 242, 21: 4, 22: 2027, 23: 249, 24: 89, 25: 50, 26: 241, 27: 24, 28: 2530, 29: 3075, 30: 4392, 31: 617, 32: 1370, 34: 1, 36: 151, 37: 2707, 38: 2774, 39: 680, 40: 20459, 41: 623, 42: 2264}, 7: {0: 612, 2: 1679, 3: 6749, 4: 529, 5: 1254, 6: 211, 7: 1637, 8: 2999, 9: 4, 10: 5799, 12: 536, 13: 650, 14: 186, 15: 3080, 16: 140, 17: 5, 18: 272, 20: 377, 22: 38, 23: 1402, 24: 763, 25: 34, 26: 1356, 29: 29, 30: 2903, 31: 1022, 32: 15, 33: 395, 34: 19, 35: 740, 36: 7, 38: 22, 40: 995, 41: 277, 43: 8703, 44: 26, 45: 13, 46: 1073, 47: 98, 48: 19, 49: 503, 50: 1, 51: 83, 52: 3, 53: 594, 54: 2278, 55: 16239, 56: 4, 57: 6, 58: 2696, 59: 41, 60: 2233}, 8: {0: 50, 1: 7088, 2: 6318, 3: 173, 4: 19886, 5: 12, 6: 1892, 7: 1664, 8: 18, 10: 258, 11: 1, 12: 238, 13: 308, 14: 1248, 15: 2002, 16: 147, 18: 152, 20: 483, 21: 1, 22: 7, 23: 6, 24: 1, 25: 312, 26: 87, 27: 1632, 28: 4355, 29: 5409, 30: 4, 31: 1835, 33: 1193, 34: 198, 36: 1023, 37: 1, 39: 283, 40: 565, 41: 185, 42: 1422, 43: 1, 44: 807, 45: 43, 46: 27, 47: 12897}, 9: {0: 9, 1: 601, 2: 1479, 3: 1, 4: 4262, 5: 1, 6: 1, 7: 1, 8: 2014, 9: 1, 10: 3, 11: 74, 12: 8, 13: 2123, 14: 2, 15: 43, 16: 843, 17: 1424, 18: 1, 19: 172, 20: 176, 21: 2066, 22: 2985, 23: 2, 24: 2, 25: 39, 26: 13, 27: 6, 28: 411, 29: 38, 30: 1, 31: 120, 32: 57, 33: 192, 34: 3821, 35: 403, 36: 1, 37: 1620, 38: 40, 39: 11, 40: 1, 41: 320, 42: 1, 43: 2, 44: 344, 45: 1, 46: 23, 47: 17, 48: 2502, 49: 837, 50: 416, 51: 2230, 52: 1091, 53: 1, 54: 421, 55: 2023, 56: 802, 57: 1, 58: 1, 59: 2781, 60: 132, 61: 2725}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70004
INFO:root:client_idx = 0, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 76763
INFO:root:client_idx = 1, batch_num_train_local = 1199, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70841
INFO:root:client_idx = 2, batch_num_train_local = 1106, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 70304
INFO:root:client_idx = 3, batch_num_train_local = 1098, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 71621
INFO:root:client_idx = 4, batch_num_train_local = 1119, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 80220
INFO:root:client_idx = 5, batch_num_train_local = 1253, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70859
INFO:root:client_idx = 6, batch_num_train_local = 1107, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 71349
INFO:root:client_idx = 7, batch_num_train_local = 1114, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 74232
INFO:root:client_idx = 8, batch_num_train_local = 1159, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 41739
INFO:root:client_idx = 9, batch_num_train_local = 652, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2918, 1: 5723, 2: 2633, 3: 5267, 4: 2509, 5: 4013, 6: 704, 7: 31, 8: 4026, 9: 4548, 10: 38, 11: 135, 12: 748, 13: 10, 14: 421, 15: 1228, 16: 12, 17: 123, 18: 44, 19: 1370, 20: 223, 21: 82, 22: 112, 23: 334, 24: 6629, 25: 5159, 26: 543, 27: 252, 28: 555, 29: 123, 30: 572, 31: 400, 32: 77, 33: 324, 34: 46, 35: 34, 36: 5, 37: 945, 38: 1172, 39: 807, 40: 1581, 41: 124, 42: 163, 43: 15, 44: 1025, 45: 441, 46: 6, 47: 1898, 48: 139, 49: 867, 50: 393, 51: 33, 52: 442, 53: 6396, 54: 65, 55: 900, 56: 1032}, 1: {0: 61, 1: 1022, 2: 713, 3: 2878, 4: 704, 5: 3884, 6: 362, 7: 16340, 8: 2231, 9: 4549, 10: 318, 11: 62, 12: 1139, 13: 1760, 14: 59, 15: 1720, 16: 10, 17: 32, 18: 38, 19: 138, 20: 118, 21: 3, 22: 2218, 23: 144, 24: 20, 25: 239, 26: 2, 27: 64, 28: 2394, 29: 901, 30: 1512, 31: 223, 32: 297, 33: 102, 34: 346, 35: 216, 36: 2253, 37: 15, 38: 97, 39: 1819, 40: 1040, 41: 467, 42: 191, 43: 1842, 44: 764, 45: 247, 46: 129, 47: 86, 48: 229, 49: 1895, 50: 1352, 51: 196, 52: 1151, 53: 2564, 54: 1653, 55: 10222}, 2: {0: 7922, 1: 557, 2: 8182, 3: 534, 4: 5532, 5: 303, 6: 2916, 7: 355, 8: 7970, 9: 93, 10: 517, 11: 110, 12: 225, 13: 103, 14: 1596, 15: 410, 16: 1001, 17: 305, 18: 4773, 19: 690, 20: 143, 21: 707, 22: 945, 23: 1720, 24: 5739, 25: 88, 26: 11, 27: 1258, 28: 762, 29: 5, 30: 1422, 31: 49, 32: 1473, 33: 274, 34: 163, 35: 52, 36: 1994, 37: 25, 38: 758, 39: 1905, 40: 4741, 41: 298, 42: 662, 43: 314, 44: 69, 45: 537}, 3: {0: 1518, 1: 3311, 2: 13171, 3: 2092, 4: 63, 5: 8813, 6: 342, 7: 595, 8: 25, 9: 7, 10: 49, 11: 973, 12: 1199, 13: 1019, 14: 20, 15: 103, 16: 12, 17: 41, 18: 469, 19: 483, 20: 506, 21: 1563, 22: 561, 23: 5, 24: 5424, 25: 218, 26: 154, 27: 65, 28: 2814, 29: 1182, 30: 109, 31: 1763, 32: 111, 33: 75, 34: 742, 35: 1080, 36: 113, 37: 720, 39: 130, 40: 93, 41: 39, 42: 98, 43: 887, 44: 110, 45: 1, 46: 355, 47: 166, 48: 49, 49: 277, 50: 311, 51: 11, 52: 17, 53: 755, 54: 293, 55: 516, 56: 296, 57: 31, 58: 1523, 59: 2792, 60: 1520, 61: 548}, 4: {0: 6313, 1: 5395, 2: 2466, 3: 216, 4: 3132, 5: 561, 6: 1256, 7: 3243, 8: 560, 9: 9126, 10: 637, 11: 551, 12: 2179, 14: 1083, 15: 211, 16: 72, 17: 327, 18: 723, 19: 34, 20: 19, 21: 754, 22: 29, 23: 1412, 24: 3888, 25: 1538, 26: 129, 27: 240, 28: 81, 29: 2638, 30: 618, 31: 2, 32: 1673, 33: 1008, 34: 1638, 35: 98, 36: 1038, 37: 760, 38: 121, 39: 2149, 40: 4650, 41: 832, 42: 87, 43: 18, 44: 34, 45: 135, 46: 139, 47: 3723, 48: 19, 49: 983, 50: 234, 51: 489, 52: 721}, 5: {0: 4491, 1: 183, 2: 132, 3: 15950, 4: 281, 5: 624, 6: 15, 7: 2695, 8: 7205, 9: 15065, 10: 34, 11: 35, 12: 3142, 13: 62, 14: 53, 15: 896, 16: 4, 17: 1422, 18: 1731, 19: 706, 20: 228, 21: 59, 22: 1093, 23: 1562, 24: 1317, 25: 52, 26: 580, 27: 48, 28: 7090, 29: 668, 30: 4568}, 6: {0: 7797, 1: 7423, 2: 16, 3: 63, 4: 2, 5: 84, 6: 610, 7: 319, 8: 6223, 9: 138, 10: 3944, 11: 578, 12: 783, 13: 204, 14: 58, 15: 120, 16: 210, 17: 322, 18: 2972, 19: 5, 20: 248, 21: 69, 22: 2020, 23: 1459, 24: 527, 25: 248, 26: 226, 27: 2, 28: 2465, 29: 1, 30: 2087, 31: 241, 32: 816, 33: 13, 34: 26, 35: 150, 36: 2683, 37: 1489, 38: 256, 39: 25, 40: 10608, 41: 99, 42: 347, 43: 2743, 44: 45, 45: 2, 46: 1169, 47: 3145, 48: 18, 49: 5642}, 7: {0: 463, 1: 1321, 2: 2660, 3: 7063, 4: 1730, 5: 8901, 6: 7289, 7: 3413, 8: 4, 9: 310, 10: 732, 11: 224, 12: 539, 13: 276, 14: 194, 15: 2519, 16: 217, 17: 53, 18: 667, 19: 16, 20: 354, 21: 26, 22: 249, 23: 381, 24: 1261, 25: 562, 26: 784, 27: 27, 28: 52, 29: 1718, 30: 1601, 31: 354, 32: 88, 33: 274, 34: 1404, 35: 11, 36: 79, 37: 323, 38: 85, 39: 8, 40: 27, 41: 2, 42: 1541, 43: 1884, 44: 360, 45: 128, 46: 414, 47: 526, 48: 119, 49: 493, 50: 424, 51: 1707, 52: 84, 53: 102, 54: 351, 55: 333, 56: 1502, 57: 2879, 58: 1173, 59: 30, 60: 845, 61: 2177}, 8: {0: 226, 2: 2449, 3: 1043, 4: 14875, 5: 3659, 6: 4491, 7: 3196, 8: 4820, 9: 5, 10: 107, 11: 162, 12: 135, 13: 664, 14: 535, 15: 1842, 16: 223, 17: 1, 18: 528, 19: 276, 20: 429, 21: 37, 22: 1654, 23: 1136, 24: 73, 25: 223, 26: 138, 27: 1, 28: 3488, 29: 117, 30: 106, 31: 432, 32: 6, 33: 500, 34: 18, 35: 867, 36: 32, 37: 106, 39: 263, 40: 1181, 41: 16, 42: 460, 43: 781, 44: 236, 45: 278, 46: 164, 47: 5515, 48: 708, 49: 1261, 50: 34, 51: 12, 52: 578, 53: 4288, 54: 337, 55: 6291}, 9: {0: 2876, 1: 13439, 2: 1781, 3: 37, 4: 4707, 5: 574, 6: 16247, 7: 5567, 8: 882, 9: 6, 10: 31, 11: 1048, 12: 5, 13: 464, 14: 915, 15: 133, 16: 756, 17: 526, 18: 1, 19: 44, 20: 200, 21: 1776, 22: 121, 23: 84, 24: 105, 25: 20, 26: 38, 27: 3116, 28: 1063, 29: 2467, 30: 7, 31: 1173, 32: 154, 33: 201, 34: 360, 35: 193, 36: 1836, 37: 776, 38: 365, 39: 3071, 40: 710, 41: 684, 42: 138, 43: 254, 44: 82, 45: 127, 46: 115, 47: 259, 48: 1364, 50: 1, 52: 1, 58: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 70415
INFO:root:client_idx = 0, batch_num_train_local = 1100, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 75031
INFO:root:client_idx = 1, batch_num_train_local = 1172, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 70208
INFO:root:client_idx = 2, batch_num_train_local = 1097, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 62328
INFO:root:client_idx = 3, batch_num_train_local = 973, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 69982
INFO:root:client_idx = 4, batch_num_train_local = 1093, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 71991
INFO:root:client_idx = 5, batch_num_train_local = 1124, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 70740
INFO:root:client_idx = 6, batch_num_train_local = 1105, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 65333
INFO:root:client_idx = 7, batch_num_train_local = 1020, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 71003
INFO:root:client_idx = 8, batch_num_train_local = 1109, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 70901
INFO:root:client_idx = 9, batch_num_train_local = 1107, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 196, in forward
    x = self.fc(x_f)  # B x num_classes
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 1407, 1: 89, 2: 3176, 3: 252, 8: 1251, 10: 563, 11: 277, 12: 30, 15: 1311, 17: 2377, 18: 72, 19: 529, 20: 1, 21: 376, 22: 40, 25: 5577, 26: 7, 28: 633, 29: 31, 31: 43, 36: 2976, 37: 1698, 39: 2143, 40: 1464, 41: 4, 42: 1, 43: 1546, 45: 255, 46: 140, 47: 2477, 49: 3965, 51: 971}, 1: {2: 1277, 4: 1, 5: 876, 6: 32703, 8: 176}, 2: {0: 126, 1: 9279, 3: 1, 4: 13130, 5: 11368, 6: 21, 8: 47, 13: 2, 14: 1, 15: 5, 18: 30, 19: 2, 21: 12, 22: 5773}, 3: {0: 8945, 1: 69, 2: 481, 3: 150, 4: 770, 7: 5725, 8: 5255, 9: 619, 11: 1, 12: 3025, 13: 1610, 14: 227, 15: 471, 16: 26, 18: 2436, 20: 235, 21: 658, 22: 32, 23: 3, 24: 3993, 26: 4, 27: 126, 28: 13285}, 4: {0: 4468, 1: 6023, 2: 39, 3: 1297, 5: 13959, 6: 3, 8: 53, 13: 762, 16: 2274, 18: 465, 20: 235, 21: 511, 23: 101, 26: 20, 27: 2814, 28: 2855}, 5: {2: 97, 3: 2, 5: 2, 7: 575, 8: 321, 12: 240, 16: 37, 20: 1, 22: 1, 23: 5697, 25: 1635, 26: 574, 27: 66, 28: 1, 32: 20, 34: 197, 35: 2009, 36: 1209, 37: 86, 39: 4468, 46: 1415, 49: 20, 50: 2, 52: 323, 53: 2, 54: 31, 55: 331, 56: 273, 57: 1759, 59: 77, 60: 264, 61: 3}, 6: {0: 12589, 2: 99, 4: 90, 5: 66, 6: 32, 7: 7676, 10: 118, 12: 614, 13: 99, 14: 2, 16: 138, 20: 435, 23: 12, 26: 9, 27: 76, 30: 6915, 37: 1, 38: 3, 40: 933, 42: 369, 43: 5380}, 7: {0: 311, 1: 9360, 2: 4, 4: 56, 5: 2891, 8: 1122, 9: 54, 10: 1231, 11: 251, 14: 719, 16: 14, 17: 42, 18: 50, 21: 1, 22: 50, 23: 8, 24: 255, 25: 219, 26: 936, 28: 1, 29: 95, 30: 1259, 31: 11, 32: 792, 34: 6, 35: 573, 38: 2380, 39: 32, 41: 561, 42: 23, 43: 503, 44: 86, 45: 86, 47: 79, 50: 5, 52: 122, 54: 5, 55: 6, 56: 240, 58: 11, 60: 4}, 8: {0: 55, 1: 2, 3: 255, 4: 110, 5: 38, 6: 57, 7: 265, 8: 1, 10: 13, 11: 1911, 14: 7, 15: 2364, 16: 1, 18: 1184, 19: 1, 20: 3, 22: 428, 23: 162, 24: 18059, 25: 1, 26: 398, 27: 82, 29: 5, 30: 134, 31: 747, 32: 2, 33: 122, 34: 7, 36: 233, 37: 17, 38: 379, 39: 1280, 40: 13341}, 9: {1: 772, 2: 27567, 3: 1353, 5: 4, 6: 78, 9: 726, 10: 20, 14: 6, 19: 281, 20: 109, 21: 1066, 22: 1224, 23: 486, 25: 13, 27: 254, 28: 583, 29: 841}, 10: {3: 3778, 4: 6, 6: 700, 9: 1, 12: 5192, 18: 2248, 20: 557, 21: 2448, 23: 10, 24: 1, 28: 117, 30: 2057, 31: 572, 32: 202, 33: 411, 35: 8, 36: 453, 41: 5, 42: 428, 45: 932, 47: 5242, 49: 5887, 50: 79, 51: 1198, 52: 813, 54: 416, 55: 353, 57: 95, 58: 271, 59: 2738}, 11: {0: 1345, 1: 3745, 3: 160, 5: 39, 10: 2410, 11: 7, 13: 12, 14: 11, 16: 11, 17: 10, 18: 343, 19: 191, 21: 2, 23: 268, 24: 1714, 25: 241, 26: 1, 27: 1153, 28: 1, 30: 1, 31: 3180, 32: 2951, 34: 89, 35: 1, 36: 4, 37: 80, 38: 15, 42: 3, 44: 185, 45: 587, 46: 5, 48: 238, 49: 108, 50: 119, 51: 187, 52: 175, 53: 371, 54: 517, 55: 9799, 60: 1549, 61: 65}, 12: {0: 9, 1: 312, 4: 4251, 5: 243, 12: 181, 14: 234, 15: 281, 18: 3, 19: 1965, 20: 1, 23: 214, 25: 414, 28: 1914, 30: 2134, 34: 18, 35: 14, 36: 2689, 37: 2359, 40: 8885, 42: 3, 43: 746, 44: 1, 45: 26, 47: 7419, 49: 84, 50: 1362}, 13: {1: 180, 2: 18, 3: 13, 4: 3, 7: 2045, 8: 9734, 9: 1, 10: 1617, 15: 3090, 19: 81, 23: 1273, 24: 497, 26: 109, 27: 95, 28: 54, 29: 2158, 33: 2194, 34: 1084, 35: 92, 36: 383, 37: 278, 38: 46, 39: 1252, 41: 1735, 43: 306, 44: 151, 45: 1, 47: 3, 48: 1, 50: 876, 51: 1, 52: 1, 53: 13730}, 14: {0: 1311, 3: 1, 4: 12947, 5: 148, 6: 635, 7: 351, 8: 14950, 9: 383, 10: 1, 11: 625, 12: 4, 13: 2069, 14: 1, 17: 682, 20: 888}, 15: {0: 3661, 1: 354, 2: 7, 3: 1610, 5: 1643, 7: 151, 8: 427, 9: 2372, 11: 232, 12: 4, 14: 18, 15: 14, 17: 36, 18: 4247, 19: 57, 21: 1, 22: 130, 24: 462, 25: 88, 28: 82, 30: 2, 32: 138, 33: 43, 34: 3309, 36: 2082, 39: 999, 40: 7, 44: 2198, 46: 929, 48: 1068, 50: 244, 53: 1, 54: 2, 55: 7704, 56: 398, 57: 2, 58: 670}, 16: {1: 214, 3: 8, 7: 1, 8: 13, 9: 540, 10: 22, 12: 690, 13: 3, 15: 1643, 16: 12, 18: 114, 19: 654, 20: 1, 22: 178, 24: 1, 27: 172, 28: 1228, 30: 83, 31: 24, 32: 589, 35: 3, 36: 1, 38: 30, 42: 367, 43: 2, 44: 104, 48: 1, 49: 3, 51: 90, 52: 1559, 55: 1, 56: 1918, 58: 1, 60: 48, 61: 2651}, 17: {0: 357, 2: 1437, 3: 82, 4: 2, 5: 80, 7: 4015, 10: 65, 12: 108, 15: 2, 16: 4, 17: 5, 18: 753, 19: 1, 20: 2, 21: 1, 22: 1146, 23: 2, 25: 159, 26: 547, 27: 235, 28: 9, 29: 6690, 30: 17, 31: 60, 33: 1, 34: 32, 35: 1, 36: 3, 37: 640, 39: 3, 40: 1, 41: 256, 42: 2493, 43: 255, 45: 9, 46: 2, 47: 97, 48: 1337, 49: 1351, 50: 62, 51: 1, 52: 1, 53: 1, 54: 1728, 55: 68, 57: 1054, 58: 1744, 59: 7, 60: 500, 61: 5}, 18: {2: 1, 3: 547, 4: 2168, 5: 58, 7: 577, 8: 596, 9: 29151, 10: 346, 11: 573, 12: 5, 13: 5, 14: 3708}, 19: {0: 1, 1: 7975, 3: 25634, 4: 1, 5: 1, 6: 3, 7: 14373, 10: 1, 11: 1, 12: 1, 15: 1, 18: 1, 23: 1, 24: 1, 28: 1, 32: 1, 34: 1, 38: 1, 47: 1, 56: 1, 61: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35682
INFO:root:client_idx = 0, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35033
INFO:root:client_idx = 1, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 39797
INFO:root:client_idx = 2, batch_num_train_local = 621, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 48146
INFO:root:client_idx = 3, batch_num_train_local = 752, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35879
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 21738
INFO:root:client_idx = 5, batch_num_train_local = 339, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35656
INFO:root:client_idx = 6, batch_num_train_local = 557, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 24454
INFO:root:client_idx = 7, batch_num_train_local = 382, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41664
INFO:root:client_idx = 8, batch_num_train_local = 651, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35383
INFO:root:client_idx = 9, batch_num_train_local = 552, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 37218
INFO:root:client_idx = 10, batch_num_train_local = 581, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 31893
INFO:root:client_idx = 11, batch_num_train_local = 498, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35762
INFO:root:client_idx = 12, batch_num_train_local = 558, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 43102
INFO:root:client_idx = 13, batch_num_train_local = 673, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34996
INFO:root:client_idx = 14, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 35392
INFO:root:client_idx = 15, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 12969
INFO:root:client_idx = 16, batch_num_train_local = 202, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 27431
INFO:root:client_idx = 17, batch_num_train_local = 428, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 37735
INFO:root:client_idx = 18, batch_num_train_local = 589, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 48002
INFO:root:client_idx = 19, batch_num_train_local = 750, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {2: 2109, 3: 752, 4: 18904, 5: 29, 7: 6573, 8: 553, 9: 6, 10: 124, 11: 86, 14: 22, 15: 4, 16: 1, 17: 5, 18: 69, 21: 466, 22: 1010, 23: 152, 24: 1, 25: 3216, 28: 1311}, 1: {0: 8442, 1: 7109, 3: 24, 4: 40, 6: 100, 7: 1549, 8: 130, 9: 12368, 12: 155, 13: 15, 14: 189, 15: 2019, 16: 435, 17: 3, 18: 50, 19: 43, 20: 2, 21: 2650}, 2: {0: 676, 1: 603, 2: 1295, 3: 55, 5: 4358, 6: 20651, 7: 219, 8: 550, 9: 2917, 10: 1, 11: 28, 13: 1094, 15: 26, 16: 94, 18: 204, 19: 58, 20: 119, 21: 1, 22: 86, 24: 977, 25: 78, 26: 56, 27: 33, 28: 139, 29: 1467}, 3: {0: 6207, 1: 5646, 2: 5631, 3: 580, 4: 2520, 5: 532, 6: 481, 7: 10953, 8: 48, 9: 5494}, 4: {0: 54, 2: 580, 3: 1707, 4: 7, 5: 449, 6: 38, 7: 1235, 8: 8, 11: 55, 12: 142, 13: 120, 14: 197, 17: 40, 18: 19, 19: 319, 20: 118, 22: 3, 23: 7, 24: 2814, 25: 740, 27: 502, 28: 1612, 29: 464, 30: 555, 31: 145, 32: 141, 33: 800, 34: 1852, 36: 278, 37: 333, 38: 9, 39: 8389, 41: 7, 42: 247, 43: 259, 44: 48, 46: 1077, 47: 1589, 48: 150, 49: 42, 50: 2130, 51: 613, 53: 6007}, 5: {0: 8258, 2: 587, 3: 62, 4: 193, 6: 14, 7: 3, 8: 8766, 9: 591, 10: 791, 13: 24, 15: 9, 16: 16, 18: 2504, 19: 1, 20: 588, 21: 376, 23: 4, 24: 559, 25: 1, 26: 613, 28: 103, 29: 1005, 30: 1333, 32: 18, 33: 56, 34: 146, 37: 356, 38: 2, 39: 164, 40: 15, 41: 2, 42: 81, 43: 2, 45: 372, 46: 52, 49: 178, 50: 9, 51: 3, 52: 196, 53: 2, 54: 791, 55: 8333}, 6: {0: 1061, 1: 7146, 2: 120, 4: 23, 5: 220, 6: 826, 7: 11717, 8: 224, 9: 3369, 10: 802, 11: 128, 13: 48, 15: 269, 16: 155, 17: 4, 18: 30, 19: 59, 20: 4, 22: 1623, 23: 50, 24: 1, 25: 4, 26: 1, 28: 3450, 30: 244, 31: 42, 32: 1456, 33: 281, 34: 692, 35: 438, 36: 301, 37: 239}, 7: {0: 446, 1: 120, 2: 2, 4: 3768, 5: 2129, 6: 38, 8: 4, 9: 2, 10: 5, 11: 859, 12: 711, 13: 28, 14: 6, 15: 81, 16: 196, 17: 748, 18: 694, 19: 829, 21: 248, 23: 35, 25: 200, 26: 478, 27: 488, 28: 194, 30: 1048, 31: 100, 33: 979, 34: 852, 35: 359, 36: 112, 37: 202, 38: 26, 39: 36, 40: 325, 41: 1578, 42: 431, 43: 5, 44: 193, 45: 669, 46: 8, 47: 7243, 48: 1, 49: 7814, 50: 88, 52: 2015}, 8: {0: 36, 1: 2020, 2: 19271, 3: 757, 4: 1407, 5: 4714, 6: 1, 7: 201, 8: 6, 9: 1, 11: 2, 12: 99, 14: 351, 15: 320, 16: 1, 17: 637, 19: 1149, 20: 632, 21: 301, 23: 2, 24: 9623}, 9: {0: 6, 1: 40, 3: 1743, 4: 23, 5: 356, 6: 196, 7: 1, 8: 96, 9: 6, 10: 429, 11: 131, 13: 55, 15: 117, 16: 302, 17: 9, 18: 116, 19: 80, 20: 30, 21: 41, 23: 1, 24: 180, 25: 1362, 26: 1, 27: 94, 29: 30, 31: 4, 32: 32, 33: 76, 34: 1, 36: 2, 37: 1675, 38: 1, 39: 311, 40: 3665, 41: 7, 42: 1631, 43: 7, 44: 202, 45: 12, 46: 49, 47: 1755, 49: 1728, 50: 132, 52: 373, 53: 16, 54: 67, 56: 469, 58: 13, 59: 1612, 60: 4, 61: 85}, 10: {0: 2209, 1: 4453, 2: 28, 3: 3277, 6: 4, 7: 456, 8: 151, 9: 1909, 10: 46, 11: 7, 12: 64, 13: 55, 14: 146, 16: 1, 17: 2, 18: 285, 19: 155, 20: 148, 21: 283, 22: 1, 23: 362, 24: 1070, 27: 2218, 28: 105, 29: 1167, 30: 1158, 31: 15, 32: 28, 33: 1, 34: 12, 35: 90, 36: 1, 37: 518, 40: 10, 41: 211, 42: 627, 43: 4737, 44: 984, 45: 97, 46: 476, 47: 1056, 48: 717, 49: 13, 51: 1364, 52: 49, 53: 1169, 55: 9245}, 11: {0: 182, 1: 1286, 2: 4, 3: 599, 5: 1819, 6: 1693, 7: 256, 8: 128, 9: 4289, 10: 92, 11: 1048, 12: 1574, 13: 148, 14: 67, 15: 59, 16: 585, 17: 247, 18: 27, 19: 677, 20: 18, 21: 8, 23: 271, 24: 143, 26: 142, 27: 205, 28: 271, 29: 1, 30: 2, 31: 390, 32: 273, 34: 394, 35: 15, 36: 938, 38: 2743, 39: 30, 40: 7671, 41: 659, 43: 18, 44: 1076, 45: 261, 46: 705, 47: 93, 48: 5, 49: 459, 51: 270, 53: 6773}, 12: {0: 1, 1: 974, 2: 246, 3: 32, 4: 1977, 5: 1, 6: 3209, 8: 4360, 9: 133, 10: 83, 12: 860, 13: 746, 14: 8, 17: 2, 18: 3648, 19: 1, 20: 2, 21: 31, 22: 22, 23: 18, 24: 10, 25: 1, 26: 74, 27: 139, 28: 5077, 29: 4354, 30: 964, 32: 41, 33: 361, 34: 1, 35: 339, 37: 1, 38: 6, 39: 576, 40: 11605}, 13: {0: 2180, 1: 1, 2: 18, 3: 169, 4: 1052, 5: 7970, 6: 150, 7: 2549, 8: 5, 9: 72, 10: 1143, 12: 1, 13: 698, 14: 315, 15: 1887, 16: 18, 17: 1, 18: 240, 19: 9, 20: 7, 21: 64, 22: 1433, 24: 1, 25: 3, 26: 7, 27: 46, 28: 454, 29: 948, 30: 8, 32: 1451, 33: 15, 34: 270, 35: 36, 36: 238, 39: 668, 40: 1130, 41: 1, 43: 479, 45: 94, 46: 123, 47: 7, 48: 51, 49: 8, 50: 29, 52: 50, 53: 82, 55: 98, 56: 1312, 57: 2114, 58: 2633, 59: 1167, 61: 2629}, 14: {0: 3643, 1: 1370, 2: 153, 3: 50, 4: 11, 5: 763, 6: 2655, 7: 38, 8: 12951, 9: 6, 10: 1504, 11: 361, 12: 233, 13: 1273, 15: 13, 17: 47, 18: 31, 20: 55, 21: 530, 22: 916, 23: 5502, 24: 1004, 25: 97, 26: 130, 27: 103, 29: 66, 30: 278, 31: 250, 32: 163, 34: 434, 35: 272}, 15: {0: 45, 1: 1063, 2: 8, 3: 1903, 4: 1187, 6: 19, 8: 294, 9: 9, 10: 1, 11: 50, 12: 1460, 13: 53, 14: 210, 15: 2703, 16: 3, 17: 1, 18: 280, 19: 290, 20: 76, 22: 220, 23: 420, 24: 280, 25: 1, 26: 680, 27: 78, 28: 263, 29: 4, 30: 6, 31: 1285, 34: 47, 35: 724, 36: 16, 37: 1729, 38: 19, 40: 1, 42: 7, 43: 868, 44: 16, 45: 82, 47: 3425, 48: 1138, 50: 17, 51: 184, 53: 54, 54: 1549, 55: 272, 56: 7, 57: 793, 58: 35, 60: 687, 61: 1}, 16: {0: 1138, 1: 6, 2: 2238, 3: 134, 4: 2262, 5: 1082, 6: 3863, 8: 4015, 9: 338, 10: 52, 11: 1012, 12: 1598, 13: 3, 14: 135, 15: 862, 16: 612, 17: 10, 18: 79, 19: 91, 20: 32, 21: 61, 22: 3168, 23: 52, 24: 6264, 26: 37, 27: 470, 30: 2681, 31: 1465, 32: 136, 33: 113, 34: 8, 35: 1, 36: 1, 38: 14, 40: 8, 41: 45, 42: 433, 43: 178, 44: 205}, 17: {1: 6, 2: 10, 3: 1108, 4: 32, 5: 18, 6: 2, 7: 3, 8: 2, 9: 88, 10: 5, 11: 13, 12: 3122, 14: 788, 15: 55, 16: 27, 17: 15, 18: 78, 20: 613, 22: 36, 23: 1317, 24: 73, 25: 25, 27: 677, 28: 9, 29: 48, 30: 1907, 32: 866, 33: 88, 34: 4, 36: 598, 37: 106, 38: 33, 39: 3, 40: 200, 41: 51, 42: 229, 43: 2184, 44: 1, 45: 308, 46: 1, 47: 150, 48: 583, 49: 1175, 50: 343, 51: 14, 52: 311, 53: 2, 54: 291, 55: 313, 56: 1042, 57: 3, 58: 16, 59: 43, 60: 1674, 61: 10}, 18: {1: 6527, 3: 18104, 4: 14, 8: 65, 9: 782, 12: 74, 13: 182, 14: 2498, 15: 119, 16: 21, 18: 1, 20: 23, 21: 11, 22: 394, 23: 43, 24: 792, 25: 13, 26: 381, 28: 412, 29: 184, 30: 2417, 31: 941, 32: 90, 34: 30, 35: 426, 36: 7548}, 19: {0: 1, 1: 4, 2: 1903, 3: 4087, 4: 115, 5: 6976, 6: 292, 7: 1, 8: 1590, 9: 1467, 10: 1329, 11: 98, 12: 1, 13: 20, 14: 2, 15: 639, 16: 50, 17: 1381, 18: 3591, 19: 1, 20: 1, 21: 5, 22: 90, 23: 1, 24: 1191, 25: 2606, 26: 5, 27: 20, 28: 7364, 29: 82, 30: 1, 33: 1, 35: 1, 38: 1, 40: 1, 42: 1, 43: 1, 45: 1, 49: 1, 50: 1, 54: 1, 55: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35393
INFO:root:client_idx = 0, batch_num_train_local = 553, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35323
INFO:root:client_idx = 1, batch_num_train_local = 551, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35785
INFO:root:client_idx = 2, batch_num_train_local = 559, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 38092
INFO:root:client_idx = 3, batch_num_train_local = 595, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35901
INFO:root:client_idx = 4, batch_num_train_local = 560, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 37179
INFO:root:client_idx = 5, batch_num_train_local = 580, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 35027
INFO:root:client_idx = 6, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36393
INFO:root:client_idx = 7, batch_num_train_local = 568, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 41531
INFO:root:client_idx = 8, batch_num_train_local = 648, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 19374
INFO:root:client_idx = 9, batch_num_train_local = 302, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 41180
INFO:root:client_idx = 10, batch_num_train_local = 643, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 38614
INFO:root:client_idx = 11, batch_num_train_local = 603, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 39903
INFO:root:client_idx = 12, batch_num_train_local = 623, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 36134
INFO:root:client_idx = 13, batch_num_train_local = 564, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34902
INFO:root:client_idx = 14, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 24563
INFO:root:client_idx = 15, batch_num_train_local = 383, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 34902
INFO:root:client_idx = 16, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 20719
INFO:root:client_idx = 17, batch_num_train_local = 323, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 42092
INFO:root:client_idx = 18, batch_num_train_local = 657, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 34925
INFO:root:client_idx = 19, batch_num_train_local = 545, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 697932
INFO:root:traindata_cls_counts = {0: {0: 2218, 1: 2153, 2: 3833, 3: 1055, 4: 574, 5: 356, 6: 571, 7: 7549, 8: 919, 9: 4299, 10: 78, 11: 6, 12: 28, 13: 1, 14: 96, 15: 592, 16: 23, 17: 49, 18: 435, 19: 121, 20: 31, 21: 738, 22: 69, 23: 130, 24: 866, 25: 953, 27: 21, 28: 1685, 29: 504, 30: 324, 31: 701, 32: 7, 33: 229, 34: 7, 35: 102, 36: 327, 37: 265, 38: 250, 39: 2585, 40: 324}, 1: {0: 47, 1: 52, 2: 2697, 3: 238, 4: 28, 5: 21, 6: 12629, 7: 2573, 8: 918, 9: 3376, 10: 217, 11: 3, 12: 296, 13: 51, 14: 244, 15: 74, 16: 364, 17: 37, 18: 384, 19: 474, 20: 207, 21: 7, 23: 546, 24: 337, 25: 27, 27: 125, 28: 1514, 29: 447, 30: 194, 31: 67, 32: 15, 33: 16, 34: 446, 35: 177, 36: 279, 37: 275, 38: 203, 39: 274, 40: 2, 41: 3, 42: 130, 43: 627, 44: 107, 46: 696, 47: 149, 48: 521, 49: 1246, 50: 1057, 51: 757}, 2: {0: 6024, 1: 731, 2: 54, 3: 331, 4: 3899, 5: 2775, 6: 1082, 7: 1012, 8: 340, 9: 140, 10: 95, 11: 95, 13: 396, 15: 2040, 16: 132, 17: 11, 18: 681, 19: 11, 20: 154, 21: 7, 22: 2145, 23: 803, 24: 297, 25: 1969, 26: 102, 27: 254, 28: 559, 29: 330, 30: 924, 31: 12, 32: 21, 33: 25, 34: 40, 35: 27, 36: 115, 37: 223, 38: 2, 39: 50, 40: 35, 41: 372, 42: 16, 43: 259, 44: 11, 46: 14, 47: 3938, 48: 9, 49: 7, 50: 89, 51: 57, 52: 443, 53: 112, 54: 187, 55: 2051}, 3: {0: 1154, 1: 6755, 2: 1985, 3: 915, 4: 289, 5: 5120, 6: 385, 7: 2250, 8: 173, 9: 104, 10: 1878, 11: 534, 12: 43, 13: 1281, 14: 20, 15: 145, 16: 34, 17: 37, 18: 12, 19: 415, 20: 204, 21: 8, 22: 35, 23: 994, 24: 3654, 25: 165, 26: 157, 27: 581, 28: 1910, 29: 26, 30: 122, 31: 899, 32: 4, 33: 254, 34: 51, 35: 9, 36: 470, 37: 204, 38: 1, 39: 474, 40: 232, 41: 71, 42: 334, 43: 818}, 4: {0: 4801, 1: 4936, 2: 5772, 3: 1830, 4: 1071, 5: 1196, 6: 265, 7: 191, 8: 5500, 9: 232, 10: 7, 11: 498, 12: 284, 13: 116, 14: 248, 15: 262, 16: 9, 17: 115, 18: 264, 19: 95, 20: 158, 21: 147, 23: 1162, 24: 283, 25: 706, 28: 1948, 29: 1391, 30: 594, 31: 132, 32: 279, 33: 688}, 5: {0: 3415, 1: 52, 2: 1312, 3: 23, 4: 453, 5: 2506, 6: 1404, 7: 11264, 8: 634, 9: 2802, 10: 27, 11: 11, 12: 7, 13: 80, 14: 1, 15: 12, 16: 173, 17: 4, 18: 3510, 19: 221, 20: 36, 21: 2, 22: 36, 23: 254, 24: 265, 25: 813, 26: 401, 27: 2, 28: 496, 29: 327, 30: 1276, 31: 5, 32: 108, 33: 115, 34: 1058, 35: 1, 36: 490, 37: 843, 38: 3, 39: 6, 40: 748}, 6: {0: 5929, 1: 108, 2: 1321, 3: 4, 4: 5372, 5: 1100, 6: 387, 7: 36, 8: 122, 9: 5215, 10: 259, 11: 651, 12: 1, 13: 64, 14: 346, 15: 92, 16: 201, 17: 44, 18: 1325, 19: 302, 20: 9, 21: 22, 22: 27, 23: 92, 24: 995, 25: 3, 26: 20, 27: 568, 28: 3553, 29: 275, 30: 1022, 31: 73, 32: 1473, 33: 315, 34: 184, 35: 337, 36: 306, 37: 346, 38: 751, 39: 140, 40: 876, 41: 565, 42: 124}, 7: {0: 352, 1: 9951, 2: 685, 3: 1059, 4: 2668, 5: 3, 6: 45, 7: 979, 8: 451, 9: 793, 10: 16, 11: 2, 12: 749, 15: 470, 16: 17, 17: 848, 18: 13, 19: 35, 20: 86, 21: 73, 23: 119, 24: 3484, 25: 673, 26: 327, 27: 60, 28: 637, 29: 241, 30: 399, 31: 108, 33: 63, 34: 514, 35: 293, 36: 310, 37: 2, 38: 2, 39: 458, 40: 1926, 41: 128, 42: 126, 43: 431, 44: 4, 45: 64, 46: 81, 47: 8, 49: 7213}, 8: {0: 172, 1: 29, 2: 117, 3: 1861, 4: 456, 5: 796, 6: 747, 7: 115, 8: 542, 9: 618, 10: 812, 11: 8, 12: 242, 13: 85, 14: 214, 15: 235, 16: 271, 17: 36, 18: 534, 19: 23, 20: 248, 21: 165, 22: 179, 23: 4, 24: 118, 25: 596, 26: 60, 27: 198, 28: 236, 29: 61, 30: 865, 31: 462, 32: 49, 33: 134, 34: 605, 35: 206, 36: 59, 37: 19, 38: 4, 39: 489, 40: 296, 41: 12, 42: 992, 43: 994, 44: 8, 45: 378, 46: 15, 47: 55, 48: 9, 49: 374, 50: 645, 51: 23, 52: 1202, 53: 4565, 54: 561, 55: 5800, 56: 60, 57: 180, 58: 542, 59: 694, 60: 540, 61: 2046}, 9: {0: 2186, 1: 337, 2: 38, 3: 3065, 4: 36, 5: 2964, 6: 152, 7: 1370, 8: 506, 9: 233, 10: 2, 11: 2, 13: 84, 14: 150, 15: 535, 16: 23, 17: 390, 18: 802, 19: 23, 20: 67, 21: 180, 22: 1969, 23: 68, 24: 2100, 25: 1, 26: 7, 27: 301, 28: 1, 29: 51, 30: 113, 31: 28, 32: 139, 33: 17, 34: 584, 36: 43, 38: 6, 39: 1794, 40: 1624, 41: 18, 42: 7, 43: 1805, 44: 37, 45: 582, 46: 56, 47: 7289, 48: 540, 49: 218, 50: 35, 51: 22, 52: 197, 53: 2356}, 10: {0: 671, 1: 279, 2: 382, 3: 931, 4: 93, 5: 5414, 6: 2123, 7: 1078, 8: 3258, 9: 269, 10: 774, 11: 672, 12: 203, 13: 126, 14: 66, 15: 283, 16: 458, 17: 37, 18: 298, 19: 90, 20: 31, 21: 534, 22: 1426, 23: 188, 24: 3233, 25: 517, 26: 17, 27: 242, 28: 733, 29: 195, 31: 48, 32: 130, 34: 12, 35: 103, 36: 1046, 37: 432, 38: 251, 39: 22, 40: 547, 41: 56, 42: 425, 43: 232, 44: 14, 45: 21, 46: 322, 47: 328, 48: 9, 49: 32, 50: 139, 51: 370, 52: 373, 53: 144, 54: 173, 55: 14, 56: 220, 57: 160, 58: 262, 59: 1, 60: 764, 61: 23}, 11: {0: 73, 1: 2062, 2: 173, 3: 267, 4: 3294, 5: 984, 6: 3421, 7: 24, 8: 131, 9: 1153, 10: 355, 11: 641, 12: 1390, 13: 298, 14: 622, 15: 14, 17: 25, 18: 737, 19: 2, 20: 47, 21: 9, 22: 505, 23: 164, 24: 2403, 25: 10, 26: 155, 27: 143, 28: 4710, 29: 373, 30: 925, 31: 356, 32: 425, 33: 385, 34: 65, 35: 42, 37: 863, 38: 7, 39: 24, 40: 6289, 41: 226, 42: 8, 43: 203, 44: 656, 45: 147, 46: 106}, 12: {0: 2168, 1: 244, 2: 318, 3: 322, 4: 2269, 5: 11, 6: 670, 7: 3610, 8: 7191, 9: 673, 10: 1, 11: 32, 12: 875, 13: 284, 14: 323, 15: 202, 16: 64, 17: 124, 18: 316, 19: 305, 20: 121, 21: 2040, 22: 218, 23: 123, 24: 2, 26: 415, 27: 207, 28: 927, 29: 2857, 30: 58, 31: 254, 32: 153, 33: 65, 34: 331, 35: 280, 36: 435, 37: 153, 38: 365, 39: 48, 40: 1083, 41: 278, 42: 363, 43: 297, 44: 18, 45: 273, 46: 6, 47: 250, 48: 7, 49: 185, 51: 263, 52: 49, 53: 519, 54: 585, 55: 1212, 56: 1024}, 13: {0: 3141, 1: 1113, 2: 755, 3: 2001, 4: 337, 5: 2605, 6: 2929, 7: 500, 8: 707, 9: 1682, 10: 37, 11: 257, 12: 26, 13: 448, 14: 13, 15: 31, 17: 24, 18: 793, 19: 471, 20: 147, 21: 266, 22: 735, 23: 885, 24: 447, 25: 56, 26: 44, 27: 180, 28: 5, 29: 947, 30: 819, 31: 1, 32: 302, 33: 10, 34: 24, 35: 63, 36: 42, 37: 141, 38: 185, 39: 689, 40: 118, 41: 32, 42: 69, 43: 32, 44: 54, 46: 145, 47: 374, 48: 53, 49: 625, 50: 88, 51: 15, 52: 398, 53: 375, 54: 130, 55: 3362, 56: 574, 57: 274, 58: 241, 59: 624, 60: 710, 61: 56}, 14: {0: 381, 1: 4842, 2: 231, 3: 1338, 4: 2423, 5: 74, 6: 294, 7: 6, 8: 3049, 9: 2373, 10: 431, 11: 89, 12: 364, 13: 1, 14: 257, 15: 113, 16: 31, 17: 75, 18: 459, 19: 240, 20: 90, 21: 650, 22: 318, 23: 365, 24: 1676, 25: 71, 26: 148, 27: 552, 28: 723, 29: 5, 30: 101, 31: 6, 32: 9, 33: 19, 34: 259, 35: 239, 36: 743, 37: 124, 38: 3, 39: 2848, 40: 98, 41: 8, 42: 321, 43: 52, 44: 53, 46: 12, 47: 500, 48: 3, 49: 10, 50: 70, 51: 49, 52: 16, 53: 2032, 54: 483, 55: 1537, 56: 783, 57: 46, 58: 1235, 59: 1254, 60: 285, 61: 1}, 15: {0: 1489, 1: 319, 2: 2811, 3: 9491, 4: 3610, 5: 1452, 6: 3970, 7: 39, 8: 91, 9: 387, 10: 11, 11: 235, 12: 425, 14: 204, 15: 2449, 16: 474, 17: 5, 18: 458, 19: 172, 20: 678, 21: 2, 22: 490, 23: 297, 24: 683, 25: 655, 26: 436, 27: 734, 28: 5, 29: 299, 30: 87, 31: 182, 32: 273, 33: 166, 34: 354, 35: 470, 36: 4477}, 16: {0: 1, 1: 3151, 2: 250, 3: 3603, 4: 373, 5: 50, 6: 110, 7: 196, 8: 1575, 9: 2575, 10: 22, 11: 87, 12: 1315, 13: 12, 14: 634, 15: 1150, 16: 76, 17: 1243, 18: 67, 19: 587, 20: 19, 21: 22, 22: 620, 23: 1069, 24: 3149, 25: 75, 26: 2, 27: 1, 28: 191, 29: 1, 30: 1778, 31: 620, 32: 1034, 33: 144, 34: 112, 35: 16, 36: 77, 38: 599, 39: 143, 40: 3306, 41: 724, 42: 403, 43: 956, 44: 1103, 45: 317, 46: 511, 48: 122, 49: 81, 50: 2, 51: 78, 52: 296, 53: 198, 54: 185}, 17: {0: 45, 1: 37, 3: 2580, 4: 869, 5: 1794, 6: 60, 7: 4, 8: 500, 9: 296, 10: 1257, 11: 4, 12: 1405, 13: 735, 14: 1459, 15: 198, 16: 69, 17: 28, 18: 686, 19: 8, 20: 119, 21: 154, 22: 207, 23: 307, 24: 413, 25: 1052, 26: 277, 27: 529, 28: 885, 29: 312, 30: 1359, 31: 678, 32: 218, 33: 2, 34: 56, 35: 5, 36: 144, 37: 540, 38: 210, 40: 7116, 41: 1, 42: 182, 43: 350, 44: 192, 45: 95, 46: 13, 47: 216, 48: 1242, 49: 1424, 50: 612, 51: 807, 52: 19, 53: 1306, 54: 29, 55: 4197}, 18: {0: 64, 1: 1133, 2: 2516, 3: 466, 4: 1048, 5: 46, 6: 874, 7: 38, 8: 2993, 9: 1135, 10: 57, 11: 33, 12: 2226, 13: 99, 14: 37, 15: 284, 16: 97, 17: 20, 18: 172, 19: 167, 20: 16, 21: 49, 22: 23, 23: 667, 24: 577, 25: 5, 26: 37, 27: 375, 28: 45, 29: 1178, 30: 1642, 31: 5, 32: 56, 33: 124, 34: 41, 35: 331, 36: 669, 37: 729, 38: 12, 39: 133, 40: 11, 41: 67, 42: 186, 43: 1681, 44: 468, 45: 19, 46: 513, 47: 2211, 48: 130, 49: 3, 50: 12, 51: 6, 52: 1, 53: 2497, 54: 365, 55: 89, 56: 168, 57: 2250, 58: 417, 59: 249, 60: 66, 61: 599}, 19: {0: 254, 1: 90, 2: 8953, 3: 3763, 4: 4373, 5: 2149, 6: 2114, 7: 2920, 8: 4346, 9: 5492, 10: 71, 11: 18, 12: 215, 13: 401, 15: 1, 16: 1, 21: 1, 24: 1, 28: 1, 36: 1, 42: 1, 43: 1, 46: 1, 51: 1, 53: 1, 54: 1, 56: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 35074
INFO:root:client_idx = 0, batch_num_train_local = 548, batch_num_test_local = 1817
INFO:root:client_idx = 1, local_sample_number = 35174
INFO:root:client_idx = 1, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 2, local_sample_number = 35508
INFO:root:client_idx = 2, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 3, local_sample_number = 35206
INFO:root:client_idx = 3, batch_num_train_local = 550, batch_num_test_local = 1817
INFO:root:client_idx = 4, local_sample_number = 35180
INFO:root:client_idx = 4, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 5, local_sample_number = 35196
INFO:root:client_idx = 5, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 6, local_sample_number = 34955
INFO:root:client_idx = 6, batch_num_train_local = 546, batch_num_test_local = 1817
INFO:root:client_idx = 7, local_sample_number = 36966
INFO:root:client_idx = 7, batch_num_train_local = 577, batch_num_test_local = 1817
INFO:root:client_idx = 8, local_sample_number = 32661
INFO:root:client_idx = 8, batch_num_train_local = 510, batch_num_test_local = 1817
INFO:root:client_idx = 9, local_sample_number = 35153
INFO:root:client_idx = 9, batch_num_train_local = 549, batch_num_test_local = 1817
INFO:root:client_idx = 10, local_sample_number = 31294
INFO:root:client_idx = 10, batch_num_train_local = 488, batch_num_test_local = 1817
INFO:root:client_idx = 11, local_sample_number = 34912
INFO:root:client_idx = 11, batch_num_train_local = 545, batch_num_test_local = 1817
INFO:root:client_idx = 12, local_sample_number = 35466
INFO:root:client_idx = 12, batch_num_train_local = 554, batch_num_test_local = 1817
INFO:root:client_idx = 13, local_sample_number = 32207
INFO:root:client_idx = 13, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 14, local_sample_number = 34868
INFO:root:client_idx = 14, batch_num_train_local = 544, batch_num_test_local = 1817
INFO:root:client_idx = 15, local_sample_number = 38380
INFO:root:client_idx = 15, batch_num_train_local = 599, batch_num_test_local = 1817
INFO:root:client_idx = 16, local_sample_number = 35031
INFO:root:client_idx = 16, batch_num_train_local = 547, batch_num_test_local = 1817
INFO:root:client_idx = 17, local_sample_number = 37302
INFO:root:client_idx = 17, batch_num_train_local = 582, batch_num_test_local = 1817
INFO:root:client_idx = 18, local_sample_number = 32227
INFO:root:client_idx = 18, batch_num_train_local = 503, batch_num_test_local = 1817
INFO:root:client_idx = 19, local_sample_number = 35172
INFO:root:client_idx = 19, batch_num_train_local = 549, batch_num_test_local = 1817
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
1
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/listu/yiqin/FedBench/main.py", line 140, in run_clients
    return client.run(received_info)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 37, in run
    weights = self.train()
  File "/home/listu/yiqin/FedBench/methods/base.py", line 57, in train
    log_probs = self.model(images)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/yiqin/FedBench/models/resnet.py", line 183, in forward
    x = self.conv1(x)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/listu/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 283, in <module>
    client_outputs = pool.map(run_clients, server_outputs)
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/listu/miniconda3/envs/pfsn/lib/python3.8/multiprocessing/pool.py", line 771, in get
    raise self._value
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {2: 109, 3: 1, 8: 7, 9: 487}, 1: {0: 1412, 1: 2433, 2: 77, 3: 1151, 4: 2259, 5: 9, 7: 5999}, 2: {1: 227, 2: 5559, 3: 475, 4: 3740, 6: 5574}, 3: {1: 2, 2: 255, 3: 801, 5: 132, 6: 426, 7: 1, 8: 5993, 9: 5513}, 4: {0: 4588, 1: 3338, 3: 3572, 4: 1, 5: 5859}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 604
INFO:root:client_idx = 0, batch_num_train_local = 9, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13340
INFO:root:client_idx = 1, batch_num_train_local = 208, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 15575
INFO:root:client_idx = 2, batch_num_train_local = 243, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 13123
INFO:root:client_idx = 3, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 17358
INFO:root:client_idx = 4, batch_num_train_local = 271, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.027041  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 18.23 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.571737  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.636642  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.207238  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.411888  Thread 5  Map [4]
INFO:root:************* Client 1 Acc = 89.08 **************
INFO:root:************* Client 3 Acc = 93.57 **************
INFO:root:************* Client 2 Acc = 59.24 **************
INFO:root:************* Client 4 Acc = 90.62 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 49.20341229438782s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.173252  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 17.01 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.447480  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.383176  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.063439  Thread 3  Map [2]
INFO:root:************* Client 3 Acc = 92.78 **************
INFO:root:************* Client 1 Acc = 91.44 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.284627  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 63.39 **************
INFO:root:************* Client 4 Acc = 93.70 **************
INFO:root:************* Server Acc = 10.02 **************
INFO:root:Round 1 Time: 42.74730920791626s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.786545  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.97 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.264250  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.289812  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.913333  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.226536  Thread 5  Map [4]
INFO:root:************* Client 3 Acc = 94.77 **************
INFO:root:************* Client 1 Acc = 93.52 **************
INFO:root:************* Client 2 Acc = 70.40 **************
INFO:root:************* Client 4 Acc = 82.26 **************
INFO:root:************* Server Acc = 12.67 **************
INFO:root:Round 2 Time: 41.27843189239502s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.651624  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.66 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.226244  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.239953  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.800532  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.178046  Thread 5  Map [4]
INFO:root:************* Client 3 Acc = 95.79 **************
INFO:root:************* Client 1 Acc = 94.52 **************
INFO:root:************* Client 2 Acc = 72.67 **************
INFO:root:************* Client 4 Acc = 95.57 **************
INFO:root:************* Server Acc = 36.56 **************
INFO:root:Round 3 Time: 40.75177454948425s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.474494  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.178558  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.184452  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.682104  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.163114  Thread 5  Map [4]
INFO:root:************* Client 3 Acc = 96.57 **************
INFO:root:************* Client 1 Acc = 94.83 **************
INFO:root:************* Client 2 Acc = 73.55 **************
INFO:root:************* Client 4 Acc = 96.22 **************
INFO:root:************* Server Acc = 45.45 **************
INFO:root:Round 4 Time: 42.124510526657104s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.590302  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.169765  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.204685  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.620600  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.123678  Thread 5  Map [4]
INFO:root:************* Client 3 Acc = 96.87 **************
INFO:root:************* Client 1 Acc = 96.03 **************
INFO:root:************* Client 2 Acc = 78.99 **************
INFO:root:************* Client 4 Acc = 95.65 **************
INFO:root:************* Server Acc = 45.33 **************
INFO:root:Round 5 Time: 40.90859317779541s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.460947  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.27 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.132267  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.147310  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 97.07 **************
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.571218  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.120917  Thread 5  Map [4]
INFO:root:************* Client 1 Acc = 96.21 **************
INFO:root:************* Client 2 Acc = 82.43 **************
INFO:root:************* Client 4 Acc = 97.19 **************
INFO:root:************* Server Acc = 48.92 **************
INFO:root:Round 6 Time: 43.013840198516846s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.548738  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 91.49 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.143059  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.155532  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.531011  Thread 3  Map [2]
INFO:root:************* Client 3 Acc = 97.13 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.102655  Thread 5  Map [4]
INFO:root:************* Client 1 Acc = 95.80 **************
INFO:root:************* Client 2 Acc = 80.31 **************
INFO:root:************* Client 4 Acc = 96.85 **************
INFO:root:************* Server Acc = 55.91 **************
INFO:root:Round 7 Time: 41.83114194869995s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.295989  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.109689  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.125900  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.495636  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.105340  Thread 5  Map [4]
INFO:root:************* Client 3 Acc = 97.55 **************
INFO:root:************* Client 1 Acc = 96.93 **************
INFO:root:************* Client 2 Acc = 80.96 **************
INFO:root:************* Client 4 Acc = 96.04 **************
INFO:root:************* Server Acc = 57.61 **************
INFO:root:Round 8 Time: 39.354710817337036s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.444849  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 93.58 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.144061  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.121306  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492321  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.090063  Thread 5  Map [4]
INFO:root:************* Client 1 Acc = 97.22 **************
INFO:root:************* Client 3 Acc = 97.88 **************
INFO:root:************* Client 2 Acc = 79.87 **************
INFO:root:************* Client 4 Acc = 95.84 **************
INFO:root:************* Server Acc = 66.20 **************
INFO:root:Round 9 Time: 39.82884478569031s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 9, 1: 1, 2: 572, 3: 39, 5: 2, 6: 20, 7: 45, 9: 941}, 1: {0: 2137, 1: 145, 2: 477, 3: 1160, 4: 2317, 5: 150, 7: 4084, 8: 5756}, 2: {0: 3, 1: 14, 2: 4079, 3: 690, 4: 3675, 5: 23, 6: 4697}, 3: {1: 554, 2: 871, 3: 914, 4: 8, 5: 5825, 6: 1283, 7: 1871, 8: 244, 9: 5059}, 4: {0: 3851, 1: 5286, 2: 1, 3: 3197}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 1629
INFO:root:client_idx = 0, batch_num_train_local = 25, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 16226
INFO:root:client_idx = 1, batch_num_train_local = 253, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 13181
INFO:root:client_idx = 2, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 16629
INFO:root:client_idx = 3, batch_num_train_local = 259, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12335
INFO:root:client_idx = 4, batch_num_train_local = 192, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.191621  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 77.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.594129  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.246425  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.704411  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.764663  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 87.79 **************
INFO:root:************* Client 2 Acc = 49.63 **************
INFO:root:************* Client 1 Acc = 87.93 **************
INFO:root:************* Client 3 Acc = 83.83 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 49.23647904396057s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.783890  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 84.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.416758  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.097392  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.481796  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.549579  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 90.31 **************
INFO:root:************* Client 2 Acc = 51.41 **************
INFO:root:************* Client 1 Acc = 89.10 **************
INFO:root:************* Client 3 Acc = 85.49 **************
INFO:root:************* Server Acc = 18.81 **************
INFO:root:Round 1 Time: 39.88437080383301s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.468395  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.299670  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.969713  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.374758  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.415851  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 89.55 **************
INFO:root:************* Client 2 Acc = 61.58 **************
INFO:root:************* Client 1 Acc = 86.94 **************
INFO:root:************* Client 3 Acc = 87.29 **************
INFO:root:************* Server Acc = 19.45 **************
INFO:root:Round 2 Time: 40.85073113441467s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.454775  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.251850  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.892320  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.348528  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.311031  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 84.30 **************
INFO:root:************* Client 2 Acc = 71.62 **************
INFO:root:************* Client 3 Acc = 81.66 **************
INFO:root:************* Client 1 Acc = 91.78 **************
INFO:root:************* Server Acc = 38.08 **************
INFO:root:Round 3 Time: 39.6221079826355s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.410940  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.211652  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.798560  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.311323  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 93.42 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.260912  Thread 2  Map [1]
INFO:root:************* Client 2 Acc = 53.44 **************
INFO:root:************* Client 3 Acc = 88.75 **************
INFO:root:************* Client 1 Acc = 92.83 **************
INFO:root:************* Server Acc = 56.50 **************
INFO:root:Round 4 Time: 40.86129570007324s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.321703  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.179693  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.724975  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.243230  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.274511  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 95.54 **************
INFO:root:************* Client 2 Acc = 77.23 **************
INFO:root:************* Client 1 Acc = 93.31 **************
INFO:root:************* Client 3 Acc = 90.86 **************
INFO:root:************* Server Acc = 63.41 **************
INFO:root:Round 5 Time: 39.49790906906128s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.289231  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.175810  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.653504  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.207697  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.248916  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 95.08 **************
INFO:root:************* Client 2 Acc = 67.57 **************
INFO:root:************* Client 1 Acc = 93.35 **************
INFO:root:************* Client 3 Acc = 92.10 **************
INFO:root:************* Server Acc = 66.77 **************
INFO:root:Round 6 Time: 39.01625370979309s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.288333  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.156545  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.621437  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.229942  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.195398  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 95.39 **************
INFO:root:************* Client 2 Acc = 80.28 **************
INFO:root:************* Client 1 Acc = 93.52 **************
INFO:root:************* Client 3 Acc = 92.59 **************
INFO:root:************* Server Acc = 68.42 **************
INFO:root:Round 7 Time: 39.85795831680298s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.301378  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.145729  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.594954  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.187767  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.216074  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 94.62 **************
INFO:root:************* Client 2 Acc = 80.05 **************
INFO:root:************* Client 1 Acc = 94.87 **************
INFO:root:************* Client 3 Acc = 93.90 **************
INFO:root:************* Server Acc = 76.68 **************
INFO:root:Round 8 Time: 40.54491114616394s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.204091  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.128206  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.552115  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.203820  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 91.25 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.169568  Thread 2  Map [1]
INFO:root:************* Client 2 Acc = 81.65 **************
INFO:root:************* Client 3 Acc = 93.32 **************
INFO:root:************* Client 1 Acc = 95.49 **************
INFO:root:************* Server Acc = 75.26 **************
INFO:root:Round 9 Time: 39.85035490989685s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 278, 1: 188, 2: 941, 3: 1325, 4: 27, 5: 100, 6: 255, 7: 2869, 8: 1, 9: 3810}, 1: {0: 2413, 1: 2049, 2: 871, 3: 875, 4: 2454, 5: 505, 6: 2, 7: 90, 8: 4385}, 2: {0: 184, 1: 1069, 2: 3042, 3: 1099, 4: 3339, 5: 239, 6: 3459}, 3: {0: 51, 1: 410, 2: 1144, 3: 2700, 4: 118, 5: 4895, 6: 1431, 7: 261, 8: 1093}, 4: {0: 3074, 1: 2284, 2: 2, 3: 1, 4: 62, 5: 261, 6: 853, 7: 2780, 8: 521, 9: 2190}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 9794
INFO:root:client_idx = 0, batch_num_train_local = 153, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13644
INFO:root:client_idx = 1, batch_num_train_local = 213, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 12431
INFO:root:client_idx = 2, batch_num_train_local = 194, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 12103
INFO:root:client_idx = 3, batch_num_train_local = 189, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12028
INFO:root:client_idx = 4, batch_num_train_local = 187, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.940690  Thread 2  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.851776  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.810694  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.367861  Thread 3  Map [2]
INFO:root:************* Client 0 Acc = 80.85 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.913731  Thread 1  Map [1]
INFO:root:************* Client 3 Acc = 79.37 **************
INFO:root:************* Client 4 Acc = 81.18 **************
INFO:root:************* Client 2 Acc = 52.41 **************
INFO:root:************* Client 1 Acc = 76.04 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 47.58704614639282s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.663530  Thread 2  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.560051  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.143773  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.625484  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.625904  Thread 1  Map [1]
INFO:root:************* Client 0 Acc = 83.05 **************
INFO:root:************* Client 4 Acc = 80.41 **************
INFO:root:************* Client 3 Acc = 80.62 **************
INFO:root:************* Client 2 Acc = 65.49 **************
INFO:root:************* Client 1 Acc = 83.27 **************
INFO:root:************* Server Acc = 24.41 **************
INFO:root:Round 1 Time: 37.0721869468689s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.477000  Thread 2  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.489976  Thread 4  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.443221  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.999504  Thread 3  Map [2]
INFO:root:************* Client 0 Acc = 86.81 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.483020  Thread 1  Map [1]
INFO:root:************* Client 3 Acc = 80.63 **************
INFO:root:************* Client 4 Acc = 89.62 **************
INFO:root:************* Client 2 Acc = 67.19 **************
INFO:root:************* Client 1 Acc = 82.20 **************
INFO:root:************* Server Acc = 24.67 **************
INFO:root:Round 2 Time: 38.35343790054321s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.395518  Thread 2  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.426154  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.868297  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.358333  Thread 5  Map [4]
INFO:root:************* Client 0 Acc = 77.82 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.403364  Thread 1  Map [1]
INFO:root:************* Client 3 Acc = 86.87 **************
INFO:root:************* Client 2 Acc = 72.54 **************
INFO:root:************* Client 4 Acc = 89.82 **************
INFO:root:************* Client 1 Acc = 86.86 **************
INFO:root:************* Server Acc = 38.30 **************
INFO:root:Round 3 Time: 38.93092370033264s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.355440  Thread 2  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.367157  Thread 4  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.309163  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.807585  Thread 3  Map [2]
INFO:root:************* Client 0 Acc = 88.52 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.363801  Thread 1  Map [1]
INFO:root:************* Client 3 Acc = 86.59 **************
INFO:root:************* Client 4 Acc = 89.94 **************
INFO:root:************* Client 2 Acc = 70.73 **************
INFO:root:************* Client 1 Acc = 89.02 **************
INFO:root:************* Server Acc = 60.31 **************
INFO:root:Round 4 Time: 38.99720811843872s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.321807  Thread 2  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.346671  Thread 4  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.285820  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.767353  Thread 3  Map [2]
INFO:root:************* Client 0 Acc = 91.45 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.326599  Thread 1  Map [1]
INFO:root:************* Client 3 Acc = 88.35 **************
INFO:root:************* Client 4 Acc = 91.18 **************
INFO:root:************* Client 2 Acc = 72.02 **************
INFO:root:************* Client 1 Acc = 89.34 **************
INFO:root:************* Server Acc = 67.86 **************
INFO:root:Round 5 Time: 38.44963836669922s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.308679  Thread 2  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.308459  Thread 4  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.265160  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.720298  Thread 3  Map [2]
INFO:root:************* Client 0 Acc = 91.57 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.304114  Thread 1  Map [1]
INFO:root:************* Client 3 Acc = 90.52 **************
INFO:root:************* Client 4 Acc = 91.99 **************
INFO:root:************* Client 2 Acc = 68.19 **************
INFO:root:************* Client 1 Acc = 89.03 **************
INFO:root:************* Server Acc = 75.70 **************
INFO:root:Round 6 Time: 37.63594937324524s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.275841  Thread 2  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.294520  Thread 4  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.255999  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.669244  Thread 3  Map [2]
INFO:root:************* Client 0 Acc = 91.57 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.287385  Thread 1  Map [1]
INFO:root:************* Client 3 Acc = 89.42 **************
INFO:root:************* Client 4 Acc = 90.42 **************
INFO:root:************* Client 2 Acc = 79.17 **************
INFO:root:************* Client 1 Acc = 91.70 **************
INFO:root:************* Server Acc = 73.27 **************
INFO:root:Round 7 Time: 37.89395833015442s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.264423  Thread 2  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.241034  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.280251  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.620883  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.274179  Thread 1  Map [1]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:************* Client 4 Acc = 93.00 **************
INFO:root:************* Client 3 Acc = 90.87 **************
INFO:root:************* Client 2 Acc = 72.34 **************
INFO:root:************* Client 1 Acc = 92.24 **************
INFO:root:************* Server Acc = 77.76 **************
INFO:root:Round 8 Time: 37.91461157798767s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.255838  Thread 2  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.231687  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.265176  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.577366  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.249642  Thread 1  Map [1]
INFO:root:************* Client 0 Acc = 91.56 **************
INFO:root:************* Client 4 Acc = 93.71 **************
INFO:root:************* Client 3 Acc = 91.96 **************
INFO:root:************* Client 2 Acc = 80.67 **************
INFO:root:************* Client 1 Acc = 91.94 **************
INFO:root:************* Server Acc = 78.52 **************
INFO:root:Round 9 Time: 37.31527376174927s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {2: 109, 3: 1, 8: 7, 9: 487}, 1: {0: 1412, 1: 2433, 2: 77, 3: 1151, 4: 2259, 5: 9, 7: 5999}, 2: {1: 227, 2: 5559, 3: 475, 4: 3740, 6: 5574}, 3: {1: 2, 2: 255, 3: 801, 5: 132, 6: 426, 7: 1, 8: 5993, 9: 5513}, 4: {0: 4588, 1: 3338, 3: 3572, 4: 1, 5: 5859}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 604
INFO:root:client_idx = 0, batch_num_train_local = 9, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13340
INFO:root:client_idx = 1, batch_num_train_local = 208, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 15575
INFO:root:client_idx = 2, batch_num_train_local = 243, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 13123
INFO:root:client_idx = 3, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 17358
INFO:root:client_idx = 4, batch_num_train_local = 271, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.027041  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 18.23 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.571737  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.636642  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.207238  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 89.08 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.411888  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 93.57 **************
INFO:root:************* Client 2 Acc = 59.24 **************
INFO:root:************* Client 4 Acc = 90.62 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 51.33188796043396s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.173252  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 17.01 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.447480  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.383176  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.063439  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.284627  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 92.78 **************
INFO:root:************* Client 1 Acc = 91.44 **************
INFO:root:************* Client 2 Acc = 63.39 **************
INFO:root:************* Client 4 Acc = 93.70 **************
INFO:root:************* Server Acc = 10.02 **************
INFO:root:Round 1 Time: 40.976706981658936s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.786545  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 94.97 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.264250  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.289812  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.913333  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.226536  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 94.77 **************
INFO:root:************* Client 1 Acc = 93.52 **************
INFO:root:************* Client 2 Acc = 70.40 **************
INFO:root:************* Client 4 Acc = 82.26 **************
INFO:root:************* Server Acc = 12.67 **************
INFO:root:Round 2 Time: 40.69474768638611s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.651624  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 95.66 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.226244  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.239953  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.800532  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.178046  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 95.79 **************
INFO:root:************* Client 1 Acc = 94.52 **************
INFO:root:************* Client 2 Acc = 72.67 **************
INFO:root:************* Client 4 Acc = 95.57 **************
INFO:root:************* Server Acc = 36.56 **************
INFO:root:Round 3 Time: 41.43708848953247s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.474494  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.178558  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.184452  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.682104  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.163114  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 96.57 **************
INFO:root:************* Client 1 Acc = 94.83 **************
INFO:root:************* Client 2 Acc = 73.55 **************
INFO:root:************* Client 4 Acc = 96.22 **************
INFO:root:************* Server Acc = 45.45 **************
INFO:root:Round 4 Time: 41.83087372779846s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.590302  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 95.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.169765  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.204685  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.620600  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 96.87 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.123678  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 96.03 **************
INFO:root:************* Client 2 Acc = 78.99 **************
INFO:root:************* Client 4 Acc = 95.65 **************
INFO:root:************* Server Acc = 45.33 **************
INFO:root:Round 5 Time: 42.39867687225342s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.460947  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 94.27 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.132267  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.147310  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.571218  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 97.07 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.120917  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 96.21 **************
INFO:root:************* Client 2 Acc = 82.43 **************
INFO:root:************* Client 4 Acc = 97.19 **************
INFO:root:************* Server Acc = 48.92 **************
INFO:root:Round 6 Time: 41.512125730514526s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.548738  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 91.49 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.143059  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.155532  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.531011  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.102655  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 97.13 **************
INFO:root:************* Client 1 Acc = 95.80 **************
INFO:root:************* Client 2 Acc = 80.31 **************
INFO:root:************* Client 4 Acc = 96.85 **************
INFO:root:************* Server Acc = 55.91 **************
INFO:root:Round 7 Time: 41.31419801712036s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.295989  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.125900  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.109689  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.495636  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.105340  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 96.93 **************
INFO:root:************* Client 3 Acc = 97.55 **************
INFO:root:************* Client 2 Acc = 80.96 **************
INFO:root:************* Client 4 Acc = 96.04 **************
INFO:root:************* Server Acc = 57.61 **************
INFO:root:Round 8 Time: 40.466227769851685s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.444849  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 93.58 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.121306  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.144061  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492321  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 97.88 **************
INFO:root:************* Client 1 Acc = 97.22 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.090063  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 79.87 **************
INFO:root:************* Client 4 Acc = 95.84 **************
INFO:root:************* Server Acc = 66.20 **************
INFO:root:Round 9 Time: 41.622116565704346s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.313232  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 90.80 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.116481  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.098607  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.476602  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.093023  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 71.50 **************
INFO:root:************* Client 3 Acc = 97.50 **************
INFO:root:************* Client 2 Acc = 82.51 **************
INFO:root:************* Client 4 Acc = 97.69 **************
INFO:root:************* Server Acc = 60.13 **************
INFO:root:Round 10 Time: 39.5073561668396s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.539178  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 94.97 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.094592  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.124775  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.449652  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080647  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 97.58 **************
INFO:root:************* Client 1 Acc = 97.09 **************
INFO:root:************* Client 2 Acc = 83.33 **************
INFO:root:************* Client 4 Acc = 97.38 **************
INFO:root:************* Server Acc = 74.05 **************
INFO:root:Round 11 Time: 40.05084681510925s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.220011  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.098935  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.086165  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.438739  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.082116  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 96.31 **************
INFO:root:************* Client 3 Acc = 98.01 **************
INFO:root:************* Client 2 Acc = 82.84 **************
INFO:root:************* Client 4 Acc = 97.76 **************
INFO:root:************* Server Acc = 60.81 **************
INFO:root:Round 12 Time: 40.2274055480957s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.413735  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.091019  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.111002  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 98.22 **************
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.428581  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 97.27 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.072997  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 84.66 **************
INFO:root:************* Client 4 Acc = 97.46 **************
INFO:root:************* Server Acc = 74.76 **************
INFO:root:Round 13 Time: 40.78819131851196s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.294170  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 96.53 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.090986  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.078414  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.417032  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.075995  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 97.32 **************
INFO:root:************* Client 3 Acc = 98.36 **************
INFO:root:************* Client 2 Acc = 85.32 **************
INFO:root:************* Client 4 Acc = 97.85 **************
INFO:root:************* Server Acc = 65.08 **************
INFO:root:Round 14 Time: 39.9720675945282s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.408513  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 96.70 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.080988  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.115515  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.417968  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.49 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.067503  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 97.97 **************
INFO:root:************* Client 2 Acc = 83.01 **************
INFO:root:************* Client 4 Acc = 91.63 **************
INFO:root:************* Server Acc = 78.43 **************
INFO:root:Round 15 Time: 42.27847981452942s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.319762  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 96.01 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.083009  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.074196  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.401969  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.073339  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 97.94 **************
INFO:root:************* Client 3 Acc = 98.38 **************
INFO:root:************* Client 2 Acc = 87.11 **************
INFO:root:************* Client 4 Acc = 97.41 **************
INFO:root:************* Server Acc = 69.86 **************
INFO:root:Round 16 Time: 40.2897572517395s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.317995  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 91.15 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.073828  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.109259  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.400155  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.57 **************
INFO:root:************* Client 1 Acc = 97.70 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.064494  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 85.76 **************
INFO:root:************* Client 4 Acc = 98.44 **************
INFO:root:************* Server Acc = 79.70 **************
INFO:root:Round 17 Time: 42.222389698028564s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.370163  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 94.27 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.074348  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.078885  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.382179  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.065268  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 98.57 **************
INFO:root:************* Client 1 Acc = 98.12 **************
INFO:root:************* Client 2 Acc = 85.84 **************
INFO:root:************* Client 4 Acc = 98.17 **************
INFO:root:************* Server Acc = 74.52 **************
INFO:root:Round 18 Time: 42.8888578414917s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.269408  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 97.57 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.067148  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.096280  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.377664  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.43 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.060596  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 97.89 **************
INFO:root:************* Client 2 Acc = 85.49 **************
INFO:root:************* Client 4 Acc = 98.35 **************
INFO:root:************* Server Acc = 81.51 **************
INFO:root:Round 19 Time: 42.298174142837524s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 9, 1: 1, 2: 572, 3: 39, 5: 2, 6: 20, 7: 45, 9: 941}, 1: {0: 2137, 1: 145, 2: 477, 3: 1160, 4: 2317, 5: 150, 7: 4084, 8: 5756}, 2: {0: 3, 1: 14, 2: 4079, 3: 690, 4: 3675, 5: 23, 6: 4697}, 3: {1: 554, 2: 871, 3: 914, 4: 8, 5: 5825, 6: 1283, 7: 1871, 8: 244, 9: 5059}, 4: {0: 3851, 1: 5286, 2: 1, 3: 3197}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 1629
INFO:root:client_idx = 0, batch_num_train_local = 25, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 16226
INFO:root:client_idx = 1, batch_num_train_local = 253, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 13181
INFO:root:client_idx = 2, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 16629
INFO:root:client_idx = 3, batch_num_train_local = 259, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12335
INFO:root:client_idx = 4, batch_num_train_local = 192, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.191621  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 77.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.594129  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.246425  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.764663  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 87.79 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.704411  Thread 2  Map [1]
INFO:root:************* Client 2 Acc = 49.63 **************
INFO:root:************* Client 3 Acc = 83.83 **************
INFO:root:************* Client 1 Acc = 87.93 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 48.82831025123596s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.783890  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 84.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.416758  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.097392  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.549579  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 90.31 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.481796  Thread 2  Map [1]
INFO:root:************* Client 2 Acc = 51.41 **************
INFO:root:************* Client 3 Acc = 85.49 **************
INFO:root:************* Client 1 Acc = 89.10 **************
INFO:root:************* Server Acc = 18.81 **************
INFO:root:Round 1 Time: 40.47509789466858s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.468395  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.299670  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.969713  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.374758  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.415851  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 89.55 **************
INFO:root:************* Client 2 Acc = 61.58 **************
INFO:root:************* Client 1 Acc = 86.94 **************
INFO:root:************* Client 3 Acc = 87.29 **************
INFO:root:************* Server Acc = 19.45 **************
INFO:root:Round 2 Time: 40.71830773353577s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.454775  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.251850  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.892320  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.311031  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.348528  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 84.30 **************
INFO:root:************* Client 2 Acc = 71.62 **************
INFO:root:************* Client 1 Acc = 91.78 **************
INFO:root:************* Client 3 Acc = 81.66 **************
INFO:root:************* Server Acc = 38.08 **************
INFO:root:Round 3 Time: 39.534149169921875s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.410940  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.211652  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.798560  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.311323  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.260912  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 93.42 **************
INFO:root:************* Client 2 Acc = 53.44 **************
INFO:root:************* Client 3 Acc = 88.75 **************
INFO:root:************* Client 1 Acc = 92.83 **************
INFO:root:************* Server Acc = 56.50 **************
INFO:root:Round 4 Time: 39.70429348945618s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.321703  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.179693  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.724975  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.243230  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 95.54 **************
INFO:root:************* Client 2 Acc = 77.23 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.274511  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 93.31 **************
INFO:root:************* Client 3 Acc = 90.86 **************
INFO:root:************* Server Acc = 63.41 **************
INFO:root:Round 5 Time: 42.74372315406799s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.289231  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.175810  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.653504  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.207697  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.248916  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 95.08 **************
INFO:root:************* Client 2 Acc = 67.57 **************
INFO:root:************* Client 1 Acc = 93.35 **************
INFO:root:************* Client 3 Acc = 92.10 **************
INFO:root:************* Server Acc = 66.77 **************
INFO:root:Round 6 Time: 40.991138219833374s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.288333  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.156545  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.621437  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.195398  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.229942  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 95.39 **************
INFO:root:************* Client 2 Acc = 80.28 **************
INFO:root:************* Client 1 Acc = 93.52 **************
INFO:root:************* Client 3 Acc = 92.59 **************
INFO:root:************* Server Acc = 68.42 **************
INFO:root:Round 7 Time: 41.024301052093506s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.301378  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.145729  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.594954  Thread 4  Map [2]
INFO:root:************* Client 4 Acc = 94.62 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.187767  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.216074  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 80.05 **************
INFO:root:************* Client 1 Acc = 94.87 **************
INFO:root:************* Client 3 Acc = 93.90 **************
INFO:root:************* Server Acc = 76.68 **************
INFO:root:Round 8 Time: 40.95748329162598s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.204091  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.128206  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.552115  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.169568  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 91.25 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.203820  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 81.65 **************
INFO:root:************* Client 1 Acc = 95.49 **************
INFO:root:************* Client 3 Acc = 93.32 **************
INFO:root:************* Server Acc = 75.26 **************
INFO:root:Round 9 Time: 40.0969135761261s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.268808  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.134267  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.531505  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.161498  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.187895  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 96.64 **************
INFO:root:************* Client 2 Acc = 76.09 **************
INFO:root:************* Client 1 Acc = 94.86 **************
INFO:root:************* Client 3 Acc = 93.23 **************
INFO:root:************* Server Acc = 79.12 **************
INFO:root:Round 10 Time: 40.891831398010254s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.231791  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.115268  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.506428  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.153300  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.187356  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 96.74 **************
INFO:root:************* Client 2 Acc = 78.94 **************
INFO:root:************* Client 1 Acc = 95.76 **************
INFO:root:************* Client 3 Acc = 93.91 **************
INFO:root:************* Server Acc = 78.23 **************
INFO:root:Round 11 Time: 40.86067032814026s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.210604  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.112629  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492731  Thread 4  Map [2]
INFO:root:************* Client 4 Acc = 93.90 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.146965  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.174953  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 82.96 **************
INFO:root:************* Client 1 Acc = 96.02 **************
INFO:root:************* Client 3 Acc = 94.40 **************
INFO:root:************* Server Acc = 83.14 **************
INFO:root:Round 12 Time: 40.76317620277405s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.173142  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492061  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.110098  Thread 3  Map [4]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.139767  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.171370  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 96.21 **************
INFO:root:************* Client 2 Acc = 84.84 **************
INFO:root:************* Client 1 Acc = 96.25 **************
INFO:root:************* Client 3 Acc = 94.64 **************
INFO:root:************* Server Acc = 82.21 **************
INFO:root:Round 13 Time: 40.81924343109131s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.240161  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.105015  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.463633  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.135303  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.159104  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 96.40 **************
INFO:root:************* Client 2 Acc = 81.81 **************
INFO:root:************* Client 1 Acc = 96.45 **************
INFO:root:************* Client 3 Acc = 95.17 **************
INFO:root:************* Server Acc = 84.87 **************
INFO:root:Round 14 Time: 40.10866570472717s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.150037  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.101816  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.454237  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.130484  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 97.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.153991  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 84.59 **************
INFO:root:************* Client 1 Acc = 96.04 **************
INFO:root:************* Client 3 Acc = 94.99 **************
INFO:root:************* Server Acc = 84.99 **************
INFO:root:Round 15 Time: 40.69637703895569s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.182089  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.25 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094721  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.435414  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.126873  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.155054  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 97.42 **************
INFO:root:************* Client 2 Acc = 80.53 **************
INFO:root:************* Client 1 Acc = 96.79 **************
INFO:root:************* Client 3 Acc = 95.08 **************
INFO:root:************* Server Acc = 85.08 **************
INFO:root:Round 16 Time: 40.42885494232178s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.171394  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094917  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.430404  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.153726  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 95.19 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.121561  Thread 2  Map [1]
INFO:root:************* Client 2 Acc = 85.71 **************
INFO:root:************* Client 3 Acc = 95.10 **************
INFO:root:************* Client 1 Acc = 96.71 **************
INFO:root:************* Server Acc = 85.21 **************
INFO:root:Round 17 Time: 40.08984088897705s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.145238  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.44 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.092645  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.423865  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.116153  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.146056  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 97.59 **************
INFO:root:************* Client 2 Acc = 84.94 **************
INFO:root:************* Client 1 Acc = 97.04 **************
INFO:root:************* Client 3 Acc = 94.96 **************
INFO:root:************* Server Acc = 85.53 **************
INFO:root:Round 18 Time: 41.061020612716675s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.160639  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.087574  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.423538  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.110942  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.141132  Thread 5  Map [3]
INFO:root:************* Client 4 Acc = 97.60 **************
INFO:root:************* Client 2 Acc = 84.66 **************
INFO:root:************* Client 1 Acc = 97.10 **************
INFO:root:************* Client 3 Acc = 94.97 **************
INFO:root:************* Server Acc = 85.91 **************
INFO:root:Round 19 Time: 40.706979751586914s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 278, 1: 188, 2: 941, 3: 1325, 4: 27, 5: 100, 6: 255, 7: 2869, 8: 1, 9: 3810}, 1: {0: 2413, 1: 2049, 2: 871, 3: 875, 4: 2454, 5: 505, 6: 2, 7: 90, 8: 4385}, 2: {0: 184, 1: 1069, 2: 3042, 3: 1099, 4: 3339, 5: 239, 6: 3459}, 3: {0: 51, 1: 410, 2: 1144, 3: 2700, 4: 118, 5: 4895, 6: 1431, 7: 261, 8: 1093}, 4: {0: 3074, 1: 2284, 2: 2, 3: 1, 4: 62, 5: 261, 6: 853, 7: 2780, 8: 521, 9: 2190}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 9794
INFO:root:client_idx = 0, batch_num_train_local = 153, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13644
INFO:root:client_idx = 1, batch_num_train_local = 213, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 12431
INFO:root:client_idx = 2, batch_num_train_local = 194, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 12103
INFO:root:client_idx = 3, batch_num_train_local = 189, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12028
INFO:root:client_idx = 4, batch_num_train_local = 187, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.940690  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.851776  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.810694  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.367861  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 80.85 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.913731  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 81.18 **************
INFO:root:************* Client 3 Acc = 79.37 **************
INFO:root:************* Client 2 Acc = 52.41 **************
INFO:root:************* Client 1 Acc = 76.04 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 47.72175693511963s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.663530  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.560051  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.625484  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.143773  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 83.05 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.625904  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 80.41 **************
INFO:root:************* Client 3 Acc = 80.62 **************
INFO:root:************* Client 2 Acc = 65.49 **************
INFO:root:************* Client 1 Acc = 83.27 **************
INFO:root:************* Server Acc = 24.41 **************
INFO:root:Round 1 Time: 39.154247999191284s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.477000  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.443221  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.489976  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.999504  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.483020  Thread 2  Map [1]
INFO:root:************* Client 0 Acc = 86.81 **************
INFO:root:************* Client 4 Acc = 89.62 **************
INFO:root:************* Client 3 Acc = 80.63 **************
INFO:root:************* Client 2 Acc = 67.19 **************
INFO:root:************* Client 1 Acc = 82.20 **************
INFO:root:************* Server Acc = 24.67 **************
INFO:root:Round 2 Time: 38.20570492744446s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.395518  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.358333  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.426154  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.868297  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.403364  Thread 2  Map [1]
INFO:root:************* Client 0 Acc = 77.82 **************
INFO:root:************* Client 4 Acc = 89.82 **************
INFO:root:************* Client 3 Acc = 86.87 **************
INFO:root:************* Client 2 Acc = 72.54 **************
INFO:root:************* Client 1 Acc = 86.86 **************
INFO:root:************* Server Acc = 38.30 **************
INFO:root:Round 3 Time: 37.2255072593689s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.355440  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.309163  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.367157  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.807585  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.363801  Thread 2  Map [1]
INFO:root:************* Client 0 Acc = 88.52 **************
INFO:root:************* Client 3 Acc = 86.59 **************
INFO:root:************* Client 4 Acc = 89.94 **************
INFO:root:************* Client 2 Acc = 70.73 **************
INFO:root:************* Client 1 Acc = 89.02 **************
INFO:root:************* Server Acc = 60.31 **************
INFO:root:Round 4 Time: 37.50051474571228s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.321807  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.285820  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.346671  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.767353  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 91.45 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.326599  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 91.18 **************
INFO:root:************* Client 3 Acc = 88.35 **************
INFO:root:************* Client 2 Acc = 72.02 **************
INFO:root:************* Client 1 Acc = 89.34 **************
INFO:root:************* Server Acc = 67.86 **************
INFO:root:Round 5 Time: 37.206531286239624s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.308679  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.308459  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.265160  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.720298  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.304114  Thread 2  Map [1]
INFO:root:************* Client 0 Acc = 91.57 **************
INFO:root:************* Client 3 Acc = 90.52 **************
INFO:root:************* Client 2 Acc = 68.19 **************
INFO:root:************* Client 4 Acc = 91.99 **************
INFO:root:************* Client 1 Acc = 89.03 **************
INFO:root:************* Server Acc = 75.70 **************
INFO:root:Round 6 Time: 36.62942910194397s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.275841  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.255999  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.294520  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.669244  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 91.57 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.287385  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 90.42 **************
INFO:root:************* Client 3 Acc = 89.42 **************
INFO:root:************* Client 2 Acc = 79.17 **************
INFO:root:************* Client 1 Acc = 91.70 **************
INFO:root:************* Server Acc = 73.27 **************
INFO:root:Round 7 Time: 37.76246476173401s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.264423  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.241034  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.280251  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.620883  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.274179  Thread 2  Map [1]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:************* Client 4 Acc = 93.00 **************
INFO:root:************* Client 3 Acc = 90.87 **************
INFO:root:************* Client 2 Acc = 72.34 **************
INFO:root:************* Client 1 Acc = 92.24 **************
INFO:root:************* Server Acc = 77.76 **************
INFO:root:Round 8 Time: 36.863630294799805s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.255838  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.231687  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.265176  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.577366  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 91.56 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.249642  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 93.71 **************
INFO:root:************* Client 3 Acc = 91.96 **************
INFO:root:************* Client 2 Acc = 80.67 **************
INFO:root:************* Client 1 Acc = 91.94 **************
INFO:root:************* Server Acc = 78.52 **************
INFO:root:Round 9 Time: 37.57147264480591s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.242431  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.219173  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.244687  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.545088  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 92.92 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.232322  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 92.36 **************
INFO:root:************* Client 3 Acc = 92.61 **************
INFO:root:************* Client 2 Acc = 83.15 **************
INFO:root:************* Client 1 Acc = 93.71 **************
INFO:root:************* Server Acc = 82.20 **************
INFO:root:Round 10 Time: 38.27983212471008s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.230781  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.211660  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.237074  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.528734  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.219090  Thread 2  Map [1]
INFO:root:************* Client 0 Acc = 92.30 **************
INFO:root:************* Client 4 Acc = 92.86 **************
INFO:root:************* Client 3 Acc = 92.07 **************
INFO:root:************* Client 2 Acc = 75.90 **************
INFO:root:************* Client 1 Acc = 94.05 **************
INFO:root:************* Server Acc = 82.77 **************
INFO:root:Round 11 Time: 36.78549289703369s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.224769  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.203602  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.226110  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.501153  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.200602  Thread 2  Map [1]
INFO:root:************* Client 0 Acc = 87.58 **************
INFO:root:************* Client 4 Acc = 94.02 **************
INFO:root:************* Client 3 Acc = 93.01 **************
INFO:root:************* Client 2 Acc = 81.02 **************
INFO:root:************* Client 1 Acc = 94.66 **************
INFO:root:************* Server Acc = 85.44 **************
INFO:root:Round 12 Time: 37.15569758415222s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.220137  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.224156  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.195687  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.483174  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 93.79 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.194547  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 93.44 **************
INFO:root:************* Client 2 Acc = 84.46 **************
INFO:root:************* Client 4 Acc = 93.01 **************
INFO:root:************* Client 1 Acc = 93.73 **************
INFO:root:************* Server Acc = 85.46 **************
INFO:root:Round 13 Time: 37.25099229812622s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.203121  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.187226  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.211104  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.475210  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 93.63 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.189983  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.28 **************
INFO:root:************* Client 3 Acc = 93.94 **************
INFO:root:************* Client 2 Acc = 84.55 **************
INFO:root:************* Client 1 Acc = 93.68 **************
INFO:root:************* Server Acc = 85.79 **************
INFO:root:Round 14 Time: 36.91860556602478s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.208331  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.184468  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.209816  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.449441  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 92.81 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.183940  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 92.41 **************
INFO:root:************* Client 3 Acc = 93.53 **************
INFO:root:************* Client 2 Acc = 81.79 **************
INFO:root:************* Client 1 Acc = 94.98 **************
INFO:root:************* Server Acc = 87.59 **************
INFO:root:Round 15 Time: 37.423895835876465s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.201330  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.179970  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.196371  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.447617  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 94.31 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.177802  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.55 **************
INFO:root:************* Client 3 Acc = 93.61 **************
INFO:root:************* Client 2 Acc = 80.36 **************
INFO:root:************* Client 1 Acc = 94.62 **************
INFO:root:************* Server Acc = 86.88 **************
INFO:root:Round 16 Time: 37.10890007019043s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.196929  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.191510  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.176005  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.440738  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.170033  Thread 2  Map [1]
INFO:root:************* Client 0 Acc = 93.94 **************
INFO:root:************* Client 3 Acc = 93.86 **************
INFO:root:************* Client 4 Acc = 94.82 **************
INFO:root:************* Client 2 Acc = 85.69 **************
INFO:root:************* Client 1 Acc = 94.98 **************
INFO:root:************* Server Acc = 86.65 **************
INFO:root:Round 17 Time: 37.77831435203552s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.192300  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.173620  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.181527  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.437104  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 94.74 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.161330  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.73 **************
INFO:root:************* Client 3 Acc = 93.92 **************
INFO:root:************* Client 2 Acc = 85.43 **************
INFO:root:************* Client 1 Acc = 95.28 **************
INFO:root:************* Server Acc = 87.30 **************
INFO:root:Round 18 Time: 37.90227031707764s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.175769  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.159564  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.180640  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.422994  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.161576  Thread 2  Map [1]
INFO:root:************* Client 0 Acc = 95.03 **************
INFO:root:************* Client 4 Acc = 93.83 **************
INFO:root:************* Client 3 Acc = 94.31 **************
INFO:root:************* Client 2 Acc = 84.00 **************
INFO:root:************* Client 1 Acc = 95.19 **************
INFO:root:************* Server Acc = 88.12 **************
INFO:root:Round 19 Time: 37.092676877975464s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {2: 109, 3: 1, 8: 7, 9: 487}, 1: {0: 1412, 1: 2433, 2: 77, 3: 1151, 4: 2259, 5: 9, 7: 5999}, 2: {1: 227, 2: 5559, 3: 475, 4: 3740, 6: 5574}, 3: {1: 2, 2: 255, 3: 801, 5: 132, 6: 426, 7: 1, 8: 5993, 9: 5513}, 4: {0: 4588, 1: 3338, 3: 3572, 4: 1, 5: 5859}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 604
INFO:root:client_idx = 0, batch_num_train_local = 9, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13340
INFO:root:client_idx = 1, batch_num_train_local = 208, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 15575
INFO:root:client_idx = 2, batch_num_train_local = 243, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 13123
INFO:root:client_idx = 3, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 17358
INFO:root:client_idx = 4, batch_num_train_local = 271, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.027041  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 18.23 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.636642  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.571737  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.207238  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.411888  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 93.57 **************
INFO:root:************* Client 1 Acc = 89.08 **************
INFO:root:************* Client 2 Acc = 59.24 **************
INFO:root:************* Client 4 Acc = 90.62 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 49.15830159187317s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.173252  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 17.01 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.447480  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.383176  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.063439  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 92.78 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.284627  Thread 3  Map [4]
INFO:root:************* Client 2 Acc = 63.39 **************
INFO:root:************* Client 1 Acc = 91.44 **************
INFO:root:************* Client 4 Acc = 93.70 **************
INFO:root:************* Server Acc = 10.02 **************
INFO:root:Round 1 Time: 41.77456521987915s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.786545  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 94.97 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.264250  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.289812  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.913333  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.226536  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 93.52 **************
INFO:root:************* Client 3 Acc = 94.77 **************
INFO:root:************* Client 2 Acc = 70.40 **************
INFO:root:************* Client 4 Acc = 82.26 **************
INFO:root:************* Server Acc = 12.67 **************
INFO:root:Round 2 Time: 42.07494235038757s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.651624  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 95.66 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.226244  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.239953  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.800532  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.178046  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 95.79 **************
INFO:root:************* Client 1 Acc = 94.52 **************
INFO:root:************* Client 2 Acc = 72.67 **************
INFO:root:************* Client 4 Acc = 95.57 **************
INFO:root:************* Server Acc = 36.56 **************
INFO:root:Round 3 Time: 40.58560228347778s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.474494  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.184452  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.178558  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.682104  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.163114  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 94.83 **************
INFO:root:************* Client 3 Acc = 96.57 **************
INFO:root:************* Client 2 Acc = 73.55 **************
INFO:root:************* Client 4 Acc = 96.22 **************
INFO:root:************* Server Acc = 45.45 **************
INFO:root:Round 4 Time: 40.25736975669861s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.590302  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 95.31 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.204685  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.169765  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.620600  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.123678  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 96.03 **************
INFO:root:************* Client 3 Acc = 96.87 **************
INFO:root:************* Client 2 Acc = 78.99 **************
INFO:root:************* Client 4 Acc = 95.65 **************
INFO:root:************* Server Acc = 45.33 **************
INFO:root:Round 5 Time: 41.61850047111511s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.460947  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 94.27 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.147310  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.132267  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.571218  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 96.21 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.120917  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 97.07 **************
INFO:root:************* Client 2 Acc = 82.43 **************
INFO:root:************* Client 4 Acc = 97.19 **************
INFO:root:************* Server Acc = 48.92 **************
INFO:root:Round 6 Time: 41.71029281616211s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.548738  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 91.49 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.155532  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.143059  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.531011  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.102655  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 95.80 **************
INFO:root:************* Client 3 Acc = 97.13 **************
INFO:root:************* Client 2 Acc = 80.31 **************
INFO:root:************* Client 4 Acc = 96.85 **************
INFO:root:************* Server Acc = 55.91 **************
INFO:root:Round 7 Time: 41.31447672843933s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.295989  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.125900  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.109689  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.495636  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 96.93 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.105340  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 97.55 **************
INFO:root:************* Client 2 Acc = 80.96 **************
INFO:root:************* Client 4 Acc = 96.04 **************
INFO:root:************* Server Acc = 57.61 **************
INFO:root:Round 8 Time: 41.66332530975342s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.444849  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 93.58 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.121306  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.144061  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492321  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.090063  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 97.22 **************
INFO:root:************* Client 2 Acc = 79.87 **************
INFO:root:************* Client 4 Acc = 95.84 **************
INFO:root:************* Server Acc = 66.20 **************
INFO:root:Round 9 Time: 41.80858778953552s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.313232  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 90.80 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.116481  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.098607  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 71.50 **************
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.476602  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.093023  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 97.50 **************
INFO:root:************* Client 2 Acc = 82.51 **************
INFO:root:************* Client 4 Acc = 97.69 **************
INFO:root:************* Server Acc = 60.13 **************
INFO:root:Round 10 Time: 41.54051470756531s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.539178  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 94.97 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.094592  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.124775  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.449652  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080647  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 97.58 **************
INFO:root:************* Client 1 Acc = 97.09 **************
INFO:root:************* Client 2 Acc = 83.33 **************
INFO:root:************* Client 4 Acc = 97.38 **************
INFO:root:************* Server Acc = 74.05 **************
INFO:root:Round 11 Time: 41.65371799468994s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.220011  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.086165  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.098935  Thread 1  Map [1]
INFO:root:************* Client 3 Acc = 98.01 **************
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.438739  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.082116  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 96.31 **************
INFO:root:************* Client 2 Acc = 82.84 **************
INFO:root:************* Client 4 Acc = 97.76 **************
INFO:root:************* Server Acc = 60.81 **************
INFO:root:Round 12 Time: 42.719669818878174s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.413735  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.091019  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.111002  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.428581  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.072997  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 98.22 **************
INFO:root:************* Client 1 Acc = 97.27 **************
INFO:root:************* Client 2 Acc = 84.66 **************
INFO:root:************* Client 4 Acc = 97.46 **************
INFO:root:************* Server Acc = 74.76 **************
INFO:root:Round 13 Time: 42.323991775512695s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.294170  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 96.53 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.078414  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.090986  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.417032  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.075995  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 98.36 **************
INFO:root:************* Client 1 Acc = 97.32 **************
INFO:root:************* Client 2 Acc = 85.32 **************
INFO:root:************* Client 4 Acc = 97.85 **************
INFO:root:************* Server Acc = 65.08 **************
INFO:root:Round 14 Time: 42.246801137924194s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.408513  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 96.70 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.080988  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.115515  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.417968  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.067503  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 98.49 **************
INFO:root:************* Client 1 Acc = 97.97 **************
INFO:root:************* Client 2 Acc = 83.01 **************
INFO:root:************* Client 4 Acc = 91.63 **************
INFO:root:************* Server Acc = 78.43 **************
INFO:root:Round 15 Time: 42.020524978637695s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.319762  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 96.01 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.074196  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.083009  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.401969  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.073339  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 98.38 **************
INFO:root:************* Client 1 Acc = 97.94 **************
INFO:root:************* Client 2 Acc = 87.11 **************
INFO:root:************* Client 4 Acc = 97.41 **************
INFO:root:************* Server Acc = 69.86 **************
INFO:root:Round 16 Time: 39.90005803108215s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.317995  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 91.15 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.109259  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.073828  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.400155  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 97.70 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.064494  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 98.57 **************
INFO:root:************* Client 2 Acc = 85.76 **************
INFO:root:************* Client 4 Acc = 98.44 **************
INFO:root:************* Server Acc = 79.70 **************
INFO:root:Round 17 Time: 41.658602237701416s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.370163  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 94.27 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.078885  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.074348  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.382179  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 98.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.065268  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 98.57 **************
INFO:root:************* Client 2 Acc = 85.84 **************
INFO:root:************* Client 4 Acc = 98.17 **************
INFO:root:************* Server Acc = 74.52 **************
INFO:root:Round 18 Time: 41.651381492614746s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.269408  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.57 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.096280  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.067148  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.377664  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 97.89 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.060596  Thread 3  Map [4]
INFO:root:************* Client 3 Acc = 98.43 **************
INFO:root:************* Client 2 Acc = 85.49 **************
INFO:root:************* Client 4 Acc = 98.35 **************
INFO:root:************* Server Acc = 81.51 **************
INFO:root:Round 19 Time: 41.48516273498535s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.346225  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 95.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.065655  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.075373  Thread 1  Map [1]
INFO:root:************* Client 3 Acc = 98.74 **************
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.373666  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.062679  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 98.14 **************
INFO:root:************* Client 2 Acc = 87.93 **************
INFO:root:************* Client 4 Acc = 98.34 **************
INFO:root:************* Server Acc = 76.68 **************
INFO:root:Round 20 Time: 42.28106331825256s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.291983  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 94.79 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.065358  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.084310  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.367392  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.61 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.055950  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 98.17 **************
INFO:root:************* Client 2 Acc = 85.67 **************
INFO:root:************* Client 4 Acc = 98.30 **************
INFO:root:************* Server Acc = 82.90 **************
INFO:root:Round 21 Time: 41.69749617576599s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.285426  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 96.35 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.072919  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.063483  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.368237  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.060537  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 97.94 **************
INFO:root:************* Client 3 Acc = 98.78 **************
INFO:root:************* Client 2 Acc = 85.95 **************
INFO:root:************* Client 4 Acc = 98.05 **************
INFO:root:************* Server Acc = 75.68 **************
INFO:root:Round 22 Time: 40.33807349205017s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.316469  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 95.14 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.065144  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.088845  Thread 1  Map [1]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.057974  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.352177  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.57 **************
INFO:root:************* Client 1 Acc = 98.26 **************
INFO:root:************* Client 2 Acc = 87.12 **************
INFO:root:************* Client 4 Acc = 98.45 **************
INFO:root:************* Server Acc = 76.74 **************
INFO:root:Round 23 Time: 39.57352161407471s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.314526  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 95.66 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.066206  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.068576  Thread 1  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.351590  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.056382  Thread 3  Map [4]
INFO:root:************* Client 1 Acc = 98.29 **************
INFO:root:************* Client 2 Acc = 85.27 **************
INFO:root:************* Client 4 Acc = 98.01 **************
INFO:root:************* Server Acc = 76.73 **************
INFO:root:Round 24 Time: 41.20381259918213s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 9, 1: 1, 2: 572, 3: 39, 5: 2, 6: 20, 7: 45, 9: 941}, 1: {0: 2137, 1: 145, 2: 477, 3: 1160, 4: 2317, 5: 150, 7: 4084, 8: 5756}, 2: {0: 3, 1: 14, 2: 4079, 3: 690, 4: 3675, 5: 23, 6: 4697}, 3: {1: 554, 2: 871, 3: 914, 4: 8, 5: 5825, 6: 1283, 7: 1871, 8: 244, 9: 5059}, 4: {0: 3851, 1: 5286, 2: 1, 3: 3197}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 1629
INFO:root:client_idx = 0, batch_num_train_local = 25, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 16226
INFO:root:client_idx = 1, batch_num_train_local = 253, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 13181
INFO:root:client_idx = 2, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 16629
INFO:root:client_idx = 3, batch_num_train_local = 259, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12335
INFO:root:client_idx = 4, batch_num_train_local = 192, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.191621  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 77.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.594129  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.246425  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.704411  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.764663  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 87.79 **************
INFO:root:************* Client 2 Acc = 49.63 **************
INFO:root:************* Client 1 Acc = 87.93 **************
INFO:root:************* Client 3 Acc = 83.83 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 49.22441053390503s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.783890  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 84.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.416758  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.097392  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.481796  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.549579  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 90.31 **************
INFO:root:************* Client 2 Acc = 51.41 **************
INFO:root:************* Client 1 Acc = 89.10 **************
INFO:root:************* Client 3 Acc = 85.49 **************
INFO:root:************* Server Acc = 18.81 **************
INFO:root:Round 1 Time: 41.226322174072266s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.468395  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 94.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.299670  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.969713  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.374758  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.415851  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 89.55 **************
INFO:root:************* Client 2 Acc = 61.58 **************
INFO:root:************* Client 1 Acc = 86.94 **************
INFO:root:************* Client 3 Acc = 87.29 **************
INFO:root:************* Server Acc = 19.45 **************
INFO:root:Round 2 Time: 40.77760076522827s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.454775  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 95.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.251850  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.892320  Thread 5  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.348528  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 84.30 **************
INFO:root:************* Client 2 Acc = 71.62 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.311031  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 81.66 **************
INFO:root:************* Client 1 Acc = 91.78 **************
INFO:root:************* Server Acc = 38.08 **************
INFO:root:Round 3 Time: 41.51295518875122s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.410940  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 96.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.211652  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.798560  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.260912  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.311323  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 93.42 **************
INFO:root:************* Client 2 Acc = 53.44 **************
INFO:root:************* Client 1 Acc = 92.83 **************
INFO:root:************* Client 3 Acc = 88.75 **************
INFO:root:************* Server Acc = 56.50 **************
INFO:root:Round 4 Time: 39.69353175163269s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.321703  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 96.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.179693  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.724975  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.243230  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.274511  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 95.54 **************
INFO:root:************* Client 2 Acc = 77.23 **************
INFO:root:************* Client 1 Acc = 93.31 **************
INFO:root:************* Client 3 Acc = 90.86 **************
INFO:root:************* Server Acc = 63.41 **************
INFO:root:Round 5 Time: 40.066805362701416s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.289231  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.175810  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.653504  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.207697  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.248916  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 95.08 **************
INFO:root:************* Client 2 Acc = 67.57 **************
INFO:root:************* Client 1 Acc = 93.35 **************
INFO:root:************* Client 3 Acc = 92.10 **************
INFO:root:************* Server Acc = 66.77 **************
INFO:root:Round 6 Time: 40.67675995826721s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.288333  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.156545  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.621437  Thread 5  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.229942  Thread 1  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.195398  Thread 3  Map [1]
INFO:root:************* Client 4 Acc = 95.39 **************
INFO:root:************* Client 2 Acc = 80.28 **************
INFO:root:************* Client 1 Acc = 93.52 **************
INFO:root:************* Client 3 Acc = 92.59 **************
INFO:root:************* Server Acc = 68.42 **************
INFO:root:Round 7 Time: 40.017383337020874s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.301378  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.145729  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.594954  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.187767  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.216074  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 94.62 **************
INFO:root:************* Client 2 Acc = 80.05 **************
INFO:root:************* Client 1 Acc = 94.87 **************
INFO:root:************* Client 3 Acc = 93.90 **************
INFO:root:************* Server Acc = 76.68 **************
INFO:root:Round 8 Time: 40.6921124458313s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.204091  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.128206  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.552115  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.169568  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.203820  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 91.25 **************
INFO:root:************* Client 2 Acc = 81.65 **************
INFO:root:************* Client 1 Acc = 95.49 **************
INFO:root:************* Client 3 Acc = 93.32 **************
INFO:root:************* Server Acc = 75.26 **************
INFO:root:Round 9 Time: 40.87140130996704s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.268808  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.134267  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.531505  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.161498  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.187895  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 96.64 **************
INFO:root:************* Client 2 Acc = 76.09 **************
INFO:root:************* Client 1 Acc = 94.86 **************
INFO:root:************* Client 3 Acc = 93.23 **************
INFO:root:************* Server Acc = 79.12 **************
INFO:root:Round 10 Time: 41.15123534202576s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.231791  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.115268  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.506428  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.153300  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.187356  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 96.74 **************
INFO:root:************* Client 2 Acc = 78.94 **************
INFO:root:************* Client 1 Acc = 95.76 **************
INFO:root:************* Client 3 Acc = 93.91 **************
INFO:root:************* Server Acc = 78.23 **************
INFO:root:Round 11 Time: 41.03991389274597s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.210604  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.112629  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492731  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.146965  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.174953  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 93.90 **************
INFO:root:************* Client 2 Acc = 82.96 **************
INFO:root:************* Client 1 Acc = 96.02 **************
INFO:root:************* Client 3 Acc = 94.40 **************
INFO:root:************* Server Acc = 83.14 **************
INFO:root:Round 12 Time: 39.15324020385742s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.173142  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.110098  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492061  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.139767  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.171370  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 96.21 **************
INFO:root:************* Client 2 Acc = 84.84 **************
INFO:root:************* Client 1 Acc = 96.25 **************
INFO:root:************* Client 3 Acc = 94.64 **************
INFO:root:************* Server Acc = 82.21 **************
INFO:root:Round 13 Time: 40.81981348991394s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.240161  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 96.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.105015  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.463633  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.135303  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.159104  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 96.40 **************
INFO:root:************* Client 2 Acc = 81.81 **************
INFO:root:************* Client 1 Acc = 96.45 **************
INFO:root:************* Client 3 Acc = 95.17 **************
INFO:root:************* Server Acc = 84.87 **************
INFO:root:Round 14 Time: 40.84434151649475s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.150037  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.101816  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.454237  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.130484  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.153991  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 97.31 **************
INFO:root:************* Client 2 Acc = 84.59 **************
INFO:root:************* Client 1 Acc = 96.04 **************
INFO:root:************* Client 3 Acc = 94.99 **************
INFO:root:************* Server Acc = 84.99 **************
INFO:root:Round 15 Time: 40.7412428855896s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.182089  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.25 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094721  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.435414  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.126873  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.155054  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 97.42 **************
INFO:root:************* Client 2 Acc = 80.53 **************
INFO:root:************* Client 1 Acc = 96.79 **************
INFO:root:************* Client 3 Acc = 95.08 **************
INFO:root:************* Server Acc = 85.08 **************
INFO:root:Round 16 Time: 40.79074788093567s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.171394  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.75 **************
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.430404  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094917  Thread 4  Map [4]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.121561  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.153726  Thread 1  Map [3]
INFO:root:************* Client 2 Acc = 85.71 **************
INFO:root:************* Client 4 Acc = 95.19 **************
INFO:root:************* Client 1 Acc = 96.71 **************
INFO:root:************* Client 3 Acc = 95.10 **************
INFO:root:************* Server Acc = 85.21 **************
INFO:root:Round 17 Time: 39.39797401428223s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.145238  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.44 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.092645  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.423865  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.116153  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.146056  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 97.59 **************
INFO:root:************* Client 2 Acc = 84.94 **************
INFO:root:************* Client 3 Acc = 94.96 **************
INFO:root:************* Client 1 Acc = 97.04 **************
INFO:root:************* Server Acc = 85.53 **************
INFO:root:Round 18 Time: 41.105934381484985s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.160639  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 98.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.087574  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.423538  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.110942  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.141132  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 97.60 **************
INFO:root:************* Client 2 Acc = 84.66 **************
INFO:root:************* Client 1 Acc = 97.10 **************
INFO:root:************* Client 3 Acc = 94.97 **************
INFO:root:************* Server Acc = 85.91 **************
INFO:root:Round 19 Time: 40.835670471191406s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.166988  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.084465  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.411941  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.109627  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.136136  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 97.40 **************
INFO:root:************* Client 2 Acc = 84.87 **************
INFO:root:************* Client 1 Acc = 97.36 **************
INFO:root:************* Client 3 Acc = 94.69 **************
INFO:root:************* Server Acc = 86.28 **************
INFO:root:Round 20 Time: 41.10997772216797s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.183084  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.44 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.083771  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.406734  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.105679  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.137794  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 93.13 **************
INFO:root:************* Client 2 Acc = 87.44 **************
INFO:root:************* Client 1 Acc = 97.05 **************
INFO:root:************* Client 3 Acc = 95.86 **************
INFO:root:************* Server Acc = 85.72 **************
INFO:root:Round 21 Time: 40.648756980895996s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.165445  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 96.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.083648  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.396348  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.103094  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.131448  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 97.92 **************
INFO:root:************* Client 2 Acc = 85.50 **************
INFO:root:************* Client 1 Acc = 96.99 **************
INFO:root:************* Client 3 Acc = 95.34 **************
INFO:root:************* Server Acc = 86.11 **************
INFO:root:Round 22 Time: 40.641809701919556s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.152653  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.087670  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.390209  Thread 5  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.133672  Thread 1  Map [3]
INFO:root:************* Client 4 Acc = 97.48 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.103183  Thread 3  Map [1]
INFO:root:************* Client 2 Acc = 87.58 **************
INFO:root:************* Client 3 Acc = 95.95 **************
INFO:root:************* Client 1 Acc = 97.39 **************
INFO:root:************* Server Acc = 87.21 **************
INFO:root:Round 23 Time: 39.9477858543396s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.157288  Thread 2  Map [0]
INFO:root:************* Client 0 Acc = 98.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.074498  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.393721  Thread 5  Map [2]
INFO:root:************* Client 4 Acc = 97.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.126398  Thread 1  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.100470  Thread 3  Map [1]
INFO:root:************* Client 2 Acc = 87.96 **************
INFO:root:************* Client 3 Acc = 95.29 **************
INFO:root:************* Client 1 Acc = 97.27 **************
INFO:root:************* Server Acc = 86.17 **************
INFO:root:Round 24 Time: 40.273611068725586s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 278, 1: 188, 2: 941, 3: 1325, 4: 27, 5: 100, 6: 255, 7: 2869, 8: 1, 9: 3810}, 1: {0: 2413, 1: 2049, 2: 871, 3: 875, 4: 2454, 5: 505, 6: 2, 7: 90, 8: 4385}, 2: {0: 184, 1: 1069, 2: 3042, 3: 1099, 4: 3339, 5: 239, 6: 3459}, 3: {0: 51, 1: 410, 2: 1144, 3: 2700, 4: 118, 5: 4895, 6: 1431, 7: 261, 8: 1093}, 4: {0: 3074, 1: 2284, 2: 2, 3: 1, 4: 62, 5: 261, 6: 853, 7: 2780, 8: 521, 9: 2190}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 9794
INFO:root:client_idx = 0, batch_num_train_local = 153, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13644
INFO:root:client_idx = 1, batch_num_train_local = 213, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 12431
INFO:root:client_idx = 2, batch_num_train_local = 194, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 12103
INFO:root:client_idx = 3, batch_num_train_local = 189, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12028
INFO:root:client_idx = 4, batch_num_train_local = 187, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.940690  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.851776  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.810694  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.367861  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.913731  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 80.85 **************
INFO:root:************* Client 4 Acc = 81.18 **************
INFO:root:************* Client 3 Acc = 79.37 **************
INFO:root:************* Client 2 Acc = 52.41 **************
INFO:root:************* Client 1 Acc = 76.04 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 46.28252339363098s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.663530  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.625484  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.143773  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.560051  Thread 3  Map [4]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.625904  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 83.05 **************
INFO:root:************* Client 3 Acc = 80.62 **************
INFO:root:************* Client 4 Acc = 80.41 **************
INFO:root:************* Client 2 Acc = 65.49 **************
INFO:root:************* Client 1 Acc = 83.27 **************
INFO:root:************* Server Acc = 24.41 **************
INFO:root:Round 1 Time: 37.04942750930786s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.477000  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.489976  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.443221  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.999504  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.483020  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 86.81 **************
INFO:root:************* Client 4 Acc = 89.62 **************
INFO:root:************* Client 3 Acc = 80.63 **************
INFO:root:************* Client 2 Acc = 67.19 **************
INFO:root:************* Client 1 Acc = 82.20 **************
INFO:root:************* Server Acc = 24.67 **************
INFO:root:Round 2 Time: 37.446234941482544s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.395518  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.426154  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.358333  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.868297  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 77.82 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.403364  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 86.87 **************
INFO:root:************* Client 4 Acc = 89.82 **************
INFO:root:************* Client 2 Acc = 72.54 **************
INFO:root:************* Client 1 Acc = 86.86 **************
INFO:root:************* Server Acc = 38.30 **************
INFO:root:Round 3 Time: 38.02344846725464s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.355440  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.367157  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.309163  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.807585  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 88.52 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.363801  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 86.59 **************
INFO:root:************* Client 4 Acc = 89.94 **************
INFO:root:************* Client 2 Acc = 70.73 **************
INFO:root:************* Client 1 Acc = 89.02 **************
INFO:root:************* Server Acc = 60.31 **************
INFO:root:Round 4 Time: 37.6782751083374s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.321807  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.285820  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.346671  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.767353  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 91.45 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.326599  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 91.18 **************
INFO:root:************* Client 3 Acc = 88.35 **************
INFO:root:************* Client 2 Acc = 72.02 **************
INFO:root:************* Client 1 Acc = 89.34 **************
INFO:root:************* Server Acc = 67.86 **************
INFO:root:Round 5 Time: 38.48257660865784s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.308679  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.265160  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.308459  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.720298  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.304114  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 91.57 **************
INFO:root:************* Client 4 Acc = 91.99 **************
INFO:root:************* Client 3 Acc = 90.52 **************
INFO:root:************* Client 2 Acc = 68.19 **************
INFO:root:************* Client 1 Acc = 89.03 **************
INFO:root:************* Server Acc = 75.70 **************
INFO:root:Round 6 Time: 37.285435914993286s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.275841  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.255999  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.294520  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.669244  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 91.57 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.287385  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 90.42 **************
INFO:root:************* Client 3 Acc = 89.42 **************
INFO:root:************* Client 2 Acc = 79.17 **************
INFO:root:************* Client 1 Acc = 91.70 **************
INFO:root:************* Server Acc = 73.27 **************
INFO:root:Round 7 Time: 39.65098977088928s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.264423  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.241034  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.280251  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.620883  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.274179  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 93.00 **************
INFO:root:************* Client 3 Acc = 90.87 **************
INFO:root:************* Client 2 Acc = 72.34 **************
INFO:root:************* Client 1 Acc = 92.24 **************
INFO:root:************* Server Acc = 77.76 **************
INFO:root:Round 8 Time: 37.54379463195801s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.255838  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.231687  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.265176  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.577366  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 91.56 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.249642  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 93.71 **************
INFO:root:************* Client 3 Acc = 91.96 **************
INFO:root:************* Client 2 Acc = 80.67 **************
INFO:root:************* Client 1 Acc = 91.94 **************
INFO:root:************* Server Acc = 78.52 **************
INFO:root:Round 9 Time: 39.63214564323425s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.242431  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.219173  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.244687  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.545088  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.232322  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 92.92 **************
INFO:root:************* Client 4 Acc = 92.36 **************
INFO:root:************* Client 3 Acc = 92.61 **************
INFO:root:************* Client 2 Acc = 83.15 **************
INFO:root:************* Client 1 Acc = 93.71 **************
INFO:root:************* Server Acc = 82.20 **************
INFO:root:Round 10 Time: 37.12621307373047s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.230781  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.211660  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.237074  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.528734  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 92.30 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.219090  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 92.86 **************
INFO:root:************* Client 3 Acc = 92.07 **************
INFO:root:************* Client 2 Acc = 75.90 **************
INFO:root:************* Client 1 Acc = 94.05 **************
INFO:root:************* Server Acc = 82.77 **************
INFO:root:Round 11 Time: 38.865179777145386s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.224769  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.203602  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.226110  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.501153  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.200602  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 87.58 **************
INFO:root:************* Client 4 Acc = 94.02 **************
INFO:root:************* Client 3 Acc = 93.01 **************
INFO:root:************* Client 2 Acc = 81.02 **************
INFO:root:************* Client 1 Acc = 94.66 **************
INFO:root:************* Server Acc = 85.44 **************
INFO:root:Round 12 Time: 38.39801216125488s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.220137  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.195687  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.224156  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.483174  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.194547  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 93.79 **************
INFO:root:************* Client 4 Acc = 93.01 **************
INFO:root:************* Client 3 Acc = 93.44 **************
INFO:root:************* Client 2 Acc = 84.46 **************
INFO:root:************* Client 1 Acc = 93.73 **************
INFO:root:************* Server Acc = 85.46 **************
INFO:root:Round 13 Time: 37.980600118637085s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.203121  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.187226  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.211104  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.475210  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 93.63 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.189983  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 94.28 **************
INFO:root:************* Client 3 Acc = 93.94 **************
INFO:root:************* Client 2 Acc = 84.55 **************
INFO:root:************* Client 1 Acc = 93.68 **************
INFO:root:************* Server Acc = 85.79 **************
INFO:root:Round 14 Time: 38.76639795303345s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.208331  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.184468  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.209816  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.449441  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 92.81 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.183940  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 92.41 **************
INFO:root:************* Client 3 Acc = 93.53 **************
INFO:root:************* Client 2 Acc = 81.79 **************
INFO:root:************* Client 1 Acc = 94.98 **************
INFO:root:************* Server Acc = 87.59 **************
INFO:root:Round 15 Time: 37.82985734939575s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.201330  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.179970  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.196371  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.447617  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.177802  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 94.31 **************
INFO:root:************* Client 4 Acc = 94.55 **************
INFO:root:************* Client 3 Acc = 93.61 **************
INFO:root:************* Client 2 Acc = 80.36 **************
INFO:root:************* Client 1 Acc = 94.62 **************
INFO:root:************* Server Acc = 86.88 **************
INFO:root:Round 16 Time: 37.11596655845642s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.196929  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.176005  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.191510  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.440738  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.170033  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 93.94 **************
INFO:root:************* Client 4 Acc = 94.82 **************
INFO:root:************* Client 3 Acc = 93.86 **************
INFO:root:************* Client 2 Acc = 85.69 **************
INFO:root:************* Client 1 Acc = 94.98 **************
INFO:root:************* Server Acc = 86.65 **************
INFO:root:Round 17 Time: 36.762046813964844s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.192300  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.173620  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.181527  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.437104  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.161330  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 94.74 **************
INFO:root:************* Client 4 Acc = 94.73 **************
INFO:root:************* Client 3 Acc = 93.92 **************
INFO:root:************* Client 2 Acc = 85.43 **************
INFO:root:************* Client 1 Acc = 95.28 **************
INFO:root:************* Server Acc = 87.30 **************
INFO:root:Round 18 Time: 37.34342980384827s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.175769  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.159564  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.180640  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.422994  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.161576  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 95.03 **************
INFO:root:************* Client 4 Acc = 93.83 **************
INFO:root:************* Client 3 Acc = 94.31 **************
INFO:root:************* Client 2 Acc = 84.00 **************
INFO:root:************* Client 1 Acc = 95.19 **************
INFO:root:************* Server Acc = 88.12 **************
INFO:root:Round 19 Time: 36.548495292663574s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.174667  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.156565  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.178137  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.411823  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.159901  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 94.46 **************
INFO:root:************* Client 4 Acc = 95.01 **************
INFO:root:************* Client 3 Acc = 94.25 **************
INFO:root:************* Client 2 Acc = 86.90 **************
INFO:root:************* Client 1 Acc = 95.69 **************
INFO:root:************* Server Acc = 88.45 **************
INFO:root:Round 20 Time: 36.82608437538147s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.180250  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.166327  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.170170  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.403223  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.153049  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 94.57 **************
INFO:root:************* Client 4 Acc = 95.41 **************
INFO:root:************* Client 3 Acc = 89.92 **************
INFO:root:************* Client 2 Acc = 84.28 **************
INFO:root:************* Client 1 Acc = 94.85 **************
INFO:root:************* Server Acc = 88.38 **************
INFO:root:Round 21 Time: 36.22363829612732s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.179127  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.158286  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.172675  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.404261  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 95.31 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.150210  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 94.59 **************
INFO:root:************* Client 4 Acc = 95.20 **************
INFO:root:************* Client 2 Acc = 87.46 **************
INFO:root:************* Client 1 Acc = 95.68 **************
INFO:root:************* Server Acc = 88.23 **************
INFO:root:Round 22 Time: 36.541216135025024s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.169243  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.154380  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.169452  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.393009  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.147400  Thread 4  Map [1]
INFO:root:************* Client 0 Acc = 94.79 **************
INFO:root:************* Client 4 Acc = 94.87 **************
INFO:root:************* Client 3 Acc = 95.07 **************
INFO:root:************* Client 2 Acc = 87.54 **************
INFO:root:************* Client 1 Acc = 95.76 **************
INFO:root:************* Server Acc = 88.21 **************
INFO:root:Round 23 Time: 36.52511787414551s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.165672  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.164057  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.152027  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.387371  Thread 5  Map [2]
INFO:root:************* Client 0 Acc = 95.06 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.149908  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 94.93 **************
INFO:root:************* Client 3 Acc = 95.08 **************
INFO:root:************* Client 2 Acc = 87.69 **************
INFO:root:************* Client 1 Acc = 95.13 **************
INFO:root:************* Server Acc = 88.32 **************
INFO:root:Round 24 Time: 37.37144637107849s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {2: 109, 3: 1, 8: 7, 9: 487}, 1: {0: 1412, 1: 2433, 2: 77, 3: 1151, 4: 2259, 5: 9, 7: 5999}, 2: {1: 227, 2: 5559, 3: 475, 4: 3740, 6: 5574}, 3: {1: 2, 2: 255, 3: 801, 5: 132, 6: 426, 7: 1, 8: 5993, 9: 5513}, 4: {0: 4588, 1: 3338, 3: 3572, 4: 1, 5: 5859}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 604
INFO:root:client_idx = 0, batch_num_train_local = 9, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13340
INFO:root:client_idx = 1, batch_num_train_local = 208, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 15575
INFO:root:client_idx = 2, batch_num_train_local = 243, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 13123
INFO:root:client_idx = 3, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 17358
INFO:root:client_idx = 4, batch_num_train_local = 271, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.027041  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 18.23 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.636642  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.571737  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.411888  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.207238  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 93.57 **************
INFO:root:************* Client 1 Acc = 89.08 **************
INFO:root:************* Client 4 Acc = 90.62 **************
INFO:root:************* Client 2 Acc = 59.24 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 49.36995458602905s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.173252  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 17.01 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.447480  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.383176  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.063439  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.284627  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 92.78 **************
INFO:root:************* Client 1 Acc = 91.44 **************
INFO:root:************* Client 2 Acc = 63.39 **************
INFO:root:************* Client 4 Acc = 93.70 **************
INFO:root:************* Server Acc = 10.02 **************
INFO:root:Round 1 Time: 40.46136164665222s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.786545  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.97 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.289812  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.264250  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.913333  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.226536  Thread 4  Map [4]
INFO:root:************* Client 1 Acc = 93.52 **************
INFO:root:************* Client 3 Acc = 94.77 **************
INFO:root:************* Client 2 Acc = 70.40 **************
INFO:root:************* Client 4 Acc = 82.26 **************
INFO:root:************* Server Acc = 12.67 **************
INFO:root:Round 2 Time: 39.85141110420227s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.651624  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.66 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.226244  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.239953  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.800532  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.178046  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 95.79 **************
INFO:root:************* Client 1 Acc = 94.52 **************
INFO:root:************* Client 2 Acc = 72.67 **************
INFO:root:************* Client 4 Acc = 95.57 **************
INFO:root:************* Server Acc = 36.56 **************
INFO:root:Round 3 Time: 40.63061308860779s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.474494  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.178558  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.184452  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.682104  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.163114  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 96.57 **************
INFO:root:************* Client 1 Acc = 94.83 **************
INFO:root:************* Client 2 Acc = 73.55 **************
INFO:root:************* Client 4 Acc = 96.22 **************
INFO:root:************* Server Acc = 45.45 **************
INFO:root:Round 4 Time: 41.43819499015808s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.590302  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.169765  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.204685  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.123678  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.620600  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 96.87 **************
INFO:root:************* Client 1 Acc = 96.03 **************
INFO:root:************* Client 2 Acc = 78.99 **************
INFO:root:************* Client 4 Acc = 95.65 **************
INFO:root:************* Server Acc = 45.33 **************
INFO:root:Round 5 Time: 39.81521797180176s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.460947  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.27 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.132267  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.147310  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.571218  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.120917  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 97.07 **************
INFO:root:************* Client 1 Acc = 96.21 **************
INFO:root:************* Client 2 Acc = 82.43 **************
INFO:root:************* Client 4 Acc = 97.19 **************
INFO:root:************* Server Acc = 48.92 **************
INFO:root:Round 6 Time: 44.157142162323s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.548738  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 91.49 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.143059  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.155532  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.531011  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 97.13 **************
INFO:root:************* Client 1 Acc = 95.80 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.102655  Thread 4  Map [4]
INFO:root:************* Client 2 Acc = 80.31 **************
INFO:root:************* Client 4 Acc = 96.85 **************
INFO:root:************* Server Acc = 55.91 **************
INFO:root:Round 7 Time: 41.963324785232544s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.295989  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.125900  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.109689  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.495636  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.105340  Thread 4  Map [4]
INFO:root:************* Client 1 Acc = 96.93 **************
INFO:root:************* Client 3 Acc = 97.55 **************
INFO:root:************* Client 2 Acc = 80.96 **************
INFO:root:************* Client 4 Acc = 96.04 **************
INFO:root:************* Server Acc = 57.61 **************
INFO:root:Round 8 Time: 39.899203062057495s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.444849  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 93.58 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.121306  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.144061  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.090063  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492321  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 97.88 **************
INFO:root:************* Client 1 Acc = 97.22 **************
INFO:root:************* Client 4 Acc = 95.84 **************
INFO:root:************* Client 2 Acc = 79.87 **************
INFO:root:************* Server Acc = 66.20 **************
INFO:root:Round 9 Time: 41.34831953048706s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.313232  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 90.80 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.098607  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.116481  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.476602  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.093023  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 97.50 **************
INFO:root:************* Client 1 Acc = 71.50 **************
INFO:root:************* Client 2 Acc = 82.51 **************
INFO:root:************* Client 4 Acc = 97.69 **************
INFO:root:************* Server Acc = 60.13 **************
INFO:root:Round 10 Time: 41.45114874839783s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.539178  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.97 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.094592  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.124775  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.449652  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080647  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 97.58 **************
INFO:root:************* Client 1 Acc = 97.09 **************
INFO:root:************* Client 2 Acc = 83.33 **************
INFO:root:************* Client 4 Acc = 97.38 **************
INFO:root:************* Server Acc = 74.05 **************
INFO:root:Round 11 Time: 39.47078800201416s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.220011  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.086165  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.098935  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.438739  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.082116  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.01 **************
INFO:root:************* Client 1 Acc = 96.31 **************
INFO:root:************* Client 2 Acc = 82.84 **************
INFO:root:************* Client 4 Acc = 97.76 **************
INFO:root:************* Server Acc = 60.81 **************
INFO:root:Round 12 Time: 39.707502126693726s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.413735  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.091019  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.111002  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.428581  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 98.22 **************
INFO:root:************* Client 1 Acc = 97.27 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.072997  Thread 4  Map [4]
INFO:root:************* Client 2 Acc = 84.66 **************
INFO:root:************* Client 4 Acc = 97.46 **************
INFO:root:************* Server Acc = 74.76 **************
INFO:root:Round 13 Time: 42.08891797065735s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.294170  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.53 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.078414  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.090986  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.417032  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 98.36 **************
INFO:root:************* Client 1 Acc = 97.32 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.075995  Thread 4  Map [4]
INFO:root:************* Client 2 Acc = 85.32 **************
INFO:root:************* Client 4 Acc = 97.85 **************
INFO:root:************* Server Acc = 65.08 **************
INFO:root:Round 14 Time: 42.58160448074341s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.408513  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.70 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.080988  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.115515  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.417968  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 98.49 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.067503  Thread 4  Map [4]
INFO:root:************* Client 1 Acc = 97.97 **************
INFO:root:************* Client 2 Acc = 83.01 **************
INFO:root:************* Client 4 Acc = 91.63 **************
INFO:root:************* Server Acc = 78.43 **************
INFO:root:Round 15 Time: 43.024757385253906s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.319762  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.01 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.074196  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.083009  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.401969  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.073339  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.38 **************
INFO:root:************* Client 1 Acc = 97.94 **************
INFO:root:************* Client 2 Acc = 87.11 **************
INFO:root:************* Client 4 Acc = 97.41 **************
INFO:root:************* Server Acc = 69.86 **************
INFO:root:Round 16 Time: 39.639551639556885s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.317995  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 91.15 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.073828  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.109259  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.400155  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 98.57 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.064494  Thread 4  Map [4]
INFO:root:************* Client 1 Acc = 97.70 **************
INFO:root:************* Client 2 Acc = 85.76 **************
INFO:root:************* Client 4 Acc = 98.44 **************
INFO:root:************* Server Acc = 79.70 **************
INFO:root:Round 17 Time: 42.06831121444702s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.370163  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.27 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.074348  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.078885  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.382179  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 98.57 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.065268  Thread 4  Map [4]
INFO:root:************* Client 1 Acc = 98.12 **************
INFO:root:************* Client 2 Acc = 85.84 **************
INFO:root:************* Client 4 Acc = 98.17 **************
INFO:root:************* Server Acc = 74.52 **************
INFO:root:Round 18 Time: 41.77382707595825s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.269408  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.57 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.067148  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.096280  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.060596  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.377664  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 98.43 **************
INFO:root:************* Client 1 Acc = 97.89 **************
INFO:root:************* Client 4 Acc = 98.35 **************
INFO:root:************* Client 2 Acc = 85.49 **************
INFO:root:************* Server Acc = 81.51 **************
INFO:root:Round 19 Time: 39.78365159034729s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.346225  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.31 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.075373  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.065655  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.373666  Thread 5  Map [2]
INFO:root:************* Client 1 Acc = 98.14 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.062679  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.74 **************
INFO:root:************* Client 2 Acc = 87.93 **************
INFO:root:************* Client 4 Acc = 98.34 **************
INFO:root:************* Server Acc = 76.68 **************
INFO:root:Round 20 Time: 41.869162797927856s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.291983  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.79 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.065358  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.084310  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.367392  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.055950  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.61 **************
INFO:root:************* Client 1 Acc = 98.17 **************
INFO:root:************* Client 2 Acc = 85.67 **************
INFO:root:************* Client 4 Acc = 98.30 **************
INFO:root:************* Server Acc = 82.90 **************
INFO:root:Round 21 Time: 39.86506485939026s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.285426  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.35 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.063483  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.072919  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.368237  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.060537  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.78 **************
INFO:root:************* Client 1 Acc = 97.94 **************
INFO:root:************* Client 2 Acc = 85.95 **************
INFO:root:************* Client 4 Acc = 98.05 **************
INFO:root:************* Server Acc = 75.68 **************
INFO:root:Round 22 Time: 39.95160889625549s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.316469  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.14 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.065144  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.088845  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.352177  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 98.57 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.057974  Thread 4  Map [4]
INFO:root:************* Client 1 Acc = 98.26 **************
INFO:root:************* Client 2 Acc = 87.12 **************
INFO:root:************* Client 4 Acc = 98.45 **************
INFO:root:************* Server Acc = 76.74 **************
INFO:root:Round 23 Time: 42.732444286346436s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.314526  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.66 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.066206  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.068576  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.351590  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.056382  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.75 **************
INFO:root:************* Client 1 Acc = 98.29 **************
INFO:root:************* Client 2 Acc = 85.27 **************
INFO:root:************* Client 4 Acc = 98.01 **************
INFO:root:************* Server Acc = 76.73 **************
INFO:root:Round 24 Time: 40.19371438026428s
INFO:root:************** Round: 25 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.212944  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.88 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.061540  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.085229  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.349258  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.052740  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.89 **************
INFO:root:************* Client 1 Acc = 98.22 **************
INFO:root:************* Client 2 Acc = 87.47 **************
INFO:root:************* Client 4 Acc = 98.01 **************
INFO:root:************* Server Acc = 80.42 **************
INFO:root:Round 25 Time: 39.6236093044281s
INFO:root:************** Round: 26 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.275319  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.057939  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.067430  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.339043  Thread 5  Map [2]
INFO:root:************* Client 3 Acc = 98.53 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.055991  Thread 4  Map [4]
INFO:root:************* Client 1 Acc = 98.08 **************
INFO:root:************* Client 2 Acc = 88.62 **************
INFO:root:************* Client 4 Acc = 98.66 **************
INFO:root:************* Server Acc = 76.07 **************
INFO:root:Round 26 Time: 43.262993574142456s
INFO:root:************** Round: 27 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.309509  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 91.84 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.085331  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.055803  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.341954  Thread 5  Map [2]
INFO:root:************* Client 1 Acc = 98.02 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.050795  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.75 **************
INFO:root:************* Client 2 Acc = 89.94 **************
INFO:root:************* Client 4 Acc = 98.77 **************
INFO:root:************* Server Acc = 81.18 **************
INFO:root:Round 27 Time: 42.482969999313354s
INFO:root:************** Round: 28 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.226167  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.92 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.054398  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.065890  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.337040  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.053334  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.63 **************
INFO:root:************* Client 1 Acc = 98.22 **************
INFO:root:************* Client 2 Acc = 84.79 **************
INFO:root:************* Client 4 Acc = 98.88 **************
INFO:root:************* Server Acc = 76.84 **************
INFO:root:Round 28 Time: 42.104082345962524s
INFO:root:************** Round: 29 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.175450  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.05 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.054804  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.080582  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.333856  Thread 5  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.048889  Thread 4  Map [4]
INFO:root:************* Client 3 Acc = 98.89 **************
INFO:root:************* Client 1 Acc = 89.87 **************
INFO:root:************* Client 2 Acc = 88.69 **************
INFO:root:************* Client 4 Acc = 98.73 **************
INFO:root:************* Server Acc = 84.20 **************
INFO:root:Round 29 Time: 39.78658938407898s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 9, 1: 1, 2: 572, 3: 39, 5: 2, 6: 20, 7: 45, 9: 941}, 1: {0: 2137, 1: 145, 2: 477, 3: 1160, 4: 2317, 5: 150, 7: 4084, 8: 5756}, 2: {0: 3, 1: 14, 2: 4079, 3: 690, 4: 3675, 5: 23, 6: 4697}, 3: {1: 554, 2: 871, 3: 914, 4: 8, 5: 5825, 6: 1283, 7: 1871, 8: 244, 9: 5059}, 4: {0: 3851, 1: 5286, 2: 1, 3: 3197}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 1629
INFO:root:client_idx = 0, batch_num_train_local = 25, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 16226
INFO:root:client_idx = 1, batch_num_train_local = 253, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 13181
INFO:root:client_idx = 2, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 16629
INFO:root:client_idx = 3, batch_num_train_local = 259, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12335
INFO:root:client_idx = 4, batch_num_train_local = 192, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.191621  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 77.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.594129  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.246425  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.704411  Thread 1  Map [1]
INFO:root:************* Client 4 Acc = 87.79 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.764663  Thread 3  Map [3]
INFO:root:************* Client 2 Acc = 49.63 **************
INFO:root:************* Client 1 Acc = 87.93 **************
INFO:root:************* Client 3 Acc = 83.83 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 50.02190351486206s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.783890  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 84.75 **************
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.097392  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.416758  Thread 4  Map [4]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.481796  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.549579  Thread 3  Map [3]
INFO:root:************* Client 2 Acc = 51.41 **************
INFO:root:************* Client 4 Acc = 90.31 **************
INFO:root:************* Client 1 Acc = 89.10 **************
INFO:root:************* Client 3 Acc = 85.49 **************
INFO:root:************* Server Acc = 18.81 **************
INFO:root:Round 1 Time: 40.367695808410645s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.468395  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 94.56 **************
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.969713  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.299670  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.415851  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.374758  Thread 1  Map [1]
INFO:root:************* Client 2 Acc = 61.58 **************
INFO:root:************* Client 4 Acc = 89.55 **************
INFO:root:************* Client 3 Acc = 87.29 **************
INFO:root:************* Client 1 Acc = 86.94 **************
INFO:root:************* Server Acc = 19.45 **************
INFO:root:Round 2 Time: 40.38538074493408s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.454775  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 95.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.251850  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.892320  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 84.30 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.311031  Thread 1  Map [1]
INFO:root:************* Client 2 Acc = 71.62 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.348528  Thread 3  Map [3]
INFO:root:************* Client 1 Acc = 91.78 **************
INFO:root:************* Client 3 Acc = 81.66 **************
INFO:root:************* Server Acc = 38.08 **************
INFO:root:Round 3 Time: 42.9786741733551s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.410940  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 96.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.211652  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.798560  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.260912  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.311323  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 93.42 **************
INFO:root:************* Client 2 Acc = 53.44 **************
INFO:root:************* Client 1 Acc = 92.83 **************
INFO:root:************* Client 3 Acc = 88.75 **************
INFO:root:************* Server Acc = 56.50 **************
INFO:root:Round 4 Time: 42.151110887527466s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.321703  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 96.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.179693  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.724975  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.243230  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.274511  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 95.54 **************
INFO:root:************* Client 2 Acc = 77.23 **************
INFO:root:************* Client 1 Acc = 93.31 **************
INFO:root:************* Client 3 Acc = 90.86 **************
INFO:root:************* Server Acc = 63.41 **************
INFO:root:Round 5 Time: 40.894391775131226s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.289231  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.175810  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.653504  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.207697  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.248916  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 95.08 **************
INFO:root:************* Client 2 Acc = 67.57 **************
INFO:root:************* Client 1 Acc = 93.35 **************
INFO:root:************* Client 3 Acc = 92.10 **************
INFO:root:************* Server Acc = 66.77 **************
INFO:root:Round 6 Time: 42.211649894714355s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.288333  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.156545  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.621437  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.195398  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.229942  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 95.39 **************
INFO:root:************* Client 2 Acc = 80.28 **************
INFO:root:************* Client 1 Acc = 93.52 **************
INFO:root:************* Client 3 Acc = 92.59 **************
INFO:root:************* Server Acc = 68.42 **************
INFO:root:Round 7 Time: 40.98405933380127s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.301378  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.145729  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.594954  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.187767  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.216074  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 94.62 **************
INFO:root:************* Client 2 Acc = 80.05 **************
INFO:root:************* Client 1 Acc = 94.87 **************
INFO:root:************* Client 3 Acc = 93.90 **************
INFO:root:************* Server Acc = 76.68 **************
INFO:root:Round 8 Time: 40.168174743652344s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.204091  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.128206  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.552115  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.169568  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.203820  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 91.25 **************
INFO:root:************* Client 2 Acc = 81.65 **************
INFO:root:************* Client 3 Acc = 93.32 **************
INFO:root:************* Client 1 Acc = 95.49 **************
INFO:root:************* Server Acc = 75.26 **************
INFO:root:Round 9 Time: 41.13792681694031s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.268808  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.134267  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.531505  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.187895  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 96.64 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.161498  Thread 1  Map [1]
INFO:root:************* Client 2 Acc = 76.09 **************
INFO:root:************* Client 3 Acc = 93.23 **************
INFO:root:************* Client 1 Acc = 94.86 **************
INFO:root:************* Server Acc = 79.12 **************
INFO:root:Round 10 Time: 41.773948192596436s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.231791  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.115268  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.506428  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.153300  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.187356  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 96.74 **************
INFO:root:************* Client 2 Acc = 78.94 **************
INFO:root:************* Client 1 Acc = 95.76 **************
INFO:root:************* Client 3 Acc = 93.91 **************
INFO:root:************* Server Acc = 78.23 **************
INFO:root:Round 11 Time: 42.28024911880493s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.210604  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.112629  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492731  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.146965  Thread 1  Map [1]
INFO:root:************* Client 4 Acc = 93.90 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.174953  Thread 3  Map [3]
INFO:root:************* Client 2 Acc = 82.96 **************
INFO:root:************* Client 1 Acc = 96.02 **************
INFO:root:************* Client 3 Acc = 94.40 **************
INFO:root:************* Server Acc = 83.14 **************
INFO:root:Round 12 Time: 39.913907527923584s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.173142  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.110098  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.492061  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.139767  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.171370  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 96.21 **************
INFO:root:************* Client 2 Acc = 84.84 **************
INFO:root:************* Client 1 Acc = 96.25 **************
INFO:root:************* Client 3 Acc = 94.64 **************
INFO:root:************* Server Acc = 82.21 **************
INFO:root:Round 13 Time: 41.608787059783936s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.240161  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 96.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.105015  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.463633  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.135303  Thread 1  Map [1]
INFO:root:************* Client 4 Acc = 96.40 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.159104  Thread 3  Map [3]
INFO:root:************* Client 2 Acc = 81.81 **************
INFO:root:************* Client 3 Acc = 95.17 **************
INFO:root:************* Client 1 Acc = 96.45 **************
INFO:root:************* Server Acc = 84.87 **************
INFO:root:Round 14 Time: 40.06932520866394s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.150037  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.101816  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.454237  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.31 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.130484  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.153991  Thread 3  Map [3]
INFO:root:************* Client 2 Acc = 84.59 **************
INFO:root:************* Client 3 Acc = 94.99 **************
INFO:root:************* Client 1 Acc = 96.04 **************
INFO:root:************* Server Acc = 84.99 **************
INFO:root:Round 15 Time: 42.288569927215576s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.182089  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.25 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094721  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.435414  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.126873  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.155054  Thread 3  Map [3]
INFO:root:************* Client 2 Acc = 80.53 **************
INFO:root:************* Client 4 Acc = 97.42 **************
INFO:root:************* Client 3 Acc = 95.08 **************
INFO:root:************* Client 1 Acc = 96.79 **************
INFO:root:************* Server Acc = 85.08 **************
INFO:root:Round 16 Time: 40.199965715408325s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.171394  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094917  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.430404  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.121561  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.153726  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 95.19 **************
INFO:root:************* Client 2 Acc = 85.71 **************
INFO:root:************* Client 3 Acc = 95.10 **************
INFO:root:************* Client 1 Acc = 96.71 **************
INFO:root:************* Server Acc = 85.21 **************
INFO:root:Round 17 Time: 41.63568615913391s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.145238  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.44 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.092645  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.423865  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.116153  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.146056  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 97.59 **************
INFO:root:************* Client 2 Acc = 84.94 **************
INFO:root:************* Client 3 Acc = 94.96 **************
INFO:root:************* Client 1 Acc = 97.04 **************
INFO:root:************* Server Acc = 85.53 **************
INFO:root:Round 18 Time: 40.28332757949829s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.160639  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 98.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.087574  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.423538  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.110942  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.141132  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 97.60 **************
INFO:root:************* Client 2 Acc = 84.66 **************
INFO:root:************* Client 3 Acc = 94.97 **************
INFO:root:************* Client 1 Acc = 97.10 **************
INFO:root:************* Server Acc = 85.91 **************
INFO:root:Round 19 Time: 41.756519079208374s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.166988  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.084465  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.411941  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.109627  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.136136  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 97.40 **************
INFO:root:************* Client 2 Acc = 84.87 **************
INFO:root:************* Client 3 Acc = 94.69 **************
INFO:root:************* Client 1 Acc = 97.36 **************
INFO:root:************* Server Acc = 86.28 **************
INFO:root:Round 20 Time: 41.564475297927856s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.183084  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.44 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.083771  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.406734  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.137794  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.105679  Thread 1  Map [1]
INFO:root:************* Client 4 Acc = 93.13 **************
INFO:root:************* Client 2 Acc = 87.44 **************
INFO:root:************* Client 3 Acc = 95.86 **************
INFO:root:************* Client 1 Acc = 97.05 **************
INFO:root:************* Server Acc = 85.72 **************
INFO:root:Round 21 Time: 40.234435081481934s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.165445  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 96.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.083648  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.396348  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.131448  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 97.92 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.103094  Thread 1  Map [1]
INFO:root:************* Client 2 Acc = 85.50 **************
INFO:root:************* Client 3 Acc = 95.34 **************
INFO:root:************* Client 1 Acc = 96.99 **************
INFO:root:************* Server Acc = 86.11 **************
INFO:root:Round 22 Time: 40.09606146812439s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.152653  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.087670  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.390209  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.48 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.133672  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.103183  Thread 1  Map [1]
INFO:root:************* Client 2 Acc = 87.58 **************
INFO:root:************* Client 3 Acc = 95.95 **************
INFO:root:************* Client 1 Acc = 97.39 **************
INFO:root:************* Server Acc = 87.21 **************
INFO:root:Round 23 Time: 40.90236568450928s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.157288  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 98.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.074498  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.393721  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.126398  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 97.31 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.100470  Thread 1  Map [1]
INFO:root:************* Client 2 Acc = 87.96 **************
INFO:root:************* Client 3 Acc = 95.29 **************
INFO:root:************* Client 1 Acc = 97.27 **************
INFO:root:************* Server Acc = 86.17 **************
INFO:root:Round 24 Time: 39.99609565734863s
INFO:root:************** Round: 25 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.184089  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.075474  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.382772  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.099918  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.123490  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 97.92 **************
INFO:root:************* Client 2 Acc = 87.76 **************
INFO:root:************* Client 1 Acc = 97.50 **************
INFO:root:************* Client 3 Acc = 95.29 **************
INFO:root:************* Server Acc = 86.45 **************
INFO:root:Round 25 Time: 40.93792247772217s
INFO:root:************** Round: 26 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.142839  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 98.06 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.078388  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.373516  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.126412  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 97.92 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.099161  Thread 1  Map [1]
INFO:root:************* Client 2 Acc = 87.68 **************
INFO:root:************* Client 3 Acc = 96.30 **************
INFO:root:************* Client 1 Acc = 97.32 **************
INFO:root:************* Server Acc = 86.97 **************
INFO:root:Round 26 Time: 39.89281153678894s
INFO:root:************** Round: 27 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.150124  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 97.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.077247  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.368950  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.090273  Thread 1  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.125600  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 97.75 **************
INFO:root:************* Client 2 Acc = 83.41 **************
INFO:root:************* Client 1 Acc = 97.52 **************
INFO:root:************* Client 3 Acc = 96.64 **************
INFO:root:************* Server Acc = 86.41 **************
INFO:root:Round 27 Time: 41.03095316886902s
INFO:root:************** Round: 28 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.119935  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 98.25 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.071589  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.367222  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 98.10 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.120289  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.090142  Thread 1  Map [1]
INFO:root:************* Client 2 Acc = 78.92 **************
INFO:root:************* Client 3 Acc = 94.53 **************
INFO:root:************* Client 1 Acc = 96.74 **************
INFO:root:************* Server Acc = 88.24 **************
INFO:root:Round 28 Time: 41.967920780181885s
INFO:root:************** Round: 29 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.136771  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 98.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.074592  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.355041  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.119010  Thread 3  Map [3]
INFO:root:************* Client 4 Acc = 98.33 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.087422  Thread 1  Map [1]
INFO:root:************* Client 2 Acc = 88.81 **************
INFO:root:************* Client 3 Acc = 95.77 **************
INFO:root:************* Client 1 Acc = 97.72 **************
INFO:root:************* Server Acc = 87.66 **************
INFO:root:Round 29 Time: 40.00700402259827s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 278, 1: 188, 2: 941, 3: 1325, 4: 27, 5: 100, 6: 255, 7: 2869, 8: 1, 9: 3810}, 1: {0: 2413, 1: 2049, 2: 871, 3: 875, 4: 2454, 5: 505, 6: 2, 7: 90, 8: 4385}, 2: {0: 184, 1: 1069, 2: 3042, 3: 1099, 4: 3339, 5: 239, 6: 3459}, 3: {0: 51, 1: 410, 2: 1144, 3: 2700, 4: 118, 5: 4895, 6: 1431, 7: 261, 8: 1093}, 4: {0: 3074, 1: 2284, 2: 2, 3: 1, 4: 62, 5: 261, 6: 853, 7: 2780, 8: 521, 9: 2190}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 9794
INFO:root:client_idx = 0, batch_num_train_local = 153, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13644
INFO:root:client_idx = 1, batch_num_train_local = 213, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 12431
INFO:root:client_idx = 2, batch_num_train_local = 194, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 12103
INFO:root:client_idx = 3, batch_num_train_local = 189, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12028
INFO:root:client_idx = 4, batch_num_train_local = 187, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.940690  Thread 5  Map [0]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.367861  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.810694  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.851776  Thread 2  Map [4]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.913731  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 80.85 **************
INFO:root:************* Client 2 Acc = 52.41 **************
INFO:root:************* Client 4 Acc = 81.18 **************
INFO:root:************* Client 3 Acc = 79.37 **************
INFO:root:************* Client 1 Acc = 76.04 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 46.64843010902405s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.663530  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.625484  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.560051  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.143773  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 83.05 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.625904  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 80.62 **************
INFO:root:************* Client 4 Acc = 80.41 **************
INFO:root:************* Client 2 Acc = 65.49 **************
INFO:root:************* Client 1 Acc = 83.27 **************
INFO:root:************* Server Acc = 24.41 **************
INFO:root:Round 1 Time: 38.271382570266724s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.477000  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.443221  Thread 2  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.489976  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.999504  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.483020  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 86.81 **************
INFO:root:************* Client 3 Acc = 80.63 **************
INFO:root:************* Client 4 Acc = 89.62 **************
INFO:root:************* Client 2 Acc = 67.19 **************
INFO:root:************* Client 1 Acc = 82.20 **************
INFO:root:************* Server Acc = 24.67 **************
INFO:root:Round 2 Time: 36.83100342750549s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.395518  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.358333  Thread 2  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.426154  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.868297  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.403364  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 77.82 **************
INFO:root:************* Client 4 Acc = 89.82 **************
INFO:root:************* Client 3 Acc = 86.87 **************
INFO:root:************* Client 2 Acc = 72.54 **************
INFO:root:************* Client 1 Acc = 86.86 **************
INFO:root:************* Server Acc = 38.30 **************
INFO:root:Round 3 Time: 38.01086354255676s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.355440  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.367157  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.309163  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.807585  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 88.52 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.363801  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 86.59 **************
INFO:root:************* Client 2 Acc = 70.73 **************
INFO:root:************* Client 4 Acc = 89.94 **************
INFO:root:************* Client 1 Acc = 89.02 **************
INFO:root:************* Server Acc = 60.31 **************
INFO:root:Round 4 Time: 38.09190893173218s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.321807  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.346671  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.285820  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.767353  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 91.45 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.326599  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 88.35 **************
INFO:root:************* Client 4 Acc = 91.18 **************
INFO:root:************* Client 2 Acc = 72.02 **************
INFO:root:************* Client 1 Acc = 89.34 **************
INFO:root:************* Server Acc = 67.86 **************
INFO:root:Round 5 Time: 37.97533893585205s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.308679  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.308459  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.720298  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.265160  Thread 2  Map [4]
INFO:root:************* Client 0 Acc = 91.57 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.304114  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 90.52 **************
INFO:root:************* Client 4 Acc = 91.99 **************
INFO:root:************* Client 2 Acc = 68.19 **************
INFO:root:************* Client 1 Acc = 89.03 **************
INFO:root:************* Server Acc = 75.70 **************
INFO:root:Round 6 Time: 38.18033266067505s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.275841  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.294520  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.255999  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.669244  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.287385  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 91.57 **************
INFO:root:************* Client 3 Acc = 89.42 **************
INFO:root:************* Client 4 Acc = 90.42 **************
INFO:root:************* Client 2 Acc = 79.17 **************
INFO:root:************* Client 1 Acc = 91.70 **************
INFO:root:************* Server Acc = 73.27 **************
INFO:root:Round 7 Time: 38.29539608955383s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.264423  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.241034  Thread 2  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.280251  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.620883  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.274179  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:************* Client 3 Acc = 90.87 **************
INFO:root:************* Client 4 Acc = 93.00 **************
INFO:root:************* Client 2 Acc = 72.34 **************
INFO:root:************* Client 1 Acc = 92.24 **************
INFO:root:************* Server Acc = 77.76 **************
INFO:root:Round 8 Time: 36.97775387763977s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.255838  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.231687  Thread 2  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.265176  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.577366  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 91.56 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.249642  Thread 3  Map [1]
INFO:root:************* Client 4 Acc = 93.71 **************
INFO:root:************* Client 3 Acc = 91.96 **************
INFO:root:************* Client 2 Acc = 80.67 **************
INFO:root:************* Client 1 Acc = 91.94 **************
INFO:root:************* Server Acc = 78.52 **************
INFO:root:Round 9 Time: 38.102447509765625s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.242431  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.244687  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.219173  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.545088  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.232322  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 92.92 **************
INFO:root:************* Client 3 Acc = 92.61 **************
INFO:root:************* Client 2 Acc = 83.15 **************
INFO:root:************* Client 4 Acc = 92.36 **************
INFO:root:************* Client 1 Acc = 93.71 **************
INFO:root:************* Server Acc = 82.20 **************
INFO:root:Round 10 Time: 37.15922951698303s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.230781  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.237074  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.211660  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.528734  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.219090  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 92.30 **************
INFO:root:************* Client 3 Acc = 92.07 **************
INFO:root:************* Client 2 Acc = 75.90 **************
INFO:root:************* Client 4 Acc = 92.86 **************
INFO:root:************* Client 1 Acc = 94.05 **************
INFO:root:************* Server Acc = 82.77 **************
INFO:root:Round 11 Time: 37.12246012687683s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.224769  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.226110  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.203602  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.501153  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.200602  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 87.58 **************
INFO:root:************* Client 3 Acc = 93.01 **************
INFO:root:************* Client 4 Acc = 94.02 **************
INFO:root:************* Client 2 Acc = 81.02 **************
INFO:root:************* Client 1 Acc = 94.66 **************
INFO:root:************* Server Acc = 85.44 **************
INFO:root:Round 12 Time: 37.588587045669556s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.220137  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.224156  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.483174  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.195687  Thread 2  Map [4]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.194547  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 93.79 **************
INFO:root:************* Client 3 Acc = 93.44 **************
INFO:root:************* Client 2 Acc = 84.46 **************
INFO:root:************* Client 4 Acc = 93.01 **************
INFO:root:************* Client 1 Acc = 93.73 **************
INFO:root:************* Server Acc = 85.46 **************
INFO:root:Round 13 Time: 37.93616271018982s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.203121  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.211104  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.187226  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.475210  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.189983  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 93.63 **************
INFO:root:************* Client 3 Acc = 93.94 **************
INFO:root:************* Client 4 Acc = 94.28 **************
INFO:root:************* Client 2 Acc = 84.55 **************
INFO:root:************* Client 1 Acc = 93.68 **************
INFO:root:************* Server Acc = 85.79 **************
INFO:root:Round 14 Time: 36.85250520706177s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.208331  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.209816  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.449441  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.184468  Thread 2  Map [4]
INFO:root:************* Client 0 Acc = 92.81 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.183940  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 93.53 **************
INFO:root:************* Client 4 Acc = 92.41 **************
INFO:root:************* Client 2 Acc = 81.79 **************
INFO:root:************* Client 1 Acc = 94.98 **************
INFO:root:************* Server Acc = 87.59 **************
INFO:root:Round 15 Time: 38.16512846946716s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.201330  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.196371  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.179970  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.447617  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.177802  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 94.31 **************
INFO:root:************* Client 3 Acc = 93.61 **************
INFO:root:************* Client 4 Acc = 94.55 **************
INFO:root:************* Client 2 Acc = 80.36 **************
INFO:root:************* Client 1 Acc = 94.62 **************
INFO:root:************* Server Acc = 86.88 **************
INFO:root:Round 16 Time: 37.32964634895325s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.196929  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.176005  Thread 2  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.191510  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.440738  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.170033  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 93.94 **************
INFO:root:************* Client 3 Acc = 93.86 **************
INFO:root:************* Client 2 Acc = 85.69 **************
INFO:root:************* Client 4 Acc = 94.82 **************
INFO:root:************* Client 1 Acc = 94.98 **************
INFO:root:************* Server Acc = 86.65 **************
INFO:root:Round 17 Time: 36.82698607444763s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.192300  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.181527  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.173620  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.437104  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 94.74 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.161330  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 93.92 **************
INFO:root:************* Client 4 Acc = 94.73 **************
INFO:root:************* Client 2 Acc = 85.43 **************
INFO:root:************* Client 1 Acc = 95.28 **************
INFO:root:************* Server Acc = 87.30 **************
INFO:root:Round 18 Time: 38.36363983154297s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.175769  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.180640  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.159564  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.422994  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.161576  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 95.03 **************
INFO:root:************* Client 3 Acc = 94.31 **************
INFO:root:************* Client 4 Acc = 93.83 **************
INFO:root:************* Client 2 Acc = 84.00 **************
INFO:root:************* Client 1 Acc = 95.19 **************
INFO:root:************* Server Acc = 88.12 **************
INFO:root:Round 19 Time: 37.38110637664795s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.174667  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.178137  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.411823  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.156565  Thread 2  Map [4]
INFO:root:************* Client 0 Acc = 94.46 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.159901  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 94.25 **************
INFO:root:************* Client 2 Acc = 86.90 **************
INFO:root:************* Client 4 Acc = 95.01 **************
INFO:root:************* Client 1 Acc = 95.69 **************
INFO:root:************* Server Acc = 88.45 **************
INFO:root:Round 20 Time: 38.195451498031616s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.180250  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.170170  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.403223  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.166327  Thread 2  Map [4]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.153049  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 94.57 **************
INFO:root:************* Client 3 Acc = 89.92 **************
INFO:root:************* Client 2 Acc = 84.28 **************
INFO:root:************* Client 4 Acc = 95.41 **************
INFO:root:************* Client 1 Acc = 94.85 **************
INFO:root:************* Server Acc = 88.38 **************
INFO:root:Round 21 Time: 37.830650091171265s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.179127  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.172675  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.158286  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.404261  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.150210  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 95.31 **************
INFO:root:************* Client 3 Acc = 94.59 **************
INFO:root:************* Client 2 Acc = 87.46 **************
INFO:root:************* Client 4 Acc = 95.20 **************
INFO:root:************* Client 1 Acc = 95.68 **************
INFO:root:************* Server Acc = 88.23 **************
INFO:root:Round 22 Time: 37.64404654502869s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.169243  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.169452  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.154380  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.393009  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.147400  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 94.79 **************
INFO:root:************* Client 3 Acc = 95.07 **************
INFO:root:************* Client 4 Acc = 94.87 **************
INFO:root:************* Client 2 Acc = 87.54 **************
INFO:root:************* Client 1 Acc = 95.76 **************
INFO:root:************* Server Acc = 88.21 **************
INFO:root:Round 23 Time: 37.677979469299316s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.165672  Thread 5  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.164057  Thread 1  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.152027  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.387371  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.149908  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 95.06 **************
INFO:root:************* Client 3 Acc = 95.08 **************
INFO:root:************* Client 4 Acc = 94.93 **************
INFO:root:************* Client 2 Acc = 87.69 **************
INFO:root:************* Client 1 Acc = 95.13 **************
INFO:root:************* Server Acc = 88.32 **************
INFO:root:Round 24 Time: 37.185051679611206s
INFO:root:************** Round: 25 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.167274  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.147151  Thread 2  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.166650  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.392841  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 94.80 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.135915  Thread 3  Map [1]
INFO:root:************* Client 4 Acc = 95.48 **************
INFO:root:************* Client 3 Acc = 95.75 **************
INFO:root:************* Client 2 Acc = 87.42 **************
INFO:root:************* Client 1 Acc = 96.11 **************
INFO:root:************* Server Acc = 89.04 **************
INFO:root:Round 25 Time: 38.336649656295776s
INFO:root:************** Round: 26 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.165277  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.146386  Thread 2  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.156890  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.380388  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.133924  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 94.78 **************
INFO:root:************* Client 4 Acc = 94.90 **************
INFO:root:************* Client 3 Acc = 95.51 **************
INFO:root:************* Client 2 Acc = 84.32 **************
INFO:root:************* Client 1 Acc = 96.16 **************
INFO:root:************* Server Acc = 89.02 **************
INFO:root:Round 26 Time: 36.82163906097412s
INFO:root:************** Round: 27 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.160245  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.144454  Thread 2  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.156338  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.383332  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 94.65 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.134104  Thread 3  Map [1]
INFO:root:************* Client 4 Acc = 95.35 **************
INFO:root:************* Client 3 Acc = 95.53 **************
INFO:root:************* Client 2 Acc = 88.42 **************
INFO:root:************* Client 1 Acc = 96.19 **************
INFO:root:************* Server Acc = 89.48 **************
INFO:root:Round 27 Time: 38.69083309173584s
INFO:root:************** Round: 28 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.155163  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.140423  Thread 2  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.155826  Thread 1  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.377744  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.134615  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 95.24 **************
INFO:root:************* Client 3 Acc = 95.78 **************
INFO:root:************* Client 4 Acc = 95.01 **************
INFO:root:************* Client 2 Acc = 86.65 **************
INFO:root:************* Client 1 Acc = 96.32 **************
INFO:root:************* Server Acc = 89.75 **************
INFO:root:Round 28 Time: 36.55678105354309s
INFO:root:************** Round: 29 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.155613  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.141723  Thread 2  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.369088  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.153323  Thread 1  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.128497  Thread 3  Map [1]
INFO:root:************* Client 0 Acc = 95.62 **************
INFO:root:************* Client 4 Acc = 95.41 **************
INFO:root:************* Client 2 Acc = 85.25 **************
INFO:root:************* Client 3 Acc = 94.51 **************
INFO:root:************* Client 1 Acc = 95.98 **************
INFO:root:************* Server Acc = 89.46 **************
INFO:root:Round 29 Time: 36.84015870094299s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {2: 109, 3: 1, 8: 7, 9: 487}, 1: {0: 1412, 1: 2433, 2: 77, 3: 1151, 4: 2259, 5: 9, 7: 5999}, 2: {1: 227, 2: 5559, 3: 475, 4: 3740, 6: 5574}, 3: {1: 2, 2: 255, 3: 801, 5: 132, 6: 426, 7: 1, 8: 5993, 9: 5513}, 4: {0: 4588, 1: 3338, 3: 3572, 4: 1, 5: 5859}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 604
INFO:root:client_idx = 0, batch_num_train_local = 9, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13340
INFO:root:client_idx = 1, batch_num_train_local = 208, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 15575
INFO:root:client_idx = 2, batch_num_train_local = 243, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 13123
INFO:root:client_idx = 3, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 17358
INFO:root:client_idx = 4, batch_num_train_local = 271, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.027041  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.828775  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 18.06 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.636642  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.207238  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.571737  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.411888  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.402370  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.035062  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.423601  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 95.07 **************
INFO:root:************* Client 1 Acc = 93.44 **************
INFO:root:************* Client 2 Acc = 69.57 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.307454  Thread 5  Map [4]
INFO:root:************* Client 4 Acc = 94.69 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 81.95893406867981s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.060332  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.685628  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 72.22 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.374770  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.402232  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.031807  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.278525  Thread 5  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.295916  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.276029  Thread 3  Map [3]
INFO:root:************* Client 1 Acc = 94.15 **************
INFO:root:************* Client 3 Acc = 95.37 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.909061  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.224800  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 52.98 **************
INFO:root:************* Client 4 Acc = 94.81 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 1 Time: 72.38806557655334s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.681679  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.455779  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 93.23 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.234236  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.233876  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.843772  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.187978  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.182902  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.204274  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.727690  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 96.19 **************
INFO:root:************* Client 1 Acc = 94.42 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.159273  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 74.61 **************
INFO:root:************* Client 4 Acc = 96.20 **************
INFO:root:************* Server Acc = 22.31 **************
INFO:root:Round 2 Time: 71.10961031913757s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.527703  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.350280  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.88 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.204227  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.186085  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.661209  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.141800  Thread 5  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.175355  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.148330  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.580510  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 96.22 **************
INFO:root:************* Client 3 Acc = 96.71 **************
INFO:root:************* Client 2 Acc = 76.76 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.128092  Thread 5  Map [4]
INFO:root:************* Client 4 Acc = 96.96 **************
INFO:root:************* Server Acc = 42.17 **************
INFO:root:Round 3 Time: 71.47620224952698s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.428502  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.276591  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.92 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.134910  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.141539  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.117673  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.565527  Thread 4  Map [2]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.111317  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.129670  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 96.64 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.105836  Thread 5  Map [4]
INFO:root:************* Client 1 Acc = 96.33 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.512294  Thread 4  Map [2]
INFO:root:************* Client 2 Acc = 78.19 **************
INFO:root:************* Client 4 Acc = 97.68 **************
INFO:root:************* Server Acc = 48.97 **************
INFO:root:Round 4 Time: 66.95647597312927s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.551062  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.319368  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.44 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.137395  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.153131  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.499656  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.093100  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.105322  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.131124  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.465830  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 97.85 **************
INFO:root:************* Client 1 Acc = 96.98 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.087145  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 84.93 **************
INFO:root:************* Client 4 Acc = 96.54 **************
INFO:root:************* Server Acc = 64.26 **************
INFO:root:Round 5 Time: 68.62220215797424s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.293079  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.174754  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.115368  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.097475  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.462831  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094713  Thread 5  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.102057  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.083517  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.439352  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 97.47 **************
INFO:root:************* Client 3 Acc = 98.18 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.084347  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 83.27 **************
INFO:root:************* Client 4 Acc = 96.98 **************
INFO:root:************* Server Acc = 57.21 **************
INFO:root:Round 6 Time: 68.60781669616699s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.509648  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.279114  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.78 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.107716  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.124730  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.438741  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080716  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.084166  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.106728  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 97.70 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.416064  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 97.62 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.073781  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 86.52 **************
INFO:root:************* Client 4 Acc = 98.22 **************
INFO:root:************* Server Acc = 77.20 **************
INFO:root:Round 7 Time: 71.52000331878662s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.225410  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.128026  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.080750  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.091870  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.413297  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.077604  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.067294  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.085748  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 98.02 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.394271  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 96.96 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.071457  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 87.43 **************
INFO:root:************* Client 4 Acc = 98.36 **************
INFO:root:************* Server Acc = 63.42 **************
INFO:root:Round 8 Time: 67.48336148262024s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.383531  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.214118  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.83 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.090944  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.106275  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.407576  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.070792  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.070943  Thread 3  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.093281  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 98.53 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.388918  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 97.71 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.065208  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 85.56 **************
INFO:root:************* Client 4 Acc = 98.06 **************
INFO:root:************* Server Acc = 81.59 **************
INFO:root:Round 9 Time: 68.26272797584534s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 9, 1: 1, 2: 572, 3: 39, 5: 2, 6: 20, 7: 45, 9: 941}, 1: {0: 2137, 1: 145, 2: 477, 3: 1160, 4: 2317, 5: 150, 7: 4084, 8: 5756}, 2: {0: 3, 1: 14, 2: 4079, 3: 690, 4: 3675, 5: 23, 6: 4697}, 3: {1: 554, 2: 871, 3: 914, 4: 8, 5: 5825, 6: 1283, 7: 1871, 8: 244, 9: 5059}, 4: {0: 3851, 1: 5286, 2: 1, 3: 3197}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 1629
INFO:root:client_idx = 0, batch_num_train_local = 25, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 16226
INFO:root:client_idx = 1, batch_num_train_local = 253, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 13181
INFO:root:client_idx = 2, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 16629
INFO:root:client_idx = 3, batch_num_train_local = 259, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12335
INFO:root:client_idx = 4, batch_num_train_local = 192, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.191621  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.830997  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 86.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.594129  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.246425  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.764663  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.704411  Thread 3  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.429617  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.112244  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 92.58 **************
INFO:root:************* Client 2 Acc = 61.58 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.567486  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.525294  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 89.55 **************
INFO:root:************* Client 1 Acc = 90.39 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 78.63691329956055s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.814784  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.559937  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 92.31 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.395936  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.082252  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.538459  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.463619  Thread 3  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.310297  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.960742  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 93.67 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.422593  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 65.56 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.375406  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 87.55 **************
INFO:root:************* Client 1 Acc = 90.83 **************
INFO:root:************* Server Acc = 10.22 **************
INFO:root:Round 1 Time: 68.64350700378418s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.480160  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.339491  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.62 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.259745  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.928324  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.386321  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.324675  Thread 3  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.218814  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.806212  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 95.34 **************
INFO:root:************* Client 2 Acc = 76.04 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.329539  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.280764  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 90.40 **************
INFO:root:************* Client 1 Acc = 93.17 **************
INFO:root:************* Server Acc = 26.79 **************
INFO:root:Round 2 Time: 68.32583856582642s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.385183  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.262660  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.192577  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.767505  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.258737  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.302756  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.170927  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.679849  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 95.26 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.233651  Thread 3  Map [1]
INFO:root:************* Client 2 Acc = 77.87 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.268464  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 94.45 **************
INFO:root:************* Client 3 Acc = 91.66 **************
INFO:root:************* Server Acc = 50.82 **************
INFO:root:Round 3 Time: 69.1096019744873s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.322354  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.219605  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.170720  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.655010  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.206426  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.254717  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.147934  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.596502  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 96.34 **************
INFO:root:************* Client 2 Acc = 79.39 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.191608  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.230101  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 94.43 **************
INFO:root:************* Client 3 Acc = 93.25 **************
INFO:root:************* Server Acc = 62.51 **************
INFO:root:Round 4 Time: 68.72558569908142s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.327367  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.212509  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.136787  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.582496  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.186160  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.220000  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.123509  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.540613  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 96.46 **************
INFO:root:************* Client 2 Acc = 84.16 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.173120  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.206633  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 95.46 **************
INFO:root:************* Client 3 Acc = 94.03 **************
INFO:root:************* Server Acc = 71.02 **************
INFO:root:Round 5 Time: 69.25269031524658s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.203167  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154623  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.125259  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.536918  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.159241  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.200487  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.114472  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.501451  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.20 **************
INFO:root:************* Client 2 Acc = 79.57 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.149538  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.186855  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 95.66 **************
INFO:root:************* Client 3 Acc = 93.81 **************
INFO:root:************* Server Acc = 72.54 **************
INFO:root:Round 6 Time: 69.15834212303162s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.230397  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154835  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.118003  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.497073  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.148815  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.176823  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.104095  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.466494  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.14 **************
INFO:root:************* Client 2 Acc = 85.05 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.136619  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.168687  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 96.63 **************
INFO:root:************* Client 3 Acc = 93.77 **************
INFO:root:************* Server Acc = 77.76 **************
INFO:root:Round 7 Time: 68.77961587905884s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.180545  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.123880  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.106040  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.475640  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.133253  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.165802  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.095245  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.442522  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 96.66 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.126583  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.159857  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 85.10 **************
INFO:root:************* Client 1 Acc = 96.76 **************
INFO:root:************* Client 3 Acc = 94.11 **************
INFO:root:************* Server Acc = 81.32 **************
INFO:root:Round 8 Time: 66.03461194038391s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.227678  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.155932  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.098857  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.466475  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.123078  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.159303  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.089171  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.437702  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.25 **************
INFO:root:************* Client 2 Acc = 83.43 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.116407  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.149979  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 96.81 **************
INFO:root:************* Client 3 Acc = 95.37 **************
INFO:root:************* Server Acc = 82.73 **************
INFO:root:Round 9 Time: 70.02392244338989s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 278, 1: 188, 2: 941, 3: 1325, 4: 27, 5: 100, 6: 255, 7: 2869, 8: 1, 9: 3810}, 1: {0: 2413, 1: 2049, 2: 871, 3: 875, 4: 2454, 5: 505, 6: 2, 7: 90, 8: 4385}, 2: {0: 184, 1: 1069, 2: 3042, 3: 1099, 4: 3339, 5: 239, 6: 3459}, 3: {0: 51, 1: 410, 2: 1144, 3: 2700, 4: 118, 5: 4895, 6: 1431, 7: 261, 8: 1093}, 4: {0: 3074, 1: 2284, 2: 2, 3: 1, 4: 62, 5: 261, 6: 853, 7: 2780, 8: 521, 9: 2190}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 9794
INFO:root:client_idx = 0, batch_num_train_local = 153, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13644
INFO:root:client_idx = 1, batch_num_train_local = 213, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 12431
INFO:root:client_idx = 2, batch_num_train_local = 194, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 12103
INFO:root:client_idx = 3, batch_num_train_local = 189, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12028
INFO:root:client_idx = 4, batch_num_train_local = 187, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.940690  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.810694  Thread 3  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.851776  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.367861  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.913731  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.716304  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.644514  Thread 3  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.624504  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.214627  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 76.06 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.669403  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 82.74 **************
INFO:root:************* Client 4 Acc = 87.27 **************
INFO:root:************* Client 2 Acc = 61.07 **************
INFO:root:************* Client 1 Acc = 87.48 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 71.67164301872253s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.632862  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.519817  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.580688  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.104151  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.617298  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.500424  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 88.53 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.434850  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.503779  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.978206  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.498790  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 89.80 **************
INFO:root:************* Client 3 Acc = 86.86 **************
INFO:root:************* Client 2 Acc = 70.82 **************
INFO:root:************* Client 1 Acc = 86.73 **************
INFO:root:************* Server Acc = 20.26 **************
INFO:root:Round 1 Time: 63.317476749420166s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.420372  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.431340  Thread 3  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.373368  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.877648  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.414063  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.370457  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 90.42 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.391117  Thread 3  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.330256  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.816499  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.373617  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 88.34 **************
INFO:root:************* Client 3 Acc = 88.96 **************
INFO:root:************* Client 2 Acc = 67.53 **************
INFO:root:************* Client 1 Acc = 88.31 **************
INFO:root:************* Server Acc = 23.26 **************
INFO:root:Round 2 Time: 64.01214528083801s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.356089  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.290104  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.354732  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.771310  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.334273  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.313264  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 91.27 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.269891  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.333035  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.711413  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.305448  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 89.71 **************
INFO:root:************* Client 4 Acc = 90.32 **************
INFO:root:************* Client 2 Acc = 77.41 **************
INFO:root:************* Client 1 Acc = 90.42 **************
INFO:root:************* Server Acc = 61.04 **************
INFO:root:Round 3 Time: 63.35497546195984s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.305062  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.301469  Thread 3  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.255590  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.692134  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.283662  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.277002  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.285326  Thread 3  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.239814  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.633002  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.263993  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 92.99 **************
INFO:root:************* Client 3 Acc = 91.73 **************
INFO:root:************* Client 2 Acc = 76.65 **************
INFO:root:************* Client 1 Acc = 91.21 **************
INFO:root:************* Server Acc = 75.72 **************
INFO:root:Round 4 Time: 64.49979496002197s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.262422  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.234170  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.269664  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.595688  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.244184  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.243280  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 92.22 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.219561  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.257422  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.553221  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.234317  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 93.26 **************
INFO:root:************* Client 3 Acc = 91.39 **************
INFO:root:************* Client 2 Acc = 78.29 **************
INFO:root:************* Client 1 Acc = 92.59 **************
INFO:root:************* Server Acc = 79.51 **************
INFO:root:Round 5 Time: 62.54604768753052s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.241272  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.210075  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.243256  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.533177  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.220117  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.219251  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.00 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.198319  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.231113  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.507330  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.206907  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 93.18 **************
INFO:root:************* Client 4 Acc = 93.97 **************
INFO:root:************* Client 2 Acc = 84.24 **************
INFO:root:************* Client 1 Acc = 93.98 **************
INFO:root:************* Server Acc = 81.52 **************
INFO:root:Round 6 Time: 64.82850313186646s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.217217  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.194219  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.215587  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.503326  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.194753  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.203580  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.187696  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.204539  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.476943  Thread 4  Map [2]
INFO:root:************* Client 0 Acc = 94.30 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.189194  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.46 **************
INFO:root:************* Client 3 Acc = 92.40 **************
INFO:root:************* Client 2 Acc = 84.59 **************
INFO:root:************* Client 1 Acc = 94.82 **************
INFO:root:************* Server Acc = 84.20 **************
INFO:root:Round 7 Time: 62.100916385650635s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.206944  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.207072  Thread 3  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.186380  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.471151  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.179311  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.195977  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.31 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.198809  Thread 3  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.176282  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.450967  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.172431  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.59 **************
INFO:root:************* Client 3 Acc = 94.12 **************
INFO:root:************* Client 2 Acc = 85.08 **************
INFO:root:************* Client 1 Acc = 95.11 **************
INFO:root:************* Server Acc = 86.50 **************
INFO:root:Round 8 Time: 63.180835008621216s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.188381  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.174369  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.194390  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.447346  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.168592  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.177715  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.36 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.167280  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.185718  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.432418  Thread 4  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.162545  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.98 **************
INFO:root:************* Client 3 Acc = 83.24 **************
INFO:root:************* Client 2 Acc = 85.13 **************
INFO:root:************* Client 1 Acc = 95.22 **************
INFO:root:************* Server Acc = 86.57 **************
INFO:root:Round 9 Time: 62.43824005126953s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {2: 109, 3: 1, 8: 7, 9: 487}, 1: {0: 1412, 1: 2433, 2: 77, 3: 1151, 4: 2259, 5: 9, 7: 5999}, 2: {1: 227, 2: 5559, 3: 475, 4: 3740, 6: 5574}, 3: {1: 2, 2: 255, 3: 801, 5: 132, 6: 426, 7: 1, 8: 5993, 9: 5513}, 4: {0: 4588, 1: 3338, 3: 3572, 4: 1, 5: 5859}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 604
INFO:root:client_idx = 0, batch_num_train_local = 9, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13340
INFO:root:client_idx = 1, batch_num_train_local = 208, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 15575
INFO:root:client_idx = 2, batch_num_train_local = 243, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 13123
INFO:root:client_idx = 3, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 17358
INFO:root:client_idx = 4, batch_num_train_local = 271, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.027041  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.828775  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 18.06 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.636642  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.571737  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.207238  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.411888  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.402370  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.423601  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 95.07 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.035062  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 93.44 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.307454  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 69.57 **************
INFO:root:************* Client 4 Acc = 94.69 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 80.93545174598694s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.060332  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.685628  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 72.22 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.402232  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.374770  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.031807  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.278525  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.276029  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.295916  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.909061  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 95.37 **************
INFO:root:************* Client 1 Acc = 94.15 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.224800  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 52.98 **************
INFO:root:************* Client 4 Acc = 94.81 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 1 Time: 71.79005694389343s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.681679  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.455779  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 93.23 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.234236  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.233876  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.843772  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.187978  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.182902  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.204274  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 96.19 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.727690  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 94.42 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.159273  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 74.61 **************
INFO:root:************* Client 4 Acc = 96.20 **************
INFO:root:************* Server Acc = 22.31 **************
INFO:root:Round 2 Time: 70.62669658660889s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.527703  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.350280  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 96.88 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.186085  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.204227  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.661209  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.141800  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.148330  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.175355  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.580510  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.128092  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 96.22 **************
INFO:root:************* Client 3 Acc = 96.71 **************
INFO:root:************* Client 2 Acc = 76.76 **************
INFO:root:************* Client 4 Acc = 96.96 **************
INFO:root:************* Server Acc = 42.17 **************
INFO:root:Round 3 Time: 68.78069925308228s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.428502  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.276591  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 97.92 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.134910  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.141539  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.565527  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.117673  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.111317  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.129670  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 96.64 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.512294  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 96.33 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.105836  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 78.19 **************
INFO:root:************* Client 4 Acc = 97.68 **************
INFO:root:************* Server Acc = 48.97 **************
INFO:root:Round 4 Time: 71.09480595588684s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.551062  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.319368  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 98.44 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.137395  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.153131  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.499656  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.093100  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.105322  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.131124  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 97.85 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.465830  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 96.98 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.087145  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 84.93 **************
INFO:root:************* Client 4 Acc = 96.54 **************
INFO:root:************* Server Acc = 64.26 **************
INFO:root:Round 5 Time: 71.07391095161438s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.293079  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.174754  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.097475  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.115368  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.462831  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094713  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.083517  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.102057  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.18 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.439352  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 97.47 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.084347  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 83.27 **************
INFO:root:************* Client 4 Acc = 96.98 **************
INFO:root:************* Server Acc = 57.21 **************
INFO:root:Round 6 Time: 71.14331555366516s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.509648  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.279114  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 98.78 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.107716  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.124730  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.438741  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080716  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.084166  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.106728  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 97.70 **************
INFO:root:************* Client 1 Acc = 97.62 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.416064  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.073781  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 86.52 **************
INFO:root:************* Client 4 Acc = 98.22 **************
INFO:root:************* Server Acc = 77.20 **************
INFO:root:Round 7 Time: 66.66290807723999s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.225410  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.128026  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.080750  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.091870  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.413297  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.077604  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.067294  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.085748  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.02 **************
INFO:root:************* Client 1 Acc = 96.96 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.394271  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.071457  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 87.43 **************
INFO:root:************* Client 4 Acc = 98.36 **************
INFO:root:************* Server Acc = 63.42 **************
INFO:root:Round 8 Time: 66.86713337898254s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.383531  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.214118  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.83 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.106275  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.090944  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.407576  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.070792  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.093281  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.070943  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.71 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.388918  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.065208  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 98.53 **************
INFO:root:************* Client 2 Acc = 85.56 **************
INFO:root:************* Client 4 Acc = 98.06 **************
INFO:root:************* Server Acc = 81.59 **************
INFO:root:Round 9 Time: 65.4875316619873s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.240637  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.136070  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.069244  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.087601  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.384526  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.066255  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.058544  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.077939  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.369117  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 98.47 **************
INFO:root:************* Client 1 Acc = 97.75 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.062132  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 83.94 **************
INFO:root:************* Client 4 Acc = 98.40 **************
INFO:root:************* Server Acc = 67.08 **************
INFO:root:Round 10 Time: 71.22931718826294s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.375047  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.208868  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.65 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.084835  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.100331  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.371798  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.060830  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.065936  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.086317  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.96 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.359252  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 97.85 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.058104  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 88.77 **************
INFO:root:************* Client 4 Acc = 98.30 **************
INFO:root:************* Server Acc = 82.67 **************
INFO:root:Round 11 Time: 67.4782395362854s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.356468  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.201160  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.070559  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.074768  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.352494  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.059647  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.059078  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.069439  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.80 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.345131  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 98.24 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.055617  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 89.48 **************
INFO:root:************* Client 4 Acc = 98.66 **************
INFO:root:************* Server Acc = 74.62 **************
INFO:root:Round 12 Time: 71.95233178138733s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.277365  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.152672  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.072421  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.088048  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.351756  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.055049  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.057623  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.076861  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.86 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.340534  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 98.11 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.052193  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 87.37 **************
INFO:root:************* Client 4 Acc = 98.71 **************
INFO:root:************* Server Acc = 84.51 **************
INFO:root:Round 13 Time: 67.90587520599365s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.300785  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.169176  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.059965  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.067903  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.343181  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.054970  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.050536  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.063118  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.330411  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 98.95 **************
INFO:root:************* Client 1 Acc = 98.13 **************
INFO:root:************* Client 2 Acc = 89.53 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.051816  Thread 1  Map [4]
INFO:root:************* Client 4 Acc = 98.39 **************
INFO:root:************* Server Acc = 77.28 **************
INFO:root:Round 14 Time: 76.40353608131409s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.294186  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.169187  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.059761  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.081751  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.337433  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.052526  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.051520  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.071541  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.96 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.327450  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 98.75 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.049199  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 90.43 **************
INFO:root:************* Client 4 Acc = 98.71 **************
INFO:root:************* Server Acc = 83.79 **************
INFO:root:Round 15 Time: 72.02665376663208s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.280239  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.164450  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.48 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.056628  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.062006  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.329086  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.048429  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.047961  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.058721  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.91 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.318539  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 98.37 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.045835  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 89.36 **************
INFO:root:************* Client 4 Acc = 98.85 **************
INFO:root:************* Server Acc = 77.93 **************
INFO:root:Round 16 Time: 66.8211886882782s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.282264  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.150821  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 98.61 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.054270  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.072265  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.317996  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.047099  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.045322  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.064212  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.309019  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 98.72 **************
INFO:root:************* Client 1 Acc = 97.84 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.044173  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 90.24 **************
INFO:root:************* Client 4 Acc = 98.82 **************
INFO:root:************* Server Acc = 85.29 **************
INFO:root:Round 17 Time: 71.50592494010925s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.323209  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.179076  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.050075  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.061555  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.320638  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.050965  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.042314  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.056880  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.94 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.309673  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 98.66 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.045381  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 89.90 **************
INFO:root:************* Client 4 Acc = 98.91 **************
INFO:root:************* Server Acc = 77.30 **************
INFO:root:Round 18 Time: 71.68637943267822s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.244806  Thread 4  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.133450  Thread 4  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.048091  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.072672  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.306620  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.044774  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.040705  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.063897  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 99.26 **************
INFO:root:************* Client 1 Acc = 98.72 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.300931  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.043088  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 90.59 **************
INFO:root:************* Client 4 Acc = 98.90 **************
INFO:root:************* Server Acc = 86.07 **************
INFO:root:Round 19 Time: 66.97076988220215s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 9, 1: 1, 2: 572, 3: 39, 5: 2, 6: 20, 7: 45, 9: 941}, 1: {0: 2137, 1: 145, 2: 477, 3: 1160, 4: 2317, 5: 150, 7: 4084, 8: 5756}, 2: {0: 3, 1: 14, 2: 4079, 3: 690, 4: 3675, 5: 23, 6: 4697}, 3: {1: 554, 2: 871, 3: 914, 4: 8, 5: 5825, 6: 1283, 7: 1871, 8: 244, 9: 5059}, 4: {0: 3851, 1: 5286, 2: 1, 3: 3197}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 1629
INFO:root:client_idx = 0, batch_num_train_local = 25, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 16226
INFO:root:client_idx = 1, batch_num_train_local = 253, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 13181
INFO:root:client_idx = 2, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 16629
INFO:root:client_idx = 3, batch_num_train_local = 259, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12335
INFO:root:client_idx = 4, batch_num_train_local = 192, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.191621  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.830997  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 86.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.594129  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.246425  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.704411  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.764663  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.429617  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.112244  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 92.58 **************
INFO:root:************* Client 2 Acc = 61.58 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.525294  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.567486  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 90.39 **************
INFO:root:************* Client 3 Acc = 89.55 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 81.52047729492188s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.814784  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.559937  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 92.31 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.395936  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.082252  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.463619  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.538459  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.310297  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.960742  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 93.67 **************
INFO:root:************* Client 2 Acc = 65.56 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.375406  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.422593  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 90.83 **************
INFO:root:************* Client 3 Acc = 87.55 **************
INFO:root:************* Server Acc = 10.22 **************
INFO:root:Round 1 Time: 71.46347332000732s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.480160  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.339491  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 95.62 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.259745  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.928324  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.324675  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.386321  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.218814  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.806212  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 95.34 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.280764  Thread 4  Map [1]
INFO:root:************* Client 2 Acc = 76.04 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.329539  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 93.17 **************
INFO:root:************* Client 3 Acc = 90.40 **************
INFO:root:************* Server Acc = 26.79 **************
INFO:root:Round 2 Time: 66.67725682258606s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.385183  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.262660  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 96.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.192577  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.767505  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.258737  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.302756  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.170927  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.679849  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 95.26 **************
INFO:root:************* Client 2 Acc = 77.87 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.233651  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.268464  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 94.45 **************
INFO:root:************* Client 3 Acc = 91.66 **************
INFO:root:************* Server Acc = 50.82 **************
INFO:root:Round 3 Time: 68.6651086807251s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.322354  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.219605  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 97.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.170720  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.655010  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.206426  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.254717  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.147934  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.596502  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 96.34 **************
INFO:root:************* Client 2 Acc = 79.39 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.191608  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.230101  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 94.43 **************
INFO:root:************* Client 3 Acc = 93.25 **************
INFO:root:************* Server Acc = 62.51 **************
INFO:root:Round 4 Time: 68.96123790740967s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.327367  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.212509  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.136787  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.582496  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.186160  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.220000  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.123509  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.540613  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 96.46 **************
INFO:root:************* Client 2 Acc = 84.16 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.173120  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.206633  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 95.46 **************
INFO:root:************* Client 3 Acc = 94.03 **************
INFO:root:************* Server Acc = 71.02 **************
INFO:root:Round 5 Time: 67.81672525405884s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.203167  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154623  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.125259  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.536918  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.159241  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.200487  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.114472  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.501451  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.20 **************
INFO:root:************* Client 2 Acc = 79.57 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.149538  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.186855  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 95.66 **************
INFO:root:************* Client 3 Acc = 93.81 **************
INFO:root:************* Server Acc = 72.54 **************
INFO:root:Round 6 Time: 68.38575458526611s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.230397  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154835  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 97.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.118003  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.497073  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.176823  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.148815  Thread 4  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.104095  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.466494  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.14 **************
INFO:root:************* Client 2 Acc = 85.05 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.136619  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.168687  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 96.63 **************
INFO:root:************* Client 3 Acc = 93.77 **************
INFO:root:************* Server Acc = 77.76 **************
INFO:root:Round 7 Time: 66.32889795303345s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.180545  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.123880  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.106040  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.475640  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.133253  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.165802  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.095245  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.442522  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 96.66 **************
INFO:root:************* Client 2 Acc = 85.10 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.126583  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.159857  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 96.76 **************
INFO:root:************* Client 3 Acc = 94.11 **************
INFO:root:************* Server Acc = 81.32 **************
INFO:root:Round 8 Time: 68.12993693351746s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.227678  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.155932  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.098857  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.466475  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.123078  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.159303  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.089171  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.437702  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.25 **************
INFO:root:************* Client 2 Acc = 83.43 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.116407  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.149979  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 96.81 **************
INFO:root:************* Client 3 Acc = 95.37 **************
INFO:root:************* Server Acc = 82.73 **************
INFO:root:Round 9 Time: 69.67048835754395s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.159177  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.109993  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.50 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.100757  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.433520  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.118686  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.148783  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.088013  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.407662  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.79 **************
INFO:root:************* Client 2 Acc = 85.72 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.112340  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.143260  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 96.99 **************
INFO:root:************* Client 3 Acc = 94.37 **************
INFO:root:************* Server Acc = 84.54 **************
INFO:root:Round 10 Time: 71.96952748298645s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.169690  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.117743  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.44 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.091928  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.421023  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.109017  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.144576  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.398393  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.082689  Thread 1  Map [4]
INFO:root:************* Client 4 Acc = 95.51 **************
INFO:root:************* Client 2 Acc = 86.34 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.103928  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.138992  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.38 **************
INFO:root:************* Client 3 Acc = 94.59 **************
INFO:root:************* Server Acc = 86.52 **************
INFO:root:Round 11 Time: 65.8548891544342s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.139291  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.099316  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.31 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.084413  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.400331  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.104375  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.135181  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.076959  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.386225  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 84.81 **************
INFO:root:************* Client 2 Acc = 85.59 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.129493  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.098211  Thread 4  Map [1]
INFO:root:************* Client 1 Acc = 97.11 **************
INFO:root:************* Client 3 Acc = 96.18 **************
INFO:root:************* Server Acc = 85.94 **************
INFO:root:Round 12 Time: 68.35704183578491s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.189190  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.125851  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080660  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.392485  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.100877  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.130090  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.075038  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.373358  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.41 **************
INFO:root:************* Client 2 Acc = 87.80 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.094529  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.125849  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.54 **************
INFO:root:************* Client 3 Acc = 95.09 **************
INFO:root:************* Server Acc = 85.96 **************
INFO:root:Round 13 Time: 69.13034391403198s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.180335  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.115912  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080428  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.383898  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.096267  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.127966  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.072007  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.362655  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 95.23 **************
INFO:root:************* Client 2 Acc = 86.62 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.091388  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.122326  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.79 **************
INFO:root:************* Client 3 Acc = 95.32 **************
INFO:root:************* Server Acc = 86.81 **************
INFO:root:Round 14 Time: 69.32654452323914s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.135850  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.097735  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.069843  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.366253  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.093839  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.123700  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.068468  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.354468  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 98.39 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.088868  Thread 4  Map [1]
INFO:root:************* Client 2 Acc = 88.60 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.115535  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.51 **************
INFO:root:************* Client 3 Acc = 96.51 **************
INFO:root:************* Server Acc = 87.07 **************
INFO:root:Round 15 Time: 67.01024913787842s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.157834  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.105563  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.62 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.065902  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.377356  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.087819  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.119919  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.063198  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.355752  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 97.75 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.084193  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.114995  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 88.54 **************
INFO:root:************* Client 1 Acc = 97.81 **************
INFO:root:************* Client 3 Acc = 96.49 **************
INFO:root:************* Server Acc = 86.68 **************
INFO:root:Round 16 Time: 65.50992369651794s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.137230  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.098269  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.06 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.069987  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.353353  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.115160  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.084029  Thread 4  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.065228  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.343221  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 98.57 **************
INFO:root:************* Client 2 Acc = 89.66 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.110600  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.079417  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 96.60 **************
INFO:root:************* Client 1 Acc = 97.80 **************
INFO:root:************* Server Acc = 86.18 **************
INFO:root:Round 17 Time: 67.53038287162781s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.148546  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.106750  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.072311  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.346723  Thread 2  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.079742  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.113700  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.064514  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.334632  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 98.42 **************
INFO:root:************* Client 2 Acc = 90.13 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.076638  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.108322  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.74 **************
INFO:root:************* Client 3 Acc = 96.37 **************
INFO:root:************* Server Acc = 85.89 **************
INFO:root:Round 18 Time: 69.59373354911804s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.129540  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.089970  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.061521  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.332624  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.107178  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.079209  Thread 4  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.060528  Thread 1  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.326205  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 98.49 **************
INFO:root:************* Client 2 Acc = 89.84 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.103434  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.074228  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 96.40 **************
INFO:root:************* Client 1 Acc = 98.04 **************
INFO:root:************* Server Acc = 88.23 **************
INFO:root:Round 19 Time: 66.82388830184937s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 278, 1: 188, 2: 941, 3: 1325, 4: 27, 5: 100, 6: 255, 7: 2869, 8: 1, 9: 3810}, 1: {0: 2413, 1: 2049, 2: 871, 3: 875, 4: 2454, 5: 505, 6: 2, 7: 90, 8: 4385}, 2: {0: 184, 1: 1069, 2: 3042, 3: 1099, 4: 3339, 5: 239, 6: 3459}, 3: {0: 51, 1: 410, 2: 1144, 3: 2700, 4: 118, 5: 4895, 6: 1431, 7: 261, 8: 1093}, 4: {0: 3074, 1: 2284, 2: 2, 3: 1, 4: 62, 5: 261, 6: 853, 7: 2780, 8: 521, 9: 2190}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 9794
INFO:root:client_idx = 0, batch_num_train_local = 153, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13644
INFO:root:client_idx = 1, batch_num_train_local = 213, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 12431
INFO:root:client_idx = 2, batch_num_train_local = 194, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 12103
INFO:root:client_idx = 3, batch_num_train_local = 189, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12028
INFO:root:client_idx = 4, batch_num_train_local = 187, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.940690  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.851776  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.810694  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.367861  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.913731  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.716304  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.624504  Thread 4  Map [4]
INFO:root:************* Client 0 Acc = 76.06 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.644514  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.214627  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.669403  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 87.27 **************
INFO:root:************* Client 3 Acc = 82.74 **************
INFO:root:************* Client 2 Acc = 61.07 **************
INFO:root:************* Client 1 Acc = 87.48 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 71.58980298042297s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.632862  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.519817  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.580688  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.104151  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.617298  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.500424  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 88.53 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.434850  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.503779  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.978206  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.498790  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 89.80 **************
INFO:root:************* Client 3 Acc = 86.86 **************
INFO:root:************* Client 2 Acc = 70.82 **************
INFO:root:************* Client 1 Acc = 86.73 **************
INFO:root:************* Server Acc = 20.26 **************
INFO:root:Round 1 Time: 64.29359722137451s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.420372  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.373368  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.431340  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.877648  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.414063  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.370457  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 90.42 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.330256  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.391117  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.816499  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.373617  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 88.34 **************
INFO:root:************* Client 3 Acc = 88.96 **************
INFO:root:************* Client 2 Acc = 67.53 **************
INFO:root:************* Client 1 Acc = 88.31 **************
INFO:root:************* Server Acc = 23.26 **************
INFO:root:Round 2 Time: 65.1536614894867s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.356089  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.290104  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.354732  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.771310  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.334273  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.313264  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 91.27 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.269891  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.333035  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.711413  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.305448  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 90.32 **************
INFO:root:************* Client 3 Acc = 89.71 **************
INFO:root:************* Client 2 Acc = 77.41 **************
INFO:root:************* Client 1 Acc = 90.42 **************
INFO:root:************* Server Acc = 61.04 **************
INFO:root:Round 3 Time: 62.26950764656067s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.305062  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.255590  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.301469  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.692134  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.283662  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.277002  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.239814  Thread 4  Map [4]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.285326  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.633002  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.263993  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 92.99 **************
INFO:root:************* Client 3 Acc = 91.73 **************
INFO:root:************* Client 2 Acc = 76.65 **************
INFO:root:************* Client 1 Acc = 91.21 **************
INFO:root:************* Server Acc = 75.72 **************
INFO:root:Round 4 Time: 62.84909772872925s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.262422  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.234170  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.269664  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.595688  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.244184  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.243280  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.219561  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.257422  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.553221  Thread 1  Map [2]
INFO:root:************* Client 0 Acc = 92.22 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.234317  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 93.26 **************
INFO:root:************* Client 3 Acc = 91.39 **************
INFO:root:************* Client 2 Acc = 78.29 **************
INFO:root:************* Client 1 Acc = 92.59 **************
INFO:root:************* Server Acc = 79.51 **************
INFO:root:Round 5 Time: 64.4278199672699s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.241272  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.210075  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.243256  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.533177  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.220117  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.219251  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 94.00 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.198319  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.231113  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.507330  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.206907  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 93.97 **************
INFO:root:************* Client 3 Acc = 93.18 **************
INFO:root:************* Client 2 Acc = 84.24 **************
INFO:root:************* Client 1 Acc = 93.98 **************
INFO:root:************* Server Acc = 81.52 **************
INFO:root:Round 6 Time: 65.29762411117554s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.217217  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.194219  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.215587  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.503326  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.194753  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.203580  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 94.30 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.187696  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.204539  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.476943  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.189194  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.46 **************
INFO:root:************* Client 3 Acc = 92.40 **************
INFO:root:************* Client 2 Acc = 84.59 **************
INFO:root:************* Client 1 Acc = 94.82 **************
INFO:root:************* Server Acc = 84.20 **************
INFO:root:Round 7 Time: 64.83196306228638s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.206944  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.186380  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.207072  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.471151  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.179311  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.195977  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 94.31 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.176282  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.198809  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.450967  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.172431  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.59 **************
INFO:root:************* Client 3 Acc = 94.12 **************
INFO:root:************* Client 2 Acc = 85.08 **************
INFO:root:************* Client 1 Acc = 95.11 **************
INFO:root:************* Server Acc = 86.50 **************
INFO:root:Round 8 Time: 65.28972959518433s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.188381  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.174369  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.194390  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.447346  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.168592  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.177715  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 95.36 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.167280  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.185718  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.432418  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.162545  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.98 **************
INFO:root:************* Client 3 Acc = 83.24 **************
INFO:root:************* Client 2 Acc = 85.13 **************
INFO:root:************* Client 1 Acc = 95.22 **************
INFO:root:************* Server Acc = 86.57 **************
INFO:root:Round 9 Time: 62.7814040184021s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.192500  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.173914  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.184796  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.423018  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.163104  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.178252  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 94.48 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.164856  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.180904  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.413066  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.155967  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.68 **************
INFO:root:************* Client 3 Acc = 94.86 **************
INFO:root:************* Client 2 Acc = 85.33 **************
INFO:root:************* Client 1 Acc = 94.08 **************
INFO:root:************* Server Acc = 87.10 **************
INFO:root:Round 10 Time: 62.92627167701721s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.178354  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.155838  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.176853  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.425306  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.152968  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.167788  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 95.37 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.152533  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.171479  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.405703  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.145538  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.99 **************
INFO:root:************* Client 3 Acc = 94.21 **************
INFO:root:************* Client 2 Acc = 76.35 **************
INFO:root:************* Client 1 Acc = 95.26 **************
INFO:root:************* Server Acc = 87.07 **************
INFO:root:Round 11 Time: 62.49515771865845s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.171221  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.157203  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.164646  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.410091  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.146625  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.159078  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 94.94 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.150185  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.162891  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.393604  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.142925  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.57 **************
INFO:root:************* Client 3 Acc = 95.29 **************
INFO:root:************* Client 2 Acc = 86.98 **************
INFO:root:************* Client 1 Acc = 95.53 **************
INFO:root:************* Server Acc = 88.26 **************
INFO:root:Round 12 Time: 63.13629198074341s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.167120  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.160654  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.168985  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.398323  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.143624  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154742  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 94.92 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.148654  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.159379  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.380746  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.139009  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 95.30 **************
INFO:root:************* Client 3 Acc = 95.24 **************
INFO:root:************* Client 2 Acc = 88.43 **************
INFO:root:************* Client 1 Acc = 96.41 **************
INFO:root:************* Server Acc = 89.10 **************
INFO:root:Round 13 Time: 63.5462064743042s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.168615  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.151499  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.157453  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.375762  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.136597  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.155046  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 95.62 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.144255  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.152353  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.368352  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.130742  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 95.48 **************
INFO:root:************* Client 3 Acc = 95.81 **************
INFO:root:************* Client 2 Acc = 89.01 **************
INFO:root:************* Client 1 Acc = 95.36 **************
INFO:root:************* Server Acc = 88.86 **************
INFO:root:Round 14 Time: 63.30219101905823s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.153976  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.145558  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.165018  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.369466  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.135321  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.146532  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 95.73 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.138423  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.154323  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.361404  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.128974  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 95.55 **************
INFO:root:************* Client 3 Acc = 96.18 **************
INFO:root:************* Client 2 Acc = 88.72 **************
INFO:root:************* Client 1 Acc = 96.47 **************
INFO:root:************* Server Acc = 89.14 **************
INFO:root:Round 15 Time: 63.33537530899048s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.152123  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.137420  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.149569  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.365143  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.133359  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.143492  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 95.78 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.133808  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.141186  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.352122  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.125204  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 96.11 **************
INFO:root:************* Client 3 Acc = 80.71 **************
INFO:root:************* Client 2 Acc = 86.89 **************
INFO:root:************* Client 1 Acc = 96.68 **************
INFO:root:************* Server Acc = 89.82 **************
INFO:root:Round 16 Time: 62.68162131309509s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.152827  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.141556  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.144873  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.356073  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.121384  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.142248  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 95.72 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.134817  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.137206  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.349727  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.115604  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 95.54 **************
INFO:root:************* Client 3 Acc = 96.04 **************
INFO:root:************* Client 2 Acc = 85.85 **************
INFO:root:************* Client 1 Acc = 96.62 **************
INFO:root:************* Server Acc = 89.87 **************
INFO:root:Round 17 Time: 62.810425996780396s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.144943  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.133987  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.140019  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.357860  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.120064  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.139646  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.127407  Thread 4  Map [4]
INFO:root:************* Client 0 Acc = 96.05 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.135144  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.346066  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.114312  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 94.95 **************
INFO:root:************* Client 3 Acc = 95.60 **************
INFO:root:************* Client 2 Acc = 89.05 **************
INFO:root:************* Client 1 Acc = 96.41 **************
INFO:root:************* Server Acc = 89.94 **************
INFO:root:Round 18 Time: 62.91966509819031s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.144571  Thread 5  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.131745  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.141858  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.339874  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.122486  Thread 2  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.135757  Thread 5  Map [0]
INFO:root:************* Client 0 Acc = 96.32 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.124953  Thread 4  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.134064  Thread 3  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.338906  Thread 1  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.113388  Thread 2  Map [1]
INFO:root:************* Client 4 Acc = 95.90 **************
INFO:root:************* Client 3 Acc = 95.58 **************
INFO:root:************* Client 2 Acc = 86.08 **************
INFO:root:************* Client 1 Acc = 96.25 **************
INFO:root:************* Server Acc = 90.12 **************
INFO:root:Round 19 Time: 65.22480201721191s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {2: 109, 3: 1, 8: 7, 9: 487}, 1: {0: 1412, 1: 2433, 2: 77, 3: 1151, 4: 2259, 5: 9, 7: 5999}, 2: {1: 227, 2: 5559, 3: 475, 4: 3740, 6: 5574}, 3: {1: 2, 2: 255, 3: 801, 5: 132, 6: 426, 7: 1, 8: 5993, 9: 5513}, 4: {0: 4588, 1: 3338, 3: 3572, 4: 1, 5: 5859}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 604
INFO:root:client_idx = 0, batch_num_train_local = 9, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13340
INFO:root:client_idx = 1, batch_num_train_local = 208, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 15575
INFO:root:client_idx = 2, batch_num_train_local = 243, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 13123
INFO:root:client_idx = 3, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 17358
INFO:root:client_idx = 4, batch_num_train_local = 271, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.027041  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.828775  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 18.06 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.636642  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.571737  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.207238  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.411888  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.402370  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.423601  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.035062  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 95.07 **************
INFO:root:************* Client 1 Acc = 93.44 **************
INFO:root:************* Client 2 Acc = 69.57 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.307454  Thread 1  Map [4]
INFO:root:************* Client 4 Acc = 94.69 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 82.1204354763031s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.060332  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.685628  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 72.22 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.402232  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.374770  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.031807  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.278525  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.276029  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.295916  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.909061  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 95.37 **************
INFO:root:************* Client 1 Acc = 94.15 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.224800  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 52.98 **************
INFO:root:************* Client 4 Acc = 94.81 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 1 Time: 68.31079530715942s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.681679  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.455779  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 93.23 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.233876  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.234236  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.843772  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.187978  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.204274  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.182902  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.727690  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 94.42 **************
INFO:root:************* Client 3 Acc = 96.19 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.159273  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 74.61 **************
INFO:root:************* Client 4 Acc = 96.20 **************
INFO:root:************* Server Acc = 22.31 **************
INFO:root:Round 2 Time: 68.9320855140686s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.527703  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.350280  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 96.88 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.186085  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.204227  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.661209  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.141800  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.148330  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.175355  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.580510  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.128092  Thread 1  Map [4]
INFO:root:************* Client 3 Acc = 96.71 **************
INFO:root:************* Client 1 Acc = 96.22 **************
INFO:root:************* Client 2 Acc = 76.76 **************
INFO:root:************* Client 4 Acc = 96.96 **************
INFO:root:************* Server Acc = 42.17 **************
INFO:root:Round 3 Time: 67.88048028945923s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.428502  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.276591  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 97.92 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.134910  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.141539  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.565527  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.117673  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.111317  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.129670  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.512294  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 96.64 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.105836  Thread 1  Map [4]
INFO:root:************* Client 1 Acc = 96.33 **************
INFO:root:************* Client 2 Acc = 78.19 **************
INFO:root:************* Client 4 Acc = 97.68 **************
INFO:root:************* Server Acc = 48.97 **************
INFO:root:Round 4 Time: 67.95073962211609s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.551062  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.319368  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.44 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.137395  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.153131  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.499656  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.093100  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.105322  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.131124  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.465830  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 97.85 **************
INFO:root:************* Client 1 Acc = 96.98 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.087145  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 84.93 **************
INFO:root:************* Client 4 Acc = 96.54 **************
INFO:root:************* Server Acc = 64.26 **************
INFO:root:Round 5 Time: 67.72064518928528s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.293079  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.174754  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.097475  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.115368  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.462831  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094713  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.083517  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.102057  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.439352  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.18 **************
INFO:root:************* Client 1 Acc = 97.47 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.084347  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 83.27 **************
INFO:root:************* Client 4 Acc = 96.98 **************
INFO:root:************* Server Acc = 57.21 **************
INFO:root:Round 6 Time: 71.38052582740784s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.509648  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.279114  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.78 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.124730  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.107716  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.438741  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080716  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.106728  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.084166  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.62 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.416064  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 97.70 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.073781  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 86.52 **************
INFO:root:************* Client 4 Acc = 98.22 **************
INFO:root:************* Server Acc = 77.20 **************
INFO:root:Round 7 Time: 68.74380588531494s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.225410  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.128026  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.091870  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.080750  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.413297  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.077604  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.085748  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.067294  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.394271  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 96.96 **************
INFO:root:************* Client 3 Acc = 98.02 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.071457  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 87.43 **************
INFO:root:************* Client 4 Acc = 98.36 **************
INFO:root:************* Server Acc = 63.42 **************
INFO:root:Round 8 Time: 68.67543911933899s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.383531  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.214118  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.83 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.090944  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.106275  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.407576  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.070792  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.093281  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.070943  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.388918  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.53 **************
INFO:root:************* Client 1 Acc = 97.71 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.065208  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 85.56 **************
INFO:root:************* Client 4 Acc = 98.06 **************
INFO:root:************* Server Acc = 81.59 **************
INFO:root:Round 9 Time: 70.37173748016357s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.240637  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.136070  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.069244  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.087601  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.384526  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.066255  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.058544  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.077939  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 98.47 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.369117  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 97.75 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.062132  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 83.94 **************
INFO:root:************* Client 4 Acc = 98.40 **************
INFO:root:************* Server Acc = 67.08 **************
INFO:root:Round 10 Time: 69.17165946960449s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.375047  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.208868  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.65 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.084835  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.100331  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.371798  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.060830  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.065936  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.086317  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.359252  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.96 **************
INFO:root:************* Client 1 Acc = 97.85 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.058104  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 88.77 **************
INFO:root:************* Client 4 Acc = 98.30 **************
INFO:root:************* Server Acc = 82.67 **************
INFO:root:Round 11 Time: 70.63450574874878s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.356468  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.201160  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.070559  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.074768  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.352494  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.059647  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.069439  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.059078  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 98.24 **************
INFO:root:************* Client 3 Acc = 98.80 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.345131  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.055617  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 89.48 **************
INFO:root:************* Client 4 Acc = 98.66 **************
INFO:root:************* Server Acc = 74.62 **************
INFO:root:Round 12 Time: 68.79795098304749s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.277365  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.152672  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.072421  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.088048  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.351756  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.055049  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.057623  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.076861  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.340534  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.86 **************
INFO:root:************* Client 1 Acc = 98.11 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.052193  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 87.37 **************
INFO:root:************* Client 4 Acc = 98.71 **************
INFO:root:************* Server Acc = 84.51 **************
INFO:root:Round 13 Time: 72.3605318069458s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.300785  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.169176  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.059965  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.067903  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.343181  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.054970  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.050536  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.063118  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.330411  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.95 **************
INFO:root:************* Client 1 Acc = 98.13 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.051816  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 89.53 **************
INFO:root:************* Client 4 Acc = 98.39 **************
INFO:root:************* Server Acc = 77.28 **************
INFO:root:Round 14 Time: 70.58348083496094s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.294186  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.169187  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.081751  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.059761  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.337433  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.052526  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.071541  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.051520  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.327450  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 98.75 **************
INFO:root:************* Client 3 Acc = 98.96 **************
INFO:root:************* Client 2 Acc = 90.43 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.049199  Thread 1  Map [4]
INFO:root:************* Client 4 Acc = 98.71 **************
INFO:root:************* Server Acc = 83.79 **************
INFO:root:Round 15 Time: 73.42596888542175s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.280239  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.164450  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.48 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.056628  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.062006  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.329086  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.048429  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.047961  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.058721  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 98.91 **************
INFO:root:************* Client 1 Acc = 98.37 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.318539  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.045835  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 89.36 **************
INFO:root:************* Client 4 Acc = 98.85 **************
INFO:root:************* Server Acc = 77.93 **************
INFO:root:Round 16 Time: 72.12116122245789s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.282264  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.150821  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.61 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.054270  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.072265  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.317996  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.047099  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.045322  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.064212  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 98.72 **************
INFO:root:************* Client 1 Acc = 97.84 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.309019  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.044173  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 90.24 **************
INFO:root:************* Client 4 Acc = 98.82 **************
INFO:root:************* Server Acc = 85.29 **************
INFO:root:Round 17 Time: 67.22921848297119s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.323209  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.179076  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.061555  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.050075  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.320638  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.050965  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.056880  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.042314  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 98.66 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.309673  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 98.94 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.045381  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 89.90 **************
INFO:root:************* Client 4 Acc = 98.91 **************
INFO:root:************* Server Acc = 77.30 **************
INFO:root:Round 18 Time: 67.57938885688782s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.244806  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.133450  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.048091  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.072672  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.306620  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.044774  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.040705  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.063897  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.300931  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 99.26 **************
INFO:root:************* Client 1 Acc = 98.72 **************
INFO:root:************* Client 2 Acc = 90.59 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.043088  Thread 1  Map [4]
INFO:root:************* Client 4 Acc = 98.90 **************
INFO:root:************* Server Acc = 86.07 **************
INFO:root:Round 19 Time: 71.33949017524719s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.216573  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.121180  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.057016  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.047858  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.301607  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.045722  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.053371  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.041531  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.294622  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 98.54 **************
INFO:root:************* Client 3 Acc = 99.21 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.043044  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 89.88 **************
INFO:root:************* Client 4 Acc = 98.93 **************
INFO:root:************* Server Acc = 77.56 **************
INFO:root:Round 20 Time: 70.55339908599854s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.266990  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.148543  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.61 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.047087  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.067929  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.294838  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.041306  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.040348  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.058903  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 99.25 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.286951  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 98.72 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.038425  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 85.94 **************
INFO:root:************* Client 4 Acc = 99.01 **************
INFO:root:************* Server Acc = 84.29 **************
INFO:root:Round 21 Time: 69.11365175247192s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.270979  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.149736  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.048992  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.056406  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.284523  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.043499  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.038820  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.051487  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.284406  Thread 4  Map [2]
INFO:root:************* Client 3 Acc = 99.32 **************
INFO:root:************* Client 1 Acc = 98.86 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.039421  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 91.49 **************
INFO:root:************* Client 4 Acc = 99.05 **************
INFO:root:************* Server Acc = 78.57 **************
INFO:root:Round 22 Time: 70.90644216537476s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.244623  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.128540  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.065621  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.049776  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.285368  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.042371  Thread 1  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.055537  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.039883  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 98.84 **************
INFO:root:************* Client 3 Acc = 99.24 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.276876  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.037191  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 90.17 **************
INFO:root:************* Client 4 Acc = 99.04 **************
INFO:root:************* Server Acc = 85.10 **************
INFO:root:Round 23 Time: 70.50551104545593s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.229299  Thread 3  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.126527  Thread 3  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.044777  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.056019  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.279810  Thread 4  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.041676  Thread 1  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.037743  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.050263  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 99.18 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.273511  Thread 4  Map [2]
INFO:root:************* Client 1 Acc = 98.81 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.038254  Thread 1  Map [4]
INFO:root:************* Client 2 Acc = 90.83 **************
INFO:root:************* Client 4 Acc = 98.80 **************
INFO:root:************* Server Acc = 78.53 **************
INFO:root:Round 24 Time: 72.16884183883667s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 9, 1: 1, 2: 572, 3: 39, 5: 2, 6: 20, 7: 45, 9: 941}, 1: {0: 2137, 1: 145, 2: 477, 3: 1160, 4: 2317, 5: 150, 7: 4084, 8: 5756}, 2: {0: 3, 1: 14, 2: 4079, 3: 690, 4: 3675, 5: 23, 6: 4697}, 3: {1: 554, 2: 871, 3: 914, 4: 8, 5: 5825, 6: 1283, 7: 1871, 8: 244, 9: 5059}, 4: {0: 3851, 1: 5286, 2: 1, 3: 3197}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 1629
INFO:root:client_idx = 0, batch_num_train_local = 25, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 16226
INFO:root:client_idx = 1, batch_num_train_local = 253, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 13181
INFO:root:client_idx = 2, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 16629
INFO:root:client_idx = 3, batch_num_train_local = 259, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12335
INFO:root:client_idx = 4, batch_num_train_local = 192, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.191621  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.830997  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 86.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.594129  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.246425  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.764663  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.704411  Thread 4  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.429617  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.112244  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 92.58 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.567486  Thread 2  Map [3]
INFO:root:************* Client 2 Acc = 61.58 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.525294  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 89.55 **************
INFO:root:************* Client 1 Acc = 90.39 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 77.05278420448303s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.814784  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.559937  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 92.31 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.395936  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.082252  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.463619  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.538459  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.310297  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.960742  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 93.67 **************
INFO:root:************* Client 2 Acc = 65.56 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.375406  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.422593  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 90.83 **************
INFO:root:************* Client 3 Acc = 87.55 **************
INFO:root:************* Server Acc = 10.22 **************
INFO:root:Round 1 Time: 70.12015199661255s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.480160  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.339491  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.62 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.259745  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.928324  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.324675  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.386321  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.218814  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.806212  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 95.34 **************
INFO:root:************* Client 2 Acc = 76.04 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.280764  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.329539  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 93.17 **************
INFO:root:************* Client 3 Acc = 90.40 **************
INFO:root:************* Server Acc = 26.79 **************
INFO:root:Round 2 Time: 69.57315063476562s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.385183  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.262660  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.192577  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.767505  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.258737  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.302756  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.170927  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.679849  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 95.26 **************
INFO:root:************* Client 2 Acc = 77.87 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.233651  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.268464  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 94.45 **************
INFO:root:************* Client 3 Acc = 91.66 **************
INFO:root:************* Server Acc = 50.82 **************
INFO:root:Round 3 Time: 69.4002423286438s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.322354  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.219605  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.170720  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.655010  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.206426  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.254717  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.147934  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.596502  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 96.34 **************
INFO:root:************* Client 2 Acc = 79.39 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.191608  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.230101  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 94.43 **************
INFO:root:************* Client 3 Acc = 93.25 **************
INFO:root:************* Server Acc = 62.51 **************
INFO:root:Round 4 Time: 69.11198902130127s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.327367  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.212509  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.136787  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.582496  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.186160  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.220000  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.123509  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.540613  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 96.46 **************
INFO:root:************* Client 2 Acc = 84.16 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.173120  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.206633  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 95.46 **************
INFO:root:************* Client 3 Acc = 94.03 **************
INFO:root:************* Server Acc = 71.02 **************
INFO:root:Round 5 Time: 68.53093075752258s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.203167  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154623  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.125259  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.536918  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.159241  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.200487  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.114472  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.501451  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.20 **************
INFO:root:************* Client 2 Acc = 79.57 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.149538  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.186855  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 95.66 **************
INFO:root:************* Client 3 Acc = 93.81 **************
INFO:root:************* Server Acc = 72.54 **************
INFO:root:Round 6 Time: 69.6746518611908s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.230397  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154835  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.118003  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.497073  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.148815  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.176823  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.104095  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.466494  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.14 **************
INFO:root:************* Client 2 Acc = 85.05 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.136619  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.168687  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 96.63 **************
INFO:root:************* Client 3 Acc = 93.77 **************
INFO:root:************* Server Acc = 77.76 **************
INFO:root:Round 7 Time: 66.49007511138916s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.180545  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.123880  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.106040  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.475640  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.165802  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.133253  Thread 4  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.095245  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.442522  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 96.66 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.159857  Thread 2  Map [3]
INFO:root:************* Client 2 Acc = 85.10 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.126583  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 94.11 **************
INFO:root:************* Client 1 Acc = 96.76 **************
INFO:root:************* Server Acc = 81.32 **************
INFO:root:Round 8 Time: 68.65956664085388s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.227678  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.155932  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.098857  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.466475  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.123078  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.159303  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.089171  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.437702  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.25 **************
INFO:root:************* Client 2 Acc = 83.43 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.116407  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.149979  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 96.81 **************
INFO:root:************* Client 3 Acc = 95.37 **************
INFO:root:************* Server Acc = 82.73 **************
INFO:root:Round 9 Time: 69.44486904144287s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.159177  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.109993  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.50 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.100757  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.433520  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.118686  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.148783  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.088013  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.407662  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.79 **************
INFO:root:************* Client 2 Acc = 85.72 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.112340  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.143260  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 96.99 **************
INFO:root:************* Client 3 Acc = 94.37 **************
INFO:root:************* Server Acc = 84.54 **************
INFO:root:Round 10 Time: 69.4034070968628s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.169690  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.117743  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.44 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.091928  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.421023  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.109017  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.144576  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.082689  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.398393  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.103928  Thread 4  Map [1]
INFO:root:************* Client 2 Acc = 86.34 **************
INFO:root:************* Client 4 Acc = 95.51 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.138992  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 97.38 **************
INFO:root:************* Client 3 Acc = 94.59 **************
INFO:root:************* Server Acc = 86.52 **************
INFO:root:Round 11 Time: 65.71994686126709s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.139291  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.099316  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.31 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.084413  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.400331  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.135181  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.104375  Thread 4  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.076959  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.386225  Thread 3  Map [2]
INFO:root:************* Client 2 Acc = 85.59 **************
INFO:root:************* Client 4 Acc = 84.81 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.129493  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.098211  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 96.18 **************
INFO:root:************* Client 1 Acc = 97.11 **************
INFO:root:************* Server Acc = 85.94 **************
INFO:root:Round 12 Time: 67.57664799690247s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.189190  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.125851  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080660  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.392485  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.130090  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.100877  Thread 4  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.075038  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.373358  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.41 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.125849  Thread 2  Map [3]
INFO:root:************* Client 2 Acc = 87.80 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.094529  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 95.09 **************
INFO:root:************* Client 1 Acc = 97.54 **************
INFO:root:************* Server Acc = 85.96 **************
INFO:root:Round 13 Time: 70.81622648239136s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.180335  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.115912  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080428  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.383898  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.127966  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.096267  Thread 4  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.072007  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.362655  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 95.23 **************
INFO:root:************* Client 2 Acc = 86.62 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.122326  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.091388  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 95.32 **************
INFO:root:************* Client 1 Acc = 97.79 **************
INFO:root:************* Server Acc = 86.81 **************
INFO:root:Round 14 Time: 68.89204907417297s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.135850  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.097735  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.069843  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.366253  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.093839  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.123700  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.068468  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.354468  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.39 **************
INFO:root:************* Client 2 Acc = 88.60 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.088868  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.115535  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 97.51 **************
INFO:root:************* Client 3 Acc = 96.51 **************
INFO:root:************* Server Acc = 87.07 **************
INFO:root:Round 15 Time: 69.50906729698181s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.157834  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.105563  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.62 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.065902  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.377356  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.087819  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.119919  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.063198  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.355752  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.75 **************
INFO:root:************* Client 2 Acc = 88.54 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.084193  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.114995  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 97.81 **************
INFO:root:************* Client 3 Acc = 96.49 **************
INFO:root:************* Server Acc = 86.68 **************
INFO:root:Round 16 Time: 66.66181182861328s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.137230  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.098269  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.06 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.069987  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.353353  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.084029  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.115160  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.065228  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.343221  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.57 **************
INFO:root:************* Client 2 Acc = 89.66 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.079417  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.110600  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 97.80 **************
INFO:root:************* Client 3 Acc = 96.60 **************
INFO:root:************* Server Acc = 86.18 **************
INFO:root:Round 17 Time: 69.3717908859253s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.148546  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.106750  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.072311  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.346723  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.079742  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.113700  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.334632  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.064514  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 90.13 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.076638  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 98.42 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.108322  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 97.74 **************
INFO:root:************* Client 3 Acc = 96.37 **************
INFO:root:************* Server Acc = 85.89 **************
INFO:root:Round 18 Time: 69.49592661857605s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.129540  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.089970  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.061521  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.332624  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.079209  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.107178  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.060528  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.326205  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.49 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.074228  Thread 4  Map [1]
INFO:root:************* Client 2 Acc = 89.84 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.103434  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 98.04 **************
INFO:root:************* Client 3 Acc = 96.40 **************
INFO:root:************* Server Acc = 88.23 **************
INFO:root:Round 19 Time: 68.59611296653748s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.148269  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.096731  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.067484  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.333980  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.075578  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.109685  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.059577  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.324467  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.61 **************
INFO:root:************* Client 2 Acc = 90.54 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.072530  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.103371  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 98.15 **************
INFO:root:************* Client 3 Acc = 96.94 **************
INFO:root:************* Server Acc = 86.72 **************
INFO:root:Round 20 Time: 68.17856311798096s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.149964  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.105508  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.065284  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.335385  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.078887  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.103284  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.057752  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.323611  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.71 **************
INFO:root:************* Client 2 Acc = 89.79 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.072668  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.100777  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 97.79 **************
INFO:root:************* Client 3 Acc = 97.21 **************
INFO:root:************* Server Acc = 88.06 **************
INFO:root:Round 21 Time: 68.76832628250122s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.138838  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.097089  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.061241  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.330636  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.075683  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.102207  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.057192  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.317099  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.01 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.069141  Thread 4  Map [1]
INFO:root:************* Client 2 Acc = 90.04 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.098513  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 98.10 **************
INFO:root:************* Client 3 Acc = 97.35 **************
INFO:root:************* Server Acc = 89.07 **************
INFO:root:Round 22 Time: 69.1158857345581s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.113983  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.080260  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.06 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.058840  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.320955  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.099524  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.071228  Thread 4  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.053761  Thread 5  Map [4]
INFO:root:************* Client 4 Acc = 98.49 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.305965  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.096279  Thread 2  Map [3]
INFO:root:************* Client 2 Acc = 89.54 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.066566  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 97.18 **************
INFO:root:************* Client 1 Acc = 98.34 **************
INFO:root:************* Server Acc = 88.46 **************
INFO:root:Round 23 Time: 67.868825674057s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.130148  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.091145  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.81 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.056846  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.321740  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.071854  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.095540  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.052198  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.307460  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.44 **************
INFO:root:************* Client 2 Acc = 89.25 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.064260  Thread 4  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.093239  Thread 2  Map [3]
INFO:root:************* Client 1 Acc = 98.57 **************
INFO:root:************* Client 3 Acc = 96.76 **************
INFO:root:************* Server Acc = 88.54 **************
INFO:root:Round 24 Time: 69.35432314872742s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 278, 1: 188, 2: 941, 3: 1325, 4: 27, 5: 100, 6: 255, 7: 2869, 8: 1, 9: 3810}, 1: {0: 2413, 1: 2049, 2: 871, 3: 875, 4: 2454, 5: 505, 6: 2, 7: 90, 8: 4385}, 2: {0: 184, 1: 1069, 2: 3042, 3: 1099, 4: 3339, 5: 239, 6: 3459}, 3: {0: 51, 1: 410, 2: 1144, 3: 2700, 4: 118, 5: 4895, 6: 1431, 7: 261, 8: 1093}, 4: {0: 3074, 1: 2284, 2: 2, 3: 1, 4: 62, 5: 261, 6: 853, 7: 2780, 8: 521, 9: 2190}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 9794
INFO:root:client_idx = 0, batch_num_train_local = 153, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13644
INFO:root:client_idx = 1, batch_num_train_local = 213, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 12431
INFO:root:client_idx = 2, batch_num_train_local = 194, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 12103
INFO:root:client_idx = 3, batch_num_train_local = 189, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12028
INFO:root:client_idx = 4, batch_num_train_local = 187, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.940690  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.851776  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.810694  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.367861  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.913731  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.716304  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 76.06 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.624504  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.644514  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.214627  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.669403  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 87.27 **************
INFO:root:************* Client 3 Acc = 82.74 **************
INFO:root:************* Client 2 Acc = 61.07 **************
INFO:root:************* Client 1 Acc = 87.48 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 74.11299443244934s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.632862  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.519817  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.580688  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.104151  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.617298  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.500424  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 88.53 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.434850  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.503779  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.978206  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.498790  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 89.80 **************
INFO:root:************* Client 3 Acc = 86.86 **************
INFO:root:************* Client 2 Acc = 70.82 **************
INFO:root:************* Client 1 Acc = 86.73 **************
INFO:root:************* Server Acc = 20.26 **************
INFO:root:Round 1 Time: 65.9211151599884s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.420372  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.431340  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.373368  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.877648  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.414063  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.370457  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 90.42 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.330256  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.391117  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.816499  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.373617  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 88.34 **************
INFO:root:************* Client 3 Acc = 88.96 **************
INFO:root:************* Client 2 Acc = 67.53 **************
INFO:root:************* Client 1 Acc = 88.31 **************
INFO:root:************* Server Acc = 23.26 **************
INFO:root:Round 2 Time: 62.54610896110535s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.356089  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.290104  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.354732  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.771310  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.334273  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.313264  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 91.27 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.269891  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.333035  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.711413  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.305448  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 90.32 **************
INFO:root:************* Client 3 Acc = 89.71 **************
INFO:root:************* Client 2 Acc = 77.41 **************
INFO:root:************* Client 1 Acc = 90.42 **************
INFO:root:************* Server Acc = 61.04 **************
INFO:root:Round 3 Time: 63.21305060386658s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.305062  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.301469  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.255590  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.692134  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.283662  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.277002  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 92.01 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.285326  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.239814  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.633002  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.263993  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 91.73 **************
INFO:root:************* Client 4 Acc = 92.99 **************
INFO:root:************* Client 2 Acc = 76.65 **************
INFO:root:************* Client 1 Acc = 91.21 **************
INFO:root:************* Server Acc = 75.72 **************
INFO:root:Round 4 Time: 63.88442635536194s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.262422  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.269664  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.234170  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.595688  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.244184  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.243280  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 92.22 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.257422  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.219561  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.553221  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.234317  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 91.39 **************
INFO:root:************* Client 4 Acc = 93.26 **************
INFO:root:************* Client 2 Acc = 78.29 **************
INFO:root:************* Client 1 Acc = 92.59 **************
INFO:root:************* Server Acc = 79.51 **************
INFO:root:Round 5 Time: 63.78521490097046s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.241272  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.210075  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.243256  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.533177  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.220117  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.219251  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.00 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.198319  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.231113  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.507330  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.206907  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 93.97 **************
INFO:root:************* Client 3 Acc = 93.18 **************
INFO:root:************* Client 2 Acc = 84.24 **************
INFO:root:************* Client 1 Acc = 93.98 **************
INFO:root:************* Server Acc = 81.52 **************
INFO:root:Round 6 Time: 62.9631712436676s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.217217  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.194219  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.215587  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.503326  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.194753  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.203580  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.30 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.204539  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.187696  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.476943  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.189194  Thread 4  Map [1]
INFO:root:************* Client 3 Acc = 92.40 **************
INFO:root:************* Client 4 Acc = 94.46 **************
INFO:root:************* Client 2 Acc = 84.59 **************
INFO:root:************* Client 1 Acc = 94.82 **************
INFO:root:************* Server Acc = 84.20 **************
INFO:root:Round 7 Time: 64.06320595741272s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.206944  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.207072  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.186380  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.471151  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.179311  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.195977  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.176282  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.198809  Thread 2  Map [3]
INFO:root:************* Client 0 Acc = 94.31 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.450967  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.172431  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 94.59 **************
INFO:root:************* Client 3 Acc = 94.12 **************
INFO:root:************* Client 2 Acc = 85.08 **************
INFO:root:************* Client 1 Acc = 95.11 **************
INFO:root:************* Server Acc = 86.50 **************
INFO:root:Round 8 Time: 63.67147994041443s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.188381  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.194390  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.174369  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.447346  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.168592  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.177715  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.36 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.167280  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.185718  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.432418  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.162545  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 94.98 **************
INFO:root:************* Client 2 Acc = 85.13 **************
INFO:root:************* Client 3 Acc = 83.24 **************
INFO:root:************* Client 1 Acc = 95.22 **************
INFO:root:************* Server Acc = 86.57 **************
INFO:root:Round 9 Time: 64.19165515899658s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.192500  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.173914  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.184796  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.423018  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.163104  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.178252  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.48 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.164856  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.180904  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.413066  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.155967  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 94.68 **************
INFO:root:************* Client 3 Acc = 94.86 **************
INFO:root:************* Client 2 Acc = 85.33 **************
INFO:root:************* Client 1 Acc = 94.08 **************
INFO:root:************* Server Acc = 87.10 **************
INFO:root:Round 10 Time: 67.02655410766602s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.178354  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.155838  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.176853  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.425306  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.152968  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.167788  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.37 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.152533  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.171479  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.405703  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.145538  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 94.99 **************
INFO:root:************* Client 3 Acc = 94.21 **************
INFO:root:************* Client 2 Acc = 76.35 **************
INFO:root:************* Client 1 Acc = 95.26 **************
INFO:root:************* Server Acc = 87.07 **************
INFO:root:Round 11 Time: 63.58323812484741s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.171221  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.157203  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.164646  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.410091  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.146625  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.159078  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.94 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.150185  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.162891  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.393604  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.142925  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 94.57 **************
INFO:root:************* Client 3 Acc = 95.29 **************
INFO:root:************* Client 2 Acc = 86.98 **************
INFO:root:************* Client 1 Acc = 95.53 **************
INFO:root:************* Server Acc = 88.26 **************
INFO:root:Round 12 Time: 65.11238193511963s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.167120  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.160654  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.168985  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.398323  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.143624  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154742  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 94.92 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.148654  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.159379  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.380746  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.139009  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 95.30 **************
INFO:root:************* Client 3 Acc = 95.24 **************
INFO:root:************* Client 2 Acc = 88.43 **************
INFO:root:************* Client 1 Acc = 96.41 **************
INFO:root:************* Server Acc = 89.10 **************
INFO:root:Round 13 Time: 66.3249580860138s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.168615  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.151499  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.375762  Thread 5  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.157453  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.136597  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.155046  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.62 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.144255  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.368352  Thread 5  Map [2]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.152353  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.130742  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 95.48 **************
INFO:root:************* Client 2 Acc = 89.01 **************
INFO:root:************* Client 3 Acc = 95.81 **************
INFO:root:************* Client 1 Acc = 95.36 **************
INFO:root:************* Server Acc = 88.86 **************
INFO:root:Round 14 Time: 63.11060881614685s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.153976  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.145558  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.165018  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.369466  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.135321  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.146532  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.73 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.138423  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.154323  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.361404  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.128974  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 95.55 **************
INFO:root:************* Client 3 Acc = 96.18 **************
INFO:root:************* Client 2 Acc = 88.72 **************
INFO:root:************* Client 1 Acc = 96.47 **************
INFO:root:************* Server Acc = 89.14 **************
INFO:root:Round 15 Time: 68.20669269561768s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.152123  Thread 1  Map [0]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.149569  Thread 2  Map [3]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.137420  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.365143  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.133359  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.143492  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.78 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.133808  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.141186  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.352122  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.125204  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 96.11 **************
INFO:root:************* Client 3 Acc = 80.71 **************
INFO:root:************* Client 2 Acc = 86.89 **************
INFO:root:************* Client 1 Acc = 96.68 **************
INFO:root:************* Server Acc = 89.82 **************
INFO:root:Round 16 Time: 66.80835485458374s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.152827  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.141556  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.144873  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.356073  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.121384  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.142248  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.72 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.134817  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.137206  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.349727  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.115604  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 95.54 **************
INFO:root:************* Client 3 Acc = 96.04 **************
INFO:root:************* Client 2 Acc = 85.85 **************
INFO:root:************* Client 1 Acc = 96.62 **************
INFO:root:************* Server Acc = 89.87 **************
INFO:root:Round 17 Time: 63.56104874610901s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.144943  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.133987  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.357860  Thread 5  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.140019  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.120064  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.139646  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.05 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.127407  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.135144  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.346066  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.114312  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 94.95 **************
INFO:root:************* Client 3 Acc = 95.60 **************
INFO:root:************* Client 2 Acc = 89.05 **************
INFO:root:************* Client 1 Acc = 96.41 **************
INFO:root:************* Server Acc = 89.94 **************
INFO:root:Round 18 Time: 65.2501974105835s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.144571  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.131745  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.141858  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.339874  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.122486  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.135757  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.124953  Thread 3  Map [4]
INFO:root:************* Client 0 Acc = 96.32 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.134064  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.338906  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.113388  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 95.90 **************
INFO:root:************* Client 3 Acc = 95.58 **************
INFO:root:************* Client 2 Acc = 86.08 **************
INFO:root:************* Client 1 Acc = 96.25 **************
INFO:root:************* Server Acc = 90.12 **************
INFO:root:Round 19 Time: 62.906270027160645s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.146983  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.131982  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.135694  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.337997  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.115367  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.133514  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.28 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.125324  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.126735  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.328007  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.110585  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 95.76 **************
INFO:root:************* Client 3 Acc = 95.77 **************
INFO:root:************* Client 2 Acc = 89.39 **************
INFO:root:************* Client 1 Acc = 97.14 **************
INFO:root:************* Server Acc = 90.54 **************
INFO:root:Round 20 Time: 65.46929144859314s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.139846  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.130095  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.134174  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.338985  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.112879  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.131015  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.12 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.124444  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.127210  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.325589  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.108043  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 96.43 **************
INFO:root:************* Client 3 Acc = 96.27 **************
INFO:root:************* Client 2 Acc = 89.04 **************
INFO:root:************* Client 1 Acc = 96.87 **************
INFO:root:************* Server Acc = 90.60 **************
INFO:root:Round 21 Time: 66.42269992828369s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.137179  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.124104  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.137053  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.329399  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.110704  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.130022  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.28 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.118728  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.127084  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.319916  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.103156  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 95.07 **************
INFO:root:************* Client 3 Acc = 96.59 **************
INFO:root:************* Client 2 Acc = 89.55 **************
INFO:root:************* Client 1 Acc = 96.81 **************
INFO:root:************* Server Acc = 90.41 **************
INFO:root:Round 22 Time: 65.91130900382996s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.126470  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.119794  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.324749  Thread 5  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.131554  Thread 2  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.107046  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.122554  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.116489  Thread 3  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.317997  Thread 5  Map [2]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.124421  Thread 2  Map [3]
INFO:root:************* Client 0 Acc = 95.71 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.100259  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 95.81 **************
INFO:root:************* Client 2 Acc = 87.02 **************
INFO:root:************* Client 3 Acc = 96.17 **************
INFO:root:************* Client 1 Acc = 97.21 **************
INFO:root:************* Server Acc = 90.67 **************
INFO:root:Round 23 Time: 64.91869902610779s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.140540  Thread 1  Map [0]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.121304  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.127165  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.322121  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.105008  Thread 4  Map [1]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.125793  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.10 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.114473  Thread 3  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.117870  Thread 2  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.310066  Thread 5  Map [2]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.101814  Thread 4  Map [1]
INFO:root:************* Client 4 Acc = 96.35 **************
INFO:root:************* Client 3 Acc = 96.65 **************
INFO:root:************* Client 2 Acc = 89.60 **************
INFO:root:************* Client 1 Acc = 96.97 **************
INFO:root:************* Server Acc = 90.96 **************
INFO:root:Round 24 Time: 66.18807053565979s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {2: 109, 3: 1, 8: 7, 9: 487}, 1: {0: 1412, 1: 2433, 2: 77, 3: 1151, 4: 2259, 5: 9, 7: 5999}, 2: {1: 227, 2: 5559, 3: 475, 4: 3740, 6: 5574}, 3: {1: 2, 2: 255, 3: 801, 5: 132, 6: 426, 7: 1, 8: 5993, 9: 5513}, 4: {0: 4588, 1: 3338, 3: 3572, 4: 1, 5: 5859}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 604
INFO:root:client_idx = 0, batch_num_train_local = 9, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 13340
INFO:root:client_idx = 1, batch_num_train_local = 208, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 15575
INFO:root:client_idx = 2, batch_num_train_local = 243, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 13123
INFO:root:client_idx = 3, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 17358
INFO:root:client_idx = 4, batch_num_train_local = 271, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.027041  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.828775  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 18.06 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.636642  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.571737  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.207238  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.411888  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.402370  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.423601  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.035062  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 95.07 **************
INFO:root:************* Client 1 Acc = 93.44 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.307454  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 69.57 **************
INFO:root:************* Client 4 Acc = 94.69 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 90.31965184211731s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.060332  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.685628  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 72.22 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.402232  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.374770  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.031807  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.278525  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.276029  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.295916  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.909061  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 95.37 **************
INFO:root:************* Client 1 Acc = 94.15 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.224800  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 52.98 **************
INFO:root:************* Client 4 Acc = 94.81 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 1 Time: 75.59785151481628s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.681679  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.455779  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 93.23 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.234236  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.233876  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.843772  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.187978  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.182902  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.204274  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.727690  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 96.19 **************
INFO:root:************* Client 1 Acc = 94.42 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.159273  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 74.61 **************
INFO:root:************* Client 4 Acc = 96.20 **************
INFO:root:************* Server Acc = 22.31 **************
INFO:root:Round 2 Time: 79.39876222610474s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.527703  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.350280  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.88 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.186085  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.204227  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.661209  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.141800  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.148330  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.175355  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.580510  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 96.71 **************
INFO:root:************* Client 1 Acc = 96.22 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.128092  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 76.76 **************
INFO:root:************* Client 4 Acc = 96.96 **************
INFO:root:************* Server Acc = 42.17 **************
INFO:root:Round 3 Time: 76.64434218406677s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.428502  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.276591  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.92 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.134910  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.141539  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.565527  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.117673  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.111317  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.129670  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 96.64 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.512294  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 96.33 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.105836  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 78.19 **************
INFO:root:************* Client 4 Acc = 97.68 **************
INFO:root:************* Server Acc = 48.97 **************
INFO:root:Round 4 Time: 75.80730295181274s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.551062  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.319368  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.44 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.137395  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.153131  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.499656  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.093100  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.105322  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.131124  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 97.85 **************
INFO:root:************* Client 1 Acc = 96.98 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.087145  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.465830  Thread 2  Map [2]
INFO:root:************* Client 4 Acc = 96.54 **************
INFO:root:************* Client 2 Acc = 84.93 **************
INFO:root:************* Server Acc = 64.26 **************
INFO:root:Round 5 Time: 68.36875414848328s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.293079  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.174754  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.115368  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.097475  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.462831  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.094713  Thread 5  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.102057  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.083517  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.439352  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 97.47 **************
INFO:root:************* Client 3 Acc = 98.18 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.084347  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 83.27 **************
INFO:root:************* Client 4 Acc = 96.98 **************
INFO:root:************* Server Acc = 57.21 **************
INFO:root:Round 6 Time: 71.39795112609863s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.509648  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.279114  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.78 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.107716  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.124730  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.438741  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080716  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.084166  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.106728  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 97.70 **************
INFO:root:************* Client 1 Acc = 97.62 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.416064  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.073781  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 86.52 **************
INFO:root:************* Client 4 Acc = 98.22 **************
INFO:root:************* Server Acc = 77.20 **************
INFO:root:Round 7 Time: 68.15648365020752s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.225410  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.128026  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.080750  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.091870  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.413297  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.077604  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.067294  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.085748  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.394271  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 98.02 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.071457  Thread 5  Map [4]
INFO:root:************* Client 1 Acc = 96.96 **************
INFO:root:************* Client 2 Acc = 87.43 **************
INFO:root:************* Client 4 Acc = 98.36 **************
INFO:root:************* Server Acc = 63.42 **************
INFO:root:Round 8 Time: 67.50865387916565s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.383531  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.214118  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.83 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.090944  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.106275  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.407576  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.070792  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.070943  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.093281  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.53 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.388918  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 97.71 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.065208  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 85.56 **************
INFO:root:************* Client 4 Acc = 98.06 **************
INFO:root:************* Server Acc = 81.59 **************
INFO:root:Round 9 Time: 71.60050654411316s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.240637  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.136070  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.069244  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.087601  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.384526  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.066255  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.058544  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.077939  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.369117  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 98.47 **************
INFO:root:************* Client 1 Acc = 97.75 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.062132  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 83.94 **************
INFO:root:************* Client 4 Acc = 98.40 **************
INFO:root:************* Server Acc = 67.08 **************
INFO:root:Round 10 Time: 71.60037565231323s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.375047  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.208868  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.65 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.084835  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.100331  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.371798  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.060830  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.065936  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.086317  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.359252  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 98.96 **************
INFO:root:************* Client 1 Acc = 97.85 **************
INFO:root:************* Client 2 Acc = 88.77 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.058104  Thread 5  Map [4]
INFO:root:************* Client 4 Acc = 98.30 **************
INFO:root:************* Server Acc = 82.67 **************
INFO:root:Round 11 Time: 70.90370869636536s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.356468  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.201160  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.074768  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.070559  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.352494  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.059647  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.059078  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.069439  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.345131  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 98.80 **************
INFO:root:************* Client 1 Acc = 98.24 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.055617  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 89.48 **************
INFO:root:************* Client 4 Acc = 98.66 **************
INFO:root:************* Server Acc = 74.62 **************
INFO:root:Round 12 Time: 71.97504472732544s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.277365  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.152672  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.088048  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.072421  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.351756  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.055049  Thread 5  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.076861  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.057623  Thread 4  Map [3]
INFO:root:************* Client 1 Acc = 98.11 **************
INFO:root:************* Client 3 Acc = 98.86 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.340534  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.052193  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 87.37 **************
INFO:root:************* Client 4 Acc = 98.71 **************
INFO:root:************* Server Acc = 84.51 **************
INFO:root:Round 13 Time: 72.85643577575684s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.300785  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.169176  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.059965  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.067903  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.343181  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.054970  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.050536  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.063118  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.330411  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 98.95 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.051816  Thread 5  Map [4]
INFO:root:************* Client 1 Acc = 98.13 **************
INFO:root:************* Client 2 Acc = 89.53 **************
INFO:root:************* Client 4 Acc = 98.39 **************
INFO:root:************* Server Acc = 77.28 **************
INFO:root:Round 14 Time: 67.72647309303284s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.294186  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.169187  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.059761  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.081751  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.337433  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.052526  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.051520  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.071541  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.96 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.327450  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 98.75 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.049199  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 90.43 **************
INFO:root:************* Client 4 Acc = 98.71 **************
INFO:root:************* Server Acc = 83.79 **************
INFO:root:Round 15 Time: 71.62998867034912s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.280239  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.164450  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.48 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.056628  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.062006  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.329086  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.048429  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.047961  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.058721  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.91 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.318539  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 98.37 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.045835  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 89.36 **************
INFO:root:************* Client 4 Acc = 98.85 **************
INFO:root:************* Server Acc = 77.93 **************
INFO:root:Round 16 Time: 70.22934079170227s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.282264  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.150821  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.61 **************
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.072265  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.054270  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.317996  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.047099  Thread 5  Map [4]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.064212  Thread 3  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.045322  Thread 4  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.309019  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 97.84 **************
INFO:root:************* Client 3 Acc = 98.72 **************
INFO:root:************* Client 2 Acc = 90.24 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.044173  Thread 5  Map [4]
INFO:root:************* Client 4 Acc = 98.82 **************
INFO:root:************* Server Acc = 85.29 **************
INFO:root:Round 17 Time: 73.44508218765259s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.323209  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.179076  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.050075  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.061555  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.320638  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.050965  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.042314  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.056880  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 98.94 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.045381  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.309673  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 98.66 **************
INFO:root:************* Client 2 Acc = 89.90 **************
INFO:root:************* Client 4 Acc = 98.91 **************
INFO:root:************* Server Acc = 77.30 **************
INFO:root:Round 18 Time: 68.92032814025879s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.244806  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.133450  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.048091  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.072672  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.306620  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.044774  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.040705  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.063897  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.300931  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 99.26 **************
INFO:root:************* Client 1 Acc = 98.72 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.043088  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 90.59 **************
INFO:root:************* Client 4 Acc = 98.90 **************
INFO:root:************* Server Acc = 86.07 **************
INFO:root:Round 19 Time: 70.05723261833191s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.216573  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.121180  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.047858  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.057016  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.301607  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.045722  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.041531  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.053371  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.294622  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 99.21 **************
INFO:root:************* Client 1 Acc = 98.54 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.043044  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 89.88 **************
INFO:root:************* Client 4 Acc = 98.93 **************
INFO:root:************* Server Acc = 77.56 **************
INFO:root:Round 20 Time: 71.8850474357605s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.266990  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.148543  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.61 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.047087  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.067929  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.294838  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.041306  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.040348  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.058903  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.286951  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 99.25 **************
INFO:root:************* Client 1 Acc = 98.72 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.038425  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 85.94 **************
INFO:root:************* Client 4 Acc = 99.01 **************
INFO:root:************* Server Acc = 84.29 **************
INFO:root:Round 21 Time: 71.86993980407715s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.270979  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.149736  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.048992  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.056406  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.284523  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.043499  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.038820  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.051487  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.284406  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 99.32 **************
INFO:root:************* Client 1 Acc = 98.86 **************
INFO:root:************* Client 2 Acc = 91.49 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.039421  Thread 5  Map [4]
INFO:root:************* Client 4 Acc = 99.05 **************
INFO:root:************* Server Acc = 78.57 **************
INFO:root:Round 22 Time: 72.46752786636353s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.244623  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.128540  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.96 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.049776  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.065621  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.285368  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.042371  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.039883  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.055537  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.276876  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 99.24 **************
INFO:root:************* Client 1 Acc = 98.84 **************
INFO:root:************* Client 2 Acc = 90.17 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.037191  Thread 5  Map [4]
INFO:root:************* Client 4 Acc = 99.04 **************
INFO:root:************* Server Acc = 85.10 **************
INFO:root:Round 23 Time: 72.3079833984375s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.229299  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.126527  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.31 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.044777  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.056019  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.279810  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.041676  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.037743  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.050263  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.273511  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 99.18 **************
INFO:root:************* Client 1 Acc = 98.81 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.038254  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 90.83 **************
INFO:root:************* Client 4 Acc = 98.80 **************
INFO:root:************* Server Acc = 78.53 **************
INFO:root:Round 24 Time: 69.36963677406311s
INFO:root:************** Round: 25 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.243268  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.136073  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.044793  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.062014  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.274211  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.036412  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.035773  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.054326  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 99.25 **************
INFO:root:************* Client 1 Acc = 98.87 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.271363  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.034364  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 91.15 **************
INFO:root:************* Client 4 Acc = 99.14 **************
INFO:root:************* Server Acc = 84.74 **************
INFO:root:Round 25 Time: 67.19940161705017s
INFO:root:************** Round: 26 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.239204  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.123205  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.78 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.045609  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.054537  Thread 3  Map [1]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.037792  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.265574  Thread 2  Map [2]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.037832  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.047369  Thread 3  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.035405  Thread 5  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.263107  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 99.34 **************
INFO:root:************* Client 1 Acc = 99.02 **************
INFO:root:************* Client 2 Acc = 90.29 **************
INFO:root:************* Client 4 Acc = 99.19 **************
INFO:root:************* Server Acc = 80.83 **************
INFO:root:Round 26 Time: 68.73534560203552s
INFO:root:************** Round: 27 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.207661  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.113099  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.78 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.040297  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.058912  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.267397  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.036731  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.033540  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.050553  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.262181  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 99.55 **************
INFO:root:************* Client 1 Acc = 98.92 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.035101  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 91.44 **************
INFO:root:************* Client 4 Acc = 99.00 **************
INFO:root:************* Server Acc = 84.49 **************
INFO:root:Round 27 Time: 74.17832374572754s
INFO:root:************** Round: 28 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.283102  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.155017  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.44 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.041734  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.049244  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.259960  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.037890  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.034828  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.045301  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.257485  Thread 2  Map [2]
INFO:root:************* Client 3 Acc = 99.38 **************
INFO:root:************* Client 1 Acc = 98.87 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.033156  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 89.49 **************
INFO:root:************* Client 4 Acc = 99.25 **************
INFO:root:************* Server Acc = 79.40 **************
INFO:root:Round 28 Time: 71.09552645683289s
INFO:root:************** Round: 29 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.209468  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.112229  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.13 **************
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.037320  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.056984  Thread 3  Map [1]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.260145  Thread 2  Map [2]
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.034611  Thread 5  Map [4]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.030759  Thread 4  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.048691  Thread 3  Map [1]
INFO:root:************* Client 3 Acc = 99.47 **************
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.255091  Thread 2  Map [2]
INFO:root:************* Client 1 Acc = 99.12 **************
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.031112  Thread 5  Map [4]
INFO:root:************* Client 2 Acc = 92.53 **************
INFO:root:************* Client 4 Acc = 99.09 **************
INFO:root:************* Server Acc = 86.28 **************
INFO:root:Round 29 Time: 70.3129653930664s
1
INFO:root:*********partition data***************
INFO:root:N = 60000
INFO:root:traindata_cls_counts = {0: {0: 9, 1: 1, 2: 572, 3: 39, 5: 2, 6: 20, 7: 45, 9: 941}, 1: {0: 2137, 1: 145, 2: 477, 3: 1160, 4: 2317, 5: 150, 7: 4084, 8: 5756}, 2: {0: 3, 1: 14, 2: 4079, 3: 690, 4: 3675, 5: 23, 6: 4697}, 3: {1: 554, 2: 871, 3: 914, 4: 8, 5: 5825, 6: 1283, 7: 1871, 8: 244, 9: 5059}, 4: {0: 3851, 1: 5286, 2: 1, 3: 3197}}
INFO:root:train_dl_global number = 937
INFO:root:test_dl_global number = 937
INFO:root:client_idx = 0, local_sample_number = 1629
INFO:root:client_idx = 0, batch_num_train_local = 25, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 16226
INFO:root:client_idx = 1, batch_num_train_local = 253, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 13181
INFO:root:client_idx = 2, batch_num_train_local = 205, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 16629
INFO:root:client_idx = 3, batch_num_train_local = 259, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 12335
INFO:root:client_idx = 4, batch_num_train_local = 192, batch_num_test_local = 156
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
download = True
INFO:root:************** Round: 0 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 1.191621  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.830997  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 86.12 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.594129  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.246425  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.704411  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.764663  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.429617  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 1.112244  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 92.58 **************
INFO:root:************* Client 2 Acc = 61.58 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.525294  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.567486  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 90.39 **************
INFO:root:************* Client 3 Acc = 89.55 **************
INFO:root:************* Server Acc = 9.99 **************
INFO:root:Round 0 Time: 80.52629542350769s
INFO:root:************** Round: 1 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.814784  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.559937  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 92.31 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.395936  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 1.082252  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.463619  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.538459  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.310297  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.960742  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 93.67 **************
INFO:root:************* Client 2 Acc = 65.56 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.375406  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.422593  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 90.83 **************
INFO:root:************* Client 3 Acc = 87.55 **************
INFO:root:************* Server Acc = 10.22 **************
INFO:root:Round 1 Time: 70.59333062171936s
INFO:root:************** Round: 2 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.480160  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.339491  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 95.62 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.259745  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.928324  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.324675  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.386321  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.218814  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.806212  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 95.34 **************
INFO:root:************* Client 2 Acc = 76.04 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.280764  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.329539  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 93.17 **************
INFO:root:************* Client 3 Acc = 90.40 **************
INFO:root:************* Server Acc = 26.79 **************
INFO:root:Round 2 Time: 70.60855054855347s
INFO:root:************** Round: 3 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.385183  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.262660  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 96.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.192577  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.767505  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.302756  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.258737  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.679849  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.170927  Thread 4  Map [4]
INFO:root:************* Client 2 Acc = 77.87 **************
INFO:root:************* Client 4 Acc = 95.26 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.268464  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.233651  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 91.66 **************
INFO:root:************* Client 1 Acc = 94.45 **************
INFO:root:************* Server Acc = 50.82 **************
INFO:root:Round 3 Time: 68.86527752876282s
INFO:root:************** Round: 4 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.322354  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.219605  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.170720  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.655010  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.254717  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.206426  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.147934  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.596502  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 96.34 **************
INFO:root:************* Client 2 Acc = 79.39 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.230101  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.191608  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 93.25 **************
INFO:root:************* Client 1 Acc = 94.43 **************
INFO:root:************* Server Acc = 62.51 **************
INFO:root:Round 4 Time: 69.35504126548767s
INFO:root:************** Round: 5 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.327367  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.212509  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.136787  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.582496  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.186160  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.220000  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.123509  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.540613  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 96.46 **************
INFO:root:************* Client 2 Acc = 84.16 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.173120  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.206633  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 95.46 **************
INFO:root:************* Client 3 Acc = 94.03 **************
INFO:root:************* Server Acc = 71.02 **************
INFO:root:Round 5 Time: 70.21639156341553s
INFO:root:************** Round: 6 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.203167  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154623  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.88 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.125259  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.536918  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.159241  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.200487  Thread 5  Map [3]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.501451  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.114472  Thread 4  Map [4]
INFO:root:************* Client 4 Acc = 97.20 **************
INFO:root:************* Client 2 Acc = 79.57 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.149538  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.186855  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 95.66 **************
INFO:root:************* Client 3 Acc = 93.81 **************
INFO:root:************* Server Acc = 72.54 **************
INFO:root:Round 6 Time: 70.47852230072021s
INFO:root:************** Round: 7 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.230397  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.154835  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.118003  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.497073  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.176823  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.148815  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.104095  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.466494  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.14 **************
INFO:root:************* Client 2 Acc = 85.05 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.168687  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.136619  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 93.77 **************
INFO:root:************* Client 1 Acc = 96.63 **************
INFO:root:************* Server Acc = 77.76 **************
INFO:root:Round 7 Time: 68.20979285240173s
INFO:root:************** Round: 8 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.180545  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.123880  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.106040  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.475640  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.133253  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.165802  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.095245  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.442522  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 96.66 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.126583  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.159857  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 85.10 **************
INFO:root:************* Client 1 Acc = 96.76 **************
INFO:root:************* Client 3 Acc = 94.11 **************
INFO:root:************* Server Acc = 81.32 **************
INFO:root:Round 8 Time: 67.55383133888245s
INFO:root:************** Round: 9 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.227678  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.155932  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 97.38 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.098857  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.466475  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.159303  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.123078  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.089171  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.437702  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.25 **************
INFO:root:************* Client 2 Acc = 83.43 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.116407  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.149979  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 96.81 **************
INFO:root:************* Client 3 Acc = 95.37 **************
INFO:root:************* Server Acc = 82.73 **************
INFO:root:Round 9 Time: 67.9362211227417s
INFO:root:************** Round: 10 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.159177  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.109993  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.50 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.100757  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.433520  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.148783  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.118686  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.088013  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.407662  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.79 **************
INFO:root:************* Client 2 Acc = 85.72 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.143260  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.112340  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 94.37 **************
INFO:root:************* Client 1 Acc = 96.99 **************
INFO:root:************* Server Acc = 84.54 **************
INFO:root:Round 10 Time: 67.80328297615051s
INFO:root:************** Round: 11 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.169690  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.117743  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.44 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.091928  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.421023  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.144576  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.109017  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.082689  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.398393  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 95.51 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.138992  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 86.34 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.103928  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 94.59 **************
INFO:root:************* Client 1 Acc = 97.38 **************
INFO:root:************* Server Acc = 86.52 **************
INFO:root:Round 11 Time: 68.2010407447815s
INFO:root:************** Round: 12 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.139291  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.099316  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.31 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.084413  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.400331  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.104375  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.135181  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.076959  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.386225  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 84.81 **************
INFO:root:************* Client 2 Acc = 85.59 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.098211  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.129493  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.11 **************
INFO:root:************* Client 3 Acc = 96.18 **************
INFO:root:************* Server Acc = 85.94 **************
INFO:root:Round 12 Time: 67.59465909004211s
INFO:root:************** Round: 13 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.189190  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.125851  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080660  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.392485  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.100877  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.130090  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.075038  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.373358  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.41 **************
INFO:root:************* Client 2 Acc = 87.80 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.094529  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.125849  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.54 **************
INFO:root:************* Client 3 Acc = 95.09 **************
INFO:root:************* Server Acc = 85.96 **************
INFO:root:Round 13 Time: 69.86308670043945s
INFO:root:************** Round: 14 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.180335  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.115912  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.080428  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.383898  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.127966  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.096267  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.072007  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.362655  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 95.23 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.122326  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 86.62 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.091388  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 95.32 **************
INFO:root:************* Client 1 Acc = 97.79 **************
INFO:root:************* Server Acc = 86.81 **************
INFO:root:Round 14 Time: 68.73254418373108s
INFO:root:************** Round: 15 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.135850  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.097735  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.069843  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.366253  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.123700  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.093839  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.068468  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.354468  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.39 **************
INFO:root:************* Client 2 Acc = 88.60 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.115535  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.088868  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 96.51 **************
INFO:root:************* Client 1 Acc = 97.51 **************
INFO:root:************* Server Acc = 87.07 **************
INFO:root:Round 15 Time: 67.00864219665527s
INFO:root:************** Round: 16 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.157834  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.105563  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.62 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.065902  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.377356  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.119919  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.087819  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.063198  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.355752  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 97.75 **************
INFO:root:************* Client 2 Acc = 88.54 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.114995  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.084193  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 96.49 **************
INFO:root:************* Client 1 Acc = 97.81 **************
INFO:root:************* Server Acc = 86.68 **************
INFO:root:Round 16 Time: 67.99024748802185s
INFO:root:************** Round: 17 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.137230  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.098269  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.06 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.069987  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.353353  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.115160  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.084029  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.065228  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.343221  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.57 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.110600  Thread 5  Map [3]
INFO:root:************* Client 2 Acc = 89.66 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.079417  Thread 2  Map [1]
INFO:root:************* Client 3 Acc = 96.60 **************
INFO:root:************* Client 1 Acc = 97.80 **************
INFO:root:************* Server Acc = 86.18 **************
INFO:root:Round 17 Time: 68.18102502822876s
INFO:root:************** Round: 18 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.148546  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.106750  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.072311  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.346723  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.079742  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.113700  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.064514  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.334632  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.42 **************
INFO:root:************* Client 2 Acc = 90.13 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.076638  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.108322  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.74 **************
INFO:root:************* Client 3 Acc = 96.37 **************
INFO:root:************* Server Acc = 85.89 **************
INFO:root:Round 18 Time: 70.89322638511658s
INFO:root:************** Round: 19 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.129540  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.089970  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.19 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.061521  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.332624  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.079209  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.107178  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.060528  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.326205  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.49 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.103434  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.074228  Thread 2  Map [1]
INFO:root:************* Client 2 Acc = 89.84 **************
INFO:root:************* Client 3 Acc = 96.40 **************
INFO:root:************* Client 1 Acc = 98.04 **************
INFO:root:************* Server Acc = 88.23 **************
INFO:root:Round 19 Time: 66.94702243804932s
INFO:root:************** Round: 20 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.148269  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.096731  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.94 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.067484  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.333980  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.109685  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.075578  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.059577  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.324467  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.61 **************
INFO:root:************* Client 2 Acc = 90.54 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.103371  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.072530  Thread 2  Map [1]
INFO:root:************* Client 1 Acc = 98.15 **************
INFO:root:************* Client 3 Acc = 96.94 **************
INFO:root:************* Server Acc = 86.72 **************
INFO:root:Round 20 Time: 67.54923295974731s
INFO:root:************** Round: 21 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.149964  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.105508  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.065284  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.335385  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.078887  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.103284  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.057752  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.323611  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.71 **************
INFO:root:************* Client 2 Acc = 89.79 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.072668  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.100777  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 97.79 **************
INFO:root:************* Client 3 Acc = 97.21 **************
INFO:root:************* Server Acc = 88.06 **************
INFO:root:Round 21 Time: 69.82572937011719s
INFO:root:************** Round: 22 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.138838  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.097089  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.56 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.061241  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.330636  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.075683  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.102207  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.057192  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.317099  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.01 **************
INFO:root:************* Client 2 Acc = 90.04 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.069141  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.098513  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 98.10 **************
INFO:root:************* Client 3 Acc = 97.35 **************
INFO:root:************* Server Acc = 89.07 **************
INFO:root:Round 22 Time: 71.05604314804077s
INFO:root:************** Round: 23 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.113983  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.080260  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.06 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.058840  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.320955  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.099524  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.071228  Thread 2  Map [1]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.305965  Thread 3  Map [2]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.053761  Thread 4  Map [4]
INFO:root:************* Client 2 Acc = 89.54 **************
INFO:root:************* Client 4 Acc = 98.49 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.096279  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.066566  Thread 2  Map [1]
INFO:root:************* Client 1 Acc = 98.34 **************
INFO:root:************* Client 3 Acc = 97.18 **************
INFO:root:************* Server Acc = 88.46 **************
INFO:root:Round 23 Time: 68.35792875289917s
INFO:root:************** Round: 24 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.130148  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.091145  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.81 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.056846  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.321740  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.071854  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.095540  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.052198  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.307460  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.44 **************
INFO:root:************* Client 2 Acc = 89.25 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.064260  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.093239  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 98.57 **************
INFO:root:************* Client 3 Acc = 96.76 **************
INFO:root:************* Server Acc = 88.54 **************
INFO:root:Round 24 Time: 70.12487745285034s
INFO:root:************** Round: 25 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.138855  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.094788  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.75 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.054578  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.307303  Thread 3  Map [2]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.095761  Thread 5  Map [3]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.071239  Thread 2  Map [1]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.050008  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.299188  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.58 **************
INFO:root:************* Client 2 Acc = 83.60 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.066035  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.091970  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 98.44 **************
INFO:root:************* Client 3 Acc = 96.81 **************
INFO:root:************* Server Acc = 88.23 **************
INFO:root:Round 25 Time: 69.80406451225281s
INFO:root:************** Round: 26 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.156114  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.106108  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 99.00 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.053248  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.301771  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.065082  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.094354  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.049503  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.289978  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.89 **************
INFO:root:************* Client 2 Acc = 90.16 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.059838  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.089738  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 98.22 **************
INFO:root:************* Client 3 Acc = 96.86 **************
INFO:root:************* Server Acc = 87.84 **************
INFO:root:Round 26 Time: 71.09263563156128s
INFO:root:************** Round: 27 ***************
INFO:root:(client 0. Local Training Epoch: 0 	Loss: 0.144899  Thread 1  Map [0]
INFO:root:(client 0. Local Training Epoch: 1 	Loss: 0.100674  Thread 1  Map [0]
INFO:root:************* Client 0 Acc = 98.69 **************
INFO:root:(client 4. Local Training Epoch: 0 	Loss: 0.053587  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 0 	Loss: 0.297221  Thread 3  Map [2]
INFO:root:(client 1. Local Training Epoch: 0 	Loss: 0.066452  Thread 2  Map [1]
INFO:root:(client 3. Local Training Epoch: 0 	Loss: 0.093834  Thread 5  Map [3]
INFO:root:(client 4. Local Training Epoch: 1 	Loss: 0.048098  Thread 4  Map [4]
INFO:root:(client 2. Local Training Epoch: 1 	Loss: 0.288796  Thread 3  Map [2]
INFO:root:************* Client 4 Acc = 98.89 **************
INFO:root:(client 1. Local Training Epoch: 1 	Loss: 0.060102  Thread 2  Map [1]
INFO:root:************* Client 2 Acc = 83.25 **************
INFO:root:(client 3. Local Training Epoch: 1 	Loss: 0.089057  Thread 5  Map [3]
INFO:root:************* Client 1 Acc = 98.55 **************
INFO:root:************* Client 3 Acc = 97.09 **************
INFO:root:************* Server Acc = 87.60 **************
1
Traceback (most recent call last):
  File "main.py", line 285, in <module>
    server_outputs = server.run(client_outputs)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 109, in run
    self.log_info(received_info, acc)
  File "/home/listu/yiqin/FedBench/methods/base.py", line 128, in log_info
    with open('{}/out.log'.format(self.save_path), 'a+') as out_file:
FileNotFoundError: [Errno 2] No such file or directory: '/home/listu/yiqin/FedBench/logs/20220916_145903__fedavg_e2_c5_fmnist/out.log'
INFO:root:*********partition data***************
INFO:root:N = 50000
INFO:root:traindata_cls_counts = {0: {0: 145, 3: 14, 7: 34, 8: 104, 9: 1, 10: 496, 11: 24, 12: 126, 15: 5, 16: 14, 18: 12, 20: 6, 21: 8, 24: 8, 26: 240, 27: 1, 29: 95, 30: 1, 32: 1, 33: 191, 35: 67, 36: 1, 37: 233, 38: 23, 39: 20, 43: 8, 44: 17, 46: 34, 48: 192, 50: 2, 53: 19, 54: 245, 56: 2, 60: 129, 66: 61, 67: 171, 68: 174, 71: 2, 72: 3, 74: 318, 75: 125, 76: 1, 81: 120, 83: 14, 84: 98, 85: 1, 88: 16, 89: 410, 90: 11, 91: 82, 92: 56, 94: 441, 96: 33, 97: 13, 98: 45}, 1: {0: 1, 2: 2, 4: 116, 7: 283, 9: 1, 12: 1, 13: 464, 15: 259, 16: 2, 17: 29, 20: 75, 21: 1, 22: 377, 23: 92, 26: 4, 27: 180, 34: 28, 35: 2, 36: 288, 37: 29, 38: 2, 39: 1, 46: 1, 51: 24, 52: 41, 54: 204, 56: 184, 57: 85, 58: 425, 59: 205, 60: 358, 61: 160, 65: 82, 68: 230, 71: 61, 73: 122, 74: 180, 75: 374, 76: 46}, 2: {0: 17, 4: 2, 5: 299, 6: 46, 9: 277, 10: 3, 14: 61, 19: 492, 24: 58, 26: 203, 29: 2, 30: 3, 31: 11, 32: 1, 33: 2, 34: 109, 35: 72, 37: 3, 40: 8, 41: 10, 42: 54, 43: 1, 45: 12, 46: 8, 47: 277, 48: 1, 50: 107, 51: 15, 52: 1, 53: 4, 54: 1, 55: 1, 59: 4, 60: 6, 61: 265, 62: 5, 65: 4, 66: 2, 73: 34, 76: 383, 82: 81, 83: 126, 84: 1, 85: 469, 88: 28, 89: 43, 90: 1, 91: 18, 93: 277, 97: 333, 98: 376, 99: 119}, 3: {1: 350, 2: 73, 3: 8, 4: 316, 5: 66, 6: 1, 8: 35, 11: 1, 12: 345, 13: 20, 14: 4, 18: 1, 19: 3, 23: 1, 24: 4, 25: 11, 26: 23, 28: 22, 30: 289, 32: 66, 34: 24, 37: 233, 38: 1, 40: 15, 46: 164, 51: 25, 53: 68, 54: 1, 56: 4, 60: 5, 61: 8, 64: 154, 65: 11, 66: 2, 67: 216, 69: 4, 70: 446, 71: 8, 72: 14, 74: 1, 79: 9, 80: 1, 82: 403, 83: 7, 84: 42, 85: 4, 86: 22, 87: 373, 88: 288, 90: 464, 94: 58, 95: 205, 96: 4, 97: 152}, 4: {1: 115, 2: 396, 5: 128, 6: 189, 7: 81, 11: 303, 12: 8, 15: 10, 19: 1, 20: 13, 21: 129, 24: 1, 25: 402, 30: 110, 31: 269, 33: 145, 34: 301, 40: 194, 42: 400, 43: 337, 48: 19, 49: 337, 52: 20, 55: 464, 57: 1, 59: 1, 63: 8, 64: 275, 65: 17, 69: 99, 70: 2, 72: 15, 77: 59, 82: 15, 84: 32, 90: 23, 91: 195}, 5: {0: 306, 1: 19, 2: 2, 8: 5, 9: 1, 11: 6, 12: 1, 14: 1, 15: 148, 17: 175, 21: 304, 22: 89, 25: 10, 26: 2, 27: 21, 28: 3, 30: 67, 31: 18, 32: 155, 33: 20, 35: 200, 36: 210, 37: 1, 38: 33, 40: 6, 42: 2, 43: 35, 47: 93, 48: 72, 50: 94, 51: 100, 52: 4, 53: 181, 56: 83, 57: 246, 58: 1, 61: 2, 62: 494, 63: 1, 64: 57, 65: 18, 70: 20, 72: 9, 73: 1, 76: 59, 79: 36, 80: 411, 81: 178, 83: 352, 84: 56, 85: 25, 88: 167, 89: 22, 91: 166, 92: 431}, 6: {0: 29, 1: 1, 2: 4, 3: 55, 6: 52, 7: 43, 8: 2, 9: 19, 11: 165, 14: 225, 15: 56, 16: 350, 18: 486, 22: 18, 23: 355, 24: 11, 28: 5, 29: 10, 30: 10, 33: 3, 34: 2, 38: 440, 39: 36, 40: 71, 43: 65, 44: 24, 45: 484, 47: 61, 48: 8, 49: 29, 50: 294, 51: 12, 53: 225, 58: 3, 60: 1, 61: 1, 65: 177, 66: 434, 67: 111, 68: 95, 69: 2, 72: 206, 73: 1, 77: 235, 79: 4, 80: 15, 81: 5, 84: 50, 87: 124}, 7: {0: 1, 1: 8, 2: 22, 3: 312, 5: 1, 6: 1, 7: 58, 8: 349, 12: 18, 13: 2, 14: 1, 15: 21, 16: 5, 19: 3, 21: 57, 22: 3, 24: 208, 25: 2, 26: 3, 27: 26, 28: 386, 31: 4, 33: 14, 35: 8, 39: 8, 40: 33, 42: 43, 44: 17, 45: 2, 49: 130, 50: 2, 55: 34, 56: 2, 58: 66, 59: 271, 61: 35, 64: 2, 65: 83, 66: 1, 71: 3, 73: 11, 76: 2, 78: 477, 79: 32, 81: 101, 84: 220, 86: 475, 87: 3, 89: 24, 91: 38, 92: 12, 93: 2, 95: 295, 96: 463, 97: 2, 98: 79, 99: 381}, 8: {1: 2, 3: 110, 6: 209, 9: 198, 13: 5, 14: 207, 17: 295, 22: 9, 23: 1, 25: 2, 27: 271, 29: 95, 30: 19, 31: 17, 34: 15, 35: 109, 39: 434, 40: 172, 46: 21, 47: 68, 51: 18, 53: 2, 56: 224, 59: 18, 61: 1, 64: 12, 65: 107, 67: 2, 69: 395, 70: 31, 71: 426, 72: 253, 73: 330, 74: 1, 75: 1, 76: 9, 77: 206, 78: 23, 79: 419, 80: 72, 81: 96, 82: 1, 83: 1, 84: 1, 85: 1, 86: 3, 88: 1, 90: 1, 93: 221}, 9: {0: 1, 1: 5, 2: 1, 3: 1, 4: 66, 5: 6, 6: 2, 7: 1, 8: 5, 9: 3, 10: 1, 11: 1, 12: 1, 13: 9, 14: 1, 15: 1, 16: 129, 17: 1, 18: 1, 19: 1, 20: 406, 21: 1, 22: 4, 23: 51, 24: 210, 25: 73, 26: 25, 27: 1, 28: 84, 29: 298, 30: 1, 31: 181, 32: 277, 33: 125, 34: 21, 35: 42, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 490, 42: 1, 43: 54, 44: 442, 45: 2, 46: 272, 47: 1, 48: 208, 49: 4, 50: 1, 51: 306, 52: 434, 53: 1, 54: 49, 55: 1, 56: 1, 57: 168, 58: 5, 59: 1, 60: 1, 61: 28, 62: 1, 63: 491, 65: 1, 68: 1, 70: 1, 73: 1, 80: 1, 89: 1, 91: 1, 92: 1, 94: 1}}
INFO:root:train_dl_global number = 10905
INFO:root:test_dl_global number = 10905
INFO:root:client_idx = 0, local_sample_number = 4713
INFO:root:client_idx = 0, batch_num_train_local = 73, batch_num_test_local = 156
INFO:root:client_idx = 1, local_sample_number = 5019
INFO:root:client_idx = 1, batch_num_train_local = 78, batch_num_test_local = 156
INFO:root:client_idx = 2, local_sample_number = 4736
INFO:root:client_idx = 2, batch_num_train_local = 74, batch_num_test_local = 156
INFO:root:client_idx = 3, local_sample_number = 5075
INFO:root:client_idx = 3, batch_num_train_local = 79, batch_num_test_local = 156
INFO:root:client_idx = 4, local_sample_number = 5114
INFO:root:client_idx = 4, batch_num_train_local = 79, batch_num_test_local = 156
INFO:root:client_idx = 5, local_sample_number = 5219
INFO:root:client_idx = 5, batch_num_train_local = 81, batch_num_test_local = 156
INFO:root:client_idx = 6, local_sample_number = 5114
INFO:root:client_idx = 6, batch_num_train_local = 79, batch_num_test_local = 156
INFO:root:client_idx = 7, local_sample_number = 4862
INFO:root:client_idx = 7, batch_num_train_local = 75, batch_num_test_local = 156
INFO:root:client_idx = 8, local_sample_number = 5135
